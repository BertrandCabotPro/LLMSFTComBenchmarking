{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe4d2039-1e9c-4740-a2db-f41fe0f7f93b",
   "metadata": {},
   "source": [
    "# **TULU-3 Fine-Tuning**\n",
    "In this hands-on exercise, we will be fine-tuning different models for various tasks using classical fine-tuning. Classical fine-tuning is a common approach to establish a solid baseline for model specialization performance.\n",
    "\n",
    "The goal of fine-tuning is to take a pre-trained model and adapt it to a specific task or dataset. By leveraging the knowledge and representations learned from a large-scale pre-training task, we can achieve better performance on downstream tasks with less training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ee529f5-a7af-43d7-906f-a9ceadbd88f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import datasets\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModelForCausalLM, AutoModelForSeq2SeqLM\n",
    "from torch.utils.data import Dataset, DataLoader, IterableDataset\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "\n",
    "from utils import sft_tulu_tokenize_and_truncate\n",
    "\n",
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "\n",
    "DSDIR = Path(os.environ['DSDIR'])\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6d57b9-2869-4f71-b9e9-787c058479d6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cc45ed8-88c4-4ea6-938f-a550f13a9166",
   "metadata": {},
   "outputs": [],
   "source": [
    "DSDIR = Path(os.environ[\"DSDIR\"])\n",
    "model_path = DSDIR / \"HuggingFace_Models\" / \"Qwen/Qwen2.5-32B-Instruct\"\n",
    "dataset_path = DSDIR / \"HuggingFace\" / \"allenai\" / \"tulu-3-sft-mixture\" / \"data\" /\"*.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42c6472f-fb8e-4a12-9756-aa193d4d0cc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/lustre/fsmisc/dataset/HuggingFace/allenai/tulu-3-sft-mixture/data/*.parquet')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "067d0091-8d78-4ae8-a1d8-5b981feb9295",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"parquet\", data_files=str(dataset_path), split=\"train\").shuffle()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e14881c9-3a55-4867-a9f1-49865616f88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(str(model_path), padding_side=\"left\")\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1745fc3b-4a8d-4c19-b9bd-7b01943af166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|im_start|>system\\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\\n<|im_start|>user\\ncuales son los 12 jefes mas dificiles de la historia<|im_end|>\\n<|im_start|>assistant\\nCalificar a los jefes más difíciles en la historia de los videojuegos puede ser bastante subjetivo, ya que depende de la habilidad del jugador, el género del videojuego, y el tipo de dificultad que se aprecie (puro desafío técnico, necesidad de estrategia, resistencia, etc.). Sin embargo, algunos jefes han ganado notoriedad por su dificultad a lo largo de los años. He aquí una lista que combina diversos videojuegos y sus infames jefes:\\n\\n1. Ornstein y Smough - \"Dark Souls\": Este dúo es famoso por su difícil combate en equipo, donde derrotar primero a uno cambia significativamente la dificultad del jefe restante.\\n\\n2. Nameless King - \"Dark Souls III\": Famoso por ser uno de los combates más desafiantes y técnicamente exigentes de la serie.\\n\\n3. Lingering Will - \"Kingdom Hearts II Final Mix\": Un jefe secreto que pone a prueba todas las habilidades del jugador en el juego.\\n\\n4. Mike Tyson - \"Mike Tyson\\'s Punch-Out!!\": Uno de los jefes finales más difíciles debido a su patrón de golpes rápido e impredecible.\\n\\n5. Absolute Virtue - \"Final Fantasy XI\": Antes de que fuera nerfeado, este jefe era famoso por batallas que literalmente duraban horas sin garantía de victoria.\\n\\n6. Ruby Weapon y Emerald Weapon - \"Final Fantasy VII\": Dos super jefes opcionales que requerían estrategias muy específicas y mucha preparación.\\n\\n7. Sans - \"Undertale\": Su batalla es uno de los mayores desafíos del juego si eliges la ruta genocida, con patrones de ataque muy complicados.\\n\\n8. The Lich King - \"World of Warcraft\": En su época, fue uno de los jefes finales de raid más complicados, requiriendo una coordinación perfecta entre todos los jugadores del equipo.\\n\\n9. Yellow Devil - \"Mega Man\": Famoso por su patrón de ataque difícil de predecir y por requerir precisión en los disparos.\\n\\n10. Psycho Mantis - \"Metal Gear Solid\": Este jefe lee las acciones del jugador y los movimientos de los controladores, lo que obliga a los jugadores a cambiarlos de puerto para poder derrotarlo.\\n\\n11. Dr. Wily - \"Mega Man\" series: A veces no es tanto que sea especialmente difícil en sí mismo, sino el hecho de que lo enfrentas después de pasar por un nivel o serie de niveles difíciles sin puntos de guardado.\\n\\n12. The Radiance - \"Hollow Knight\": Un jefe oculto en el juego que pone a prueba todas las habilidades del jugador con ataques rápidos y pautas complicadas.\\n\\nEstos son solo doce ejemplos cuya dificultad ha resonado con los jugadores a lo largo de los años, pero hay muchísimos más jefes infames en la historia de los videojuegos. La dificultad también podría ser considerada en términos de cómo era percibida al momento del lanzamiento del juego, y si las mecánicas de juego eran nuevas para los jugadores de ese tiempo. Cabe señalar que algunos de estos jefes pueden haber sido diseñados para ser vencidos de una manera particular o necesitan que el jugador adquiera cierta habilidad o equipo para facilitar la batalla.<|im_end|>\\n<|im_start|>user\\nsegún revistas de videojuegos y testimonio de jugadores cuales son los 12 jefes mas dificiles de la historia<|im_end|>\\n<|im_start|>assistant\\nEl calificativo de \"jefe más difícil\" depende de las experiencias y habilidades de cada jugador, pero ciertos jefes han ganado notoriedad universal y aparecen con frecuencia en listas y discusiones de comunidades de videojuegos y en artículos de revistas especializadas. Aquí hay una lista compilada a partir de la reputación que han ganado algunos jefes a través de diferentes fuentes:\\n\\n1. Ornstein y Smough - \"Dark Souls\": Un dúo implacable que requiere que los jugadores dividan su atención y cambia dependiendo de cuál derrotes primero.\\n   \\n2. Ruby Weapon - \"Final Fantasy VII\": Un jefe opcional famoso por su vasta cantidad de HP y sus ataques devastadores que requerían una estrategia muy específica para derrotarlo.\\n   \\n3. Lingering Will - \"Kingdom Hearts II Final Mix\": Un jefe secreto con un repertorio de ataques complicados y difíciles de predecir.\\n   \\n4. The Nameless King - \"Dark Souls III\": A menudo referido como uno de los jefes más desafiantes de la franquicia de \"Dark Souls\" debido a sus ataques rápidos y poderosos.\\n   \\n5. Mike Tyson - \"Mike Tyson\\'s Punch-Out!!\": Las reacciones rápidas y los movimientos impredecibles de Tyson lo hacen un desafío legendario.\\n   \\n6. Absolute Virtue - \"Final Fantasy XI\": Este jefe tenía batallas tan largas y tan difíciles que incluso los desarrolladores tuvieron que intervenir y ajustar su dificultad.\\n   \\n7. Emerald Weapon - \"Final Fantasy VII\": al igual que Ruby Weapon, este jefe requiere una estrategia meticulosa y mucha paciencia para vencer.\\n   \\n8. C\\'Thun - \"World of Warcraft\": Antes de que fuera nerfeado, se consideraba prácticamente invencible debido a la coordinación perfecta que requería de los jugadores en la raid.\\n   \\n9. Sigrun - \"God of War\" (2018): La Reina de las Valquirias es un desafío extremo incluso para los jugadores más hábiles, con una variedad de ataques letales y una enorme cantidad de salud.\\n   \\n10. Sans - \"Undertale\": Especialmente en la ruta genocida, su batalla es una prueba de resistencia, timing y memoria.\\n   \\n11. Yellow Devil - \"Mega Man\": Un clásico jefe de los videojuegos que ha frustrado a los jugadores con su infame patrón de ataque.\\n   \\n12. Gehrman, The First Hunter - \"Bloodborne\": Uno de los jefes finales del juego que pone a prueba todas las habilidades del jugador en combate rápido y brutal.\\n\\nEstos jefes son recordados por su dificultad y han sido destacados en múltiples listas y discusiones sobre jefes difíciles en los videojuegos. Estas clasificaciones, por supuesto, están sujetas a cambios con el tiempo a medida que se lanzan nuevos juegos y se descubren nuevos desafíos. Además, es posible que algunos jugadores encuentren a otros jefes más difíciles debido a su estilo de juego o a las circunstancias únicas de su experiencia de juego individual.<|im_end|>\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = dataset[2]\n",
    "tokenizer.apply_chat_template(\n",
    "            conversation=row['messages'],\n",
    "            tokenize=False,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=False,\n",
    "            truncation=False,\n",
    "            add_generation_prompt=False,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64e13a23-411a-4df0-8453-4535d7d8ffba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sft_tulu_tokenize_and_truncate(row, tokenizer, 4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e48c923-59fd-486a-8a80-a09929dabbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(str(model_path), padding_side=\"left\")\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "873ad19b-6ebe-42d6-9b74-f1c5759e25f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f154f891-bd1f-4c2c-b568-d61f338da319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘datasets’: File exists\n",
      "mkdir: cannot create directory ‘datasets/tulu_3_sft_mixture’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir datasets\n",
    "!mkdir datasets/tulu_3_sft_mixture"
   ]
  },
  {
   "cell_type": "raw",
   "id": "91bd3291-3cb6-46a1-b253-b9ff7ff72017",
   "metadata": {},
   "source": [
    "import json\n",
    "\n",
    "seq_len = 2048\n",
    "\n",
    "# Écriture ligne par ligne dans un fichier .jsonl\n",
    "with open(\"datasets/tulu_3_sft_mixture.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "\n",
    "\n",
    "    for i in trange(len(dataset)):\n",
    "        sample = dataset[i]\n",
    "        message = tokenizer.apply_chat_template(\n",
    "                    conversation=sample['messages'],\n",
    "                    tokenize=False,\n",
    "                    return_tensors=\"pt\",\n",
    "                    padding=False,\n",
    "                    truncation=False,\n",
    "                    add_generation_prompt=False,\n",
    "                )\n",
    "        tokenized = tokenizer(\n",
    "        message,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=seq_len + 1,\n",
    "        )\n",
    "        input_ids = tokenized.input_ids\n",
    "        attention_mask = tokenized.attention_mask\n",
    "        item = {\"input_ids\": input_ids[..., :-1].tolist(), \"attention_mask\": attention_mask[..., :-1].tolist(), \"labels\": input_ids[..., 1:].tolist()}\n",
    "        json_line = json.dumps(item, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fb2001f-28e6-4870-a4aa-2a9b3748ce29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58708"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "939343 // 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bdf6efa5-1682-400e-ac23-0d6149d13d98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "939328"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "58708 * 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58112cea-4447-4cb7-a597-2a81015577a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06dab84d-f9bc-43dc-9cfd-3a82d8680c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7229bf03eaf1423b9ed4de3c1b4be5c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Écriture ligne par ligne dans un fichier .jsonl\n",
    "for i in trange(16):\n",
    "    with open(f\"datasets/tulu_3_sft_mixture_{i}.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "    \n",
    "        for j in range(58708):\n",
    "            sample = dataset[i * 58708 + j]\n",
    "            message = tokenizer.apply_chat_template(\n",
    "                        conversation=sample['messages'],\n",
    "                        tokenize=False,\n",
    "                        return_tensors=\"pt\",\n",
    "                        padding=False,\n",
    "                        truncation=False,\n",
    "                        add_generation_prompt=False,\n",
    "                    )\n",
    "            item = {'text': message}\n",
    "            json_line = json.dumps(item, ensure_ascii=False)\n",
    "            f.write(json_line + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fb7d72-c7ee-419b-abf6-8c69bed0d2d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287aec2a-949c-4d29-b721-8a3783c5be6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8183406e-9575-477e-9a13-52dc2dc92ec3",
   "metadata": {},
   "source": [
    "## Nanotron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "376c02e6-15ab-4626-b8eb-a5d41dc55eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!git clone https://github.com/huggingface/nanotron.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65142e6-09a2-4414-aedb-7f235fb318ae",
   "metadata": {},
   "source": [
    "puis:\n",
    "\n",
    "```bash\n",
    "cd nanotron\n",
    "[nanotron]$ pip install --user --no-cache-dir -e . --no-deps\n",
    "[nanotron]$ pip install --user --no-cache-dir dacite\n",
    "[nanotron]$ pip install --user --no-cache-dir datatrove loguru --no-deps\n",
    "```\n",
    "\n",
    "il faut utiliser une version de python inferieure à 2.12\n",
    "\n",
    "il faut aussi binariser son dataset au format nanotron.\n",
    "\n",
    "dans preprocess_data, je change\n",
    "\n",
    "```python\n",
    "def main(args):\n",
    "    # Build datatrove reader\n",
    "    if args.readers == \"hf\":\n",
    "        datatrove_reader = HuggingFaceDatasetReader(\n",
    "            dataset=args.dataset,\n",
    "            text_key=args.column,\n",
    "            streaming=True,\n",
    "            dataset_options={\"split\": args.split},\n",
    "        )\n",
    "```\n",
    "\n",
    "et \n",
    "\n",
    "```python\n",
    "preprocess_executor = LocalPipelineExecutor(\n",
    "        pipeline=[\n",
    "            datatrove_reader,\n",
    "            DocumentTokenizer(\n",
    "                output_folder=args.output_folder,\n",
    "                tokenizer_name_or_path=args.tokenizer_name_or_path,\n",
    "                eos_token=args.eos_token,\n",
    "                shuffle_documents=False,\n",
    "                max_tokens_per_file=1e9,\n",
    "            ),\n",
    "        ],\n",
    "        tasks=args.n_tasks,\n",
    "        logging_dir=args.logging_dir,\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9c773259-1733-4ea0-abe6-ba1e8a1986b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting preprocess_nanotron.slurm\n"
     ]
    }
   ],
   "source": [
    "%%writefile preprocess_nanotron.slurm\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=nano_pp\n",
    "#SBATCH --output=logs/out/nano_pp_%j.out \n",
    "#SBATCH --error=logs/err/nano_pp_%j.err\n",
    "#SBATCH --ntasks-per-node=1\n",
    "#SBATCH --hint=nomultithread \n",
    "#SBATCH --time=01:00:00\n",
    "#SBATCH --cpus-per-task=8\n",
    "#SBATCH --partition=archive\n",
    "#SBATCH --account=sos@h100\n",
    "\n",
    "## load module \n",
    "module purge\n",
    "module load arch/h100\n",
    "module load pytorch-gpu/py3/2.4.0\n",
    "\n",
    "\n",
    "## launch script on every task \n",
    "set -x\n",
    "time srun python nanotron/tools/preprocess_data.py \\\n",
    "  --tokenizer-name-or-path Qwen/Qwen2.5-14B-Instruct \\\n",
    "  --output-folder datasets/tulu_3_sft_mixture \\\n",
    "  --n-tasks 16 \\\n",
    "  jsonl \\\n",
    "  --dataset datasets \\\n",
    "  --glob-pattern *.jsonl \n",
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "22149b94-430a-4d84-8e6f-5c87985c8af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 684543\n"
     ]
    }
   ],
   "source": [
    "!sbatch preprocess_nanotron.slurm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3c2cb5ed-0e1a-4b03-bbfb-82703b40f36a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n"
     ]
    }
   ],
   "source": [
    "!squeue --me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1c342460-287d-4a95-89bd-24e1045f23b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer.vocab_size = 151643\n",
      "len(get_vocab())     = 151665\n",
      "specials: ['<|im_end|>', '<|endoftext|>', '<|im_start|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tok = AutoTokenizer.from_pretrained(\"/lustre/fsmisc/dataset/HuggingFace_Models/Qwen/Qwen2.5-14B-Instruct\")\n",
    "print(\"tokenizer.vocab_size =\", tok.vocab_size)\n",
    "print(\"len(get_vocab())     =\", len(tok.get_vocab()))\n",
    "print(\"specials:\", tok.all_special_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c23bb73-d7e4-40c5-962c-0613098d9b8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99353314-a979-420c-845d-2f402ad89b40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "832fa2e1-9ce6-43b2-94cb-aa0ac01fbca5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/lustre/fsmisc/dataset'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9c605faa-2386-46a4-8ef1-54fc20da874c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting preprocess_nanotron.slurm\n"
     ]
    }
   ],
   "source": [
    "%%writefile preprocess_nanotron.slurm\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=nano_pp\n",
    "#SBATCH --output=logs/out/nano_pp_%j.out \n",
    "#SBATCH --error=logs/err/nano_pp_%j.err\n",
    "#SBATCH --ntasks-per-node=1\n",
    "#SBATCH --hint=nomultithread \n",
    "#SBATCH --time=01:00:00\n",
    "#SBATCH --cpus-per-task=8\n",
    "#SBATCH --partition=archive\n",
    "#SBATCH --account=sos@a100\n",
    "\n",
    "\n",
    "## load module \n",
    "module purge\n",
    "module load arch/h100\n",
    "module load pytorch-gpu/py3/2.4.0\n",
    "\n",
    "\n",
    "## launch script on every task \n",
    "set -x\n",
    "time srun python config_qwen.py --out config_qwen_TP4_PP16.yaml --dp 1 --tp 4 --pp 16 --mbs 8 --acc 16\n",
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "431bc1c9-e267-4d6b-8876-e46d128f98a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 684477\n"
     ]
    }
   ],
   "source": [
    "!sbatch preprocess_nanotron.slurm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d41cd26a-6252-4b1b-ab49-c73b31c3f436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
      "            684477   archive  nano_pp  ssos040 PD       0:00      1 (None)\n"
     ]
    }
   ],
   "source": [
    "!squeue --me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9d3c6c-3bf4-4e21-98a0-383528758145",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu-2.7.0_py3.12.10",
   "language": "python",
   "name": "module-conda-env-pytorch-gpu-2.7.0_py3.12.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
