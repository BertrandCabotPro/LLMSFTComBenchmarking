[NeMo I 2025-11-10 18:40:59 nemo_logging:393] Using passed HF dataset Dataset({
        features: ['id', 'messages', 'source'],
        num_rows: 939343
    })
[NeMo I 2025-11-10 18:40:59 nemo_logging:393] Experiments will be logged at test_logdir/default/2025-11-10_18-40-59
[NeMo I 2025-11-10 18:41:00 nemo_logging:393] Rank 0 has data parallel group : [0, 4, 8, 12]
[NeMo I 2025-11-10 18:41:00 nemo_logging:393] Rank 0 has combined group of data parallel and context parallel : [0, 4, 8, 12]
[NeMo I 2025-11-10 18:41:00 nemo_logging:393] All data parallel group ranks with context parallel combined: [[0, 4, 8, 12], [1, 5, 9, 13], [2, 6, 10, 14], [3, 7, 11, 15], [16, 20, 24, 28], [17, 21, 25, 29], [18, 22, 26, 30], [19, 23, 27, 31]]
[NeMo I 2025-11-10 18:41:00 nemo_logging:393] Ranks 0 has data parallel rank: 0
[NeMo I 2025-11-10 18:41:00 nemo_logging:393] Rank 0 has context parallel group: [0]
[NeMo I 2025-11-10 18:41:00 nemo_logging:393] All context parallel group ranks: [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21], [22], [23], [24], [25], [26], [27], [28], [29], [30], [31]]
[NeMo I 2025-11-10 18:41:00 nemo_logging:393] Ranks 0 has context parallel rank: 0
[NeMo I 2025-11-10 18:41:00 nemo_logging:393] Rank 0 has model parallel group: [0, 1, 2, 3, 16, 17, 18, 19]
[NeMo I 2025-11-10 18:41:00 nemo_logging:393] All model parallel group ranks: [[0, 1, 2, 3, 16, 17, 18, 19], [4, 5, 6, 7, 20, 21, 22, 23], [8, 9, 10, 11, 24, 25, 26, 27], [12, 13, 14, 15, 28, 29, 30, 31]]
[NeMo I 2025-11-10 18:41:00 nemo_logging:393] Rank 0 has tensor model parallel group: [0, 1, 2, 3]
[NeMo I 2025-11-10 18:41:00 nemo_logging:393] All tensor model parallel group ranks: [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]]
[NeMo I 2025-11-10 18:41:00 nemo_logging:393] Rank 0 has tensor model parallel rank: 0
[NeMo I 2025-11-10 18:41:00 nemo_logging:393] Rank 0 has pipeline model parallel group: [0, 16]
[NeMo I 2025-11-10 18:41:00 nemo_logging:393] Rank 0 has embedding group: [0, 16]
[NeMo I 2025-11-10 18:41:00 nemo_logging:393] All pipeline model parallel group ranks: [[0, 16], [1, 17], [2, 18], [3, 19], [4, 20], [5, 21], [6, 22], [7, 23], [8, 24], [9, 25], [10, 26], [11, 27], [12, 28], [13, 29], [14, 30], [15, 31]]
[NeMo I 2025-11-10 18:41:00 nemo_logging:393] Rank 0 has pipeline model parallel rank 0
[NeMo I 2025-11-10 18:41:00 nemo_logging:393] All embedding group ranks: [[0, 16], [1, 17], [2, 18], [3, 19], [4, 20], [5, 21], [6, 22], [7, 23], [8, 24], [9, 25], [10, 26], [11, 27], [12, 28], [13, 29], [14, 30], [15, 31]]
[NeMo I 2025-11-10 18:41:00 nemo_logging:393] Rank 0 has embedding rank: 0
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[NeMo I 2025-11-10 18:41:04 nemo_logging:393] Use preset vocab_size: 152064, original vocab_size: 151643, dummy tokens: 421.
[NeMo I 2025-11-10 18:41:04 nemo_logging:393]  > number of parameters on (tensor, pipeline) model parallel rank (0 ,0): 1846437888
[NeMo I 2025-11-10 18:41:04 utils:661] Setting up DistributedDataParallel with config DistributedDataParallelConfig(grad_reduce_in_fp32=True, overlap_grad_reduce=False, overlap_param_gather=False, align_param_gather=False, use_distributed_optimizer=False, num_distributed_optimizer_instances=1, check_for_nan_in_grad=True, check_for_large_grads=False, bucket_size=None, pad_buckets_for_high_nccl_busbw=False, average_in_collective=False, fp8_param_gather=False, reuse_grad_buf_for_mxfp8_param_ag=False, use_custom_fsdp=False, data_parallel_sharding_strategy='no_shard', gradient_reduce_div_fusion=True, suggested_communication_unit_size=None, preserve_fp32_weights=True, keep_fp8_transpose_cache_when_using_custom_fsdp=False, nccl_ub=False, fsdp_double_buffer=False)
[NeMo I 2025-11-10 18:41:04 utils:682] Number of buckets for gradient all-reduce / reduce-scatter: 1
    Params for bucket 1 (1846437888 elements, 1846437888 padded size):
    	module.decoder.layers.22.self_attention.linear_qkv.layer_norm_weight
    	module.decoder.layers.19.mlp.linear_fc1.weight
    	module.decoder.layers.15.mlp.linear_fc1.layer_norm_weight
    	module.decoder.layers.11.self_attention.linear_qkv.bias
    	module.decoder.layers.8.self_attention.linear_qkv.layer_norm_weight
    	module.decoder.layers.6.self_attention.linear_proj.weight
    	module.decoder.layers.23.self_attention.linear_qkv.weight
    	module.decoder.layers.13.self_attention.linear_proj.weight
    	module.decoder.layers.9.self_attention.linear_qkv.weight
    	module.decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
    	module.decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
    	module.decoder.layers.22.mlp.linear_fc1.layer_norm_weight
    	module.decoder.layers.10.mlp.linear_fc2.weight
    	module.decoder.layers.8.mlp.linear_fc1.layer_norm_weight
    	module.decoder.layers.4.self_attention.linear_qkv.weight
    	module.decoder.layers.1.self_attention.linear_qkv.bias
    	module.decoder.layers.20.self_attention.linear_proj.weight
    	module.decoder.layers.16.self_attention.linear_qkv.weight
    	module.decoder.layers.12.mlp.linear_fc1.weight
    	module.decoder.layers.3.mlp.linear_fc1.layer_norm_weight
    	module.decoder.layers.13.self_attention.linear_qkv.bias
    	module.decoder.layers.18.self_attention.linear_proj.weight
    	module.decoder.layers.10.self_attention.linear_qkv.layer_norm_weight
    	module.decoder.layers.1.self_attention.linear_proj.weight
    	module.decoder.layers.16.mlp.linear_fc1.layer_norm_weight
    	module.decoder.layers.15.self_attention.linear_proj.weight
    	module.decoder.layers.11.self_attention.linear_qkv.weight
    	module.embedding.word_embeddings.weight
    	module.decoder.layers.20.self_attention.linear_qkv.bias
    	module.decoder.layers.17.mlp.linear_fc1.weight
    	module.decoder.layers.12.mlp.linear_fc2.weight
    	module.decoder.layers.10.mlp.linear_fc1.layer_norm_weight
    	module.decoder.layers.6.self_attention.linear_qkv.bias
    	module.decoder.layers.22.self_attention.linear_proj.weight
    	module.decoder.layers.18.self_attention.linear_qkv.bias
    	module.decoder.layers.14.mlp.linear_fc1.weight
    	module.decoder.layers.8.self_attention.linear_proj.weight
    	module.decoder.layers.1.self_attention.linear_qkv.weight
    	module.decoder.layers.19.mlp.linear_fc2.weight
    	module.decoder.layers.19.mlp.linear_fc1.layer_norm_weight
    	module.decoder.layers.15.self_attention.linear_qkv.bias
    	module.decoder.layers.12.self_attention.linear_qkv.layer_norm_weight
    	module.decoder.layers.5.mlp.linear_fc1.weight
    	module.decoder.layers.3.self_attention.linear_proj.weight
    	module.decoder.layers.21.mlp.linear_fc1.weight
    	module.decoder.layers.17.mlp.linear_fc2.weight
    	module.decoder.layers.13.self_attention.linear_qkv.weight
    	module.decoder.layers.7.mlp.linear_fc1.weight
    	module.decoder.layers.6.mlp.linear_fc1.layer_norm_weight
    	module.decoder.layers.22.self_attention.linear_qkv.bias
    	module.decoder.layers.19.self_attention.linear_qkv.layer_norm_weight
    	module.decoder.layers.14.mlp.linear_fc2.weight
    	module.decoder.layers.12.mlp.linear_fc1.layer_norm_weight
    	module.decoder.layers.8.self_attention.linear_qkv.bias
    	module.decoder.layers.2.mlp.linear_fc1.weight
    	module.decoder.layers.20.self_attention.linear_qkv.weight
    	module.decoder.layers.17.self_attention.linear_qkv.layer_norm_weight
    	module.decoder.layers.10.self_attention.linear_proj.weight
    	module.decoder.layers.6.self_attention.linear_qkv.weight
    	module.decoder.layers.3.self_attention.linear_qkv.bias
    	module.decoder.layers.0.self_attention.linear_qkv.bias
    	module.decoder.layers.21.mlp.linear_fc2.weight
    	module.decoder.layers.18.self_attention.linear_qkv.weight
    	module.decoder.layers.14.self_attention.linear_qkv.layer_norm_weight
    	module.decoder.layers.7.mlp.linear_fc2.weight
    	module.decoder.layers.5.self_attention.linear_proj.weight
    	module.decoder.layers.23.mlp.linear_fc1.weight
    	module.decoder.layers.17.mlp.linear_fc1.layer_norm_weight
    	module.decoder.layers.15.self_attention.linear_qkv.weight
    	module.decoder.layers.9.mlp.linear_fc1.weight
    	module.decoder.layers.5.mlp.linear_fc2.weight
    	module.decoder.layers.2.mlp.linear_fc2.weight
    	module.decoder.layers.0.mlp.linear_fc1.layer_norm_weight
    	module.decoder.layers.21.self_attention.linear_qkv.layer_norm_weight
    	module.decoder.layers.14.mlp.linear_fc1.layer_norm_weight
    	module.decoder.layers.10.self_attention.linear_qkv.bias
    	module.decoder.layers.7.self_attention.linear_qkv.layer_norm_weight
    	module.decoder.layers.4.mlp.linear_fc1.weight
    	module.decoder.layers.22.self_attention.linear_qkv.weight
    	module.decoder.layers.16.mlp.linear_fc1.weight
    	module.decoder.layers.12.self_attention.linear_proj.weight
    	module.decoder.layers.8.self_attention.linear_qkv.weight
    	module.decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
    	module.decoder.layers.23.mlp.linear_fc2.weight
    	module.decoder.layers.21.mlp.linear_fc1.layer_norm_weight
    	module.decoder.layers.9.mlp.linear_fc2.weight
    	module.decoder.layers.7.mlp.linear_fc1.layer_norm_weight
    	module.decoder.layers.3.self_attention.linear_qkv.weight
    	module.decoder.layers.0.self_attention.linear_qkv.weight
    	module.decoder.layers.19.self_attention.linear_proj.weight
    	module.decoder.layers.11.mlp.linear_fc1.weight
    	module.decoder.layers.4.mlp.linear_fc2.weight
    	module.decoder.layers.2.self_attention.linear_proj.weight
    	module.decoder.layers.23.self_attention.linear_qkv.layer_norm_weight
    	module.decoder.layers.16.mlp.linear_fc2.weight
    	module.decoder.layers.15.mlp.linear_fc2.weight
    	module.decoder.layers.12.self_attention.linear_qkv.bias
    	module.decoder.layers.9.self_attention.linear_qkv.layer_norm_weight
    	module.decoder.layers.6.mlp.linear_fc1.weight
    	module.decoder.layers.0.self_attention.linear_proj.weight
    	module.decoder.layers.14.self_attention.linear_proj.weight
    	module.decoder.layers.10.self_attention.linear_qkv.weight
    	module.decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
    	module.decoder.layers.1.mlp.linear_fc1.layer_norm_weight
    	module.decoder.layers.23.mlp.linear_fc1.layer_norm_weight
    	module.decoder.layers.19.self_attention.linear_qkv.bias
    	module.decoder.layers.16.self_attention.linear_qkv.layer_norm_weight
    	module.decoder.layers.11.mlp.linear_fc2.weight
    	module.decoder.layers.9.mlp.linear_fc1.layer_norm_weight
    	module.decoder.layers.5.self_attention.linear_qkv.bias
    	module.decoder.layers.21.self_attention.linear_proj.weight
    	module.decoder.layers.17.self_attention.linear_qkv.bias
    	module.decoder.layers.13.mlp.linear_fc1.weight
    	module.decoder.layers.7.self_attention.linear_proj.weight
    	module.decoder.layers.4.mlp.linear_fc1.layer_norm_weight
    	module.decoder.layers.14.self_attention.linear_qkv.bias
    	module.decoder.layers.11.self_attention.linear_qkv.layer_norm_weight
    	module.decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
    	module.decoder.layers.2.mlp.linear_fc1.layer_norm_weight
    	module.decoder.layers.20.mlp.linear_fc1.weight
    	module.decoder.layers.17.self_attention.linear_proj.weight
    	module.decoder.layers.12.self_attention.linear_qkv.weight
    	module.decoder.layers.1.mlp.linear_fc1.weight
    	module.decoder.layers.21.self_attention.linear_qkv.bias
    	module.decoder.layers.18.mlp.linear_fc1.weight
    	module.decoder.layers.13.mlp.linear_fc2.weight
    	module.decoder.layers.11.mlp.linear_fc1.layer_norm_weight
    	module.decoder.layers.7.self_attention.linear_qkv.bias
    	module.decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
    	module.decoder.layers.23.self_attention.linear_proj.weight
    	module.decoder.layers.19.self_attention.linear_qkv.weight
    	module.decoder.layers.15.mlp.linear_fc1.weight
    	module.decoder.layers.9.self_attention.linear_proj.weight
    	module.decoder.layers.5.self_attention.linear_qkv.weight
    	module.decoder.layers.2.self_attention.linear_qkv.bias
    	module.decoder.layers.20.mlp.linear_fc2.weight
    	module.decoder.layers.17.self_attention.linear_qkv.weight
    	module.decoder.layers.13.self_attention.linear_qkv.layer_norm_weight
    	module.decoder.layers.6.mlp.linear_fc2.weight
    	module.decoder.layers.4.self_attention.linear_proj.weight
    	module.decoder.layers.22.mlp.linear_fc1.weight
    	module.decoder.layers.18.mlp.linear_fc2.weight
    	module.decoder.layers.14.self_attention.linear_qkv.weight
    	module.decoder.layers.8.mlp.linear_fc1.weight
    	module.decoder.layers.1.mlp.linear_fc2.weight
    	module.decoder.layers.23.self_attention.linear_qkv.bias
    	module.decoder.layers.20.self_attention.linear_qkv.layer_norm_weight
    	module.decoder.layers.16.self_attention.linear_proj.weight
    	module.decoder.layers.13.mlp.linear_fc1.layer_norm_weight
    	module.decoder.layers.9.self_attention.linear_qkv.bias
    	module.decoder.layers.6.self_attention.linear_qkv.layer_norm_weight
    	module.decoder.layers.3.mlp.linear_fc1.weight
    	module.decoder.layers.0.mlp.linear_fc1.weight
    	module.decoder.layers.21.self_attention.linear_qkv.weight
    	module.decoder.layers.18.self_attention.linear_qkv.layer_norm_weight
    	module.decoder.layers.11.self_attention.linear_proj.weight
    	module.decoder.layers.7.self_attention.linear_qkv.weight
    	module.decoder.layers.4.self_attention.linear_qkv.bias
    	module.decoder.layers.22.mlp.linear_fc2.weight
    	module.decoder.layers.20.mlp.linear_fc1.layer_norm_weight
    	module.decoder.layers.16.self_attention.linear_qkv.bias
    	module.decoder.layers.15.self_attention.linear_qkv.layer_norm_weight
    	module.decoder.layers.8.mlp.linear_fc2.weight
    	module.decoder.layers.5.mlp.linear_fc1.layer_norm_weight
    	module.decoder.layers.2.self_attention.linear_qkv.weight
    	module.decoder.layers.18.mlp.linear_fc1.layer_norm_weight
    	module.decoder.layers.10.mlp.linear_fc1.weight
    	module.decoder.layers.3.mlp.linear_fc2.weight
    	module.decoder.layers.0.mlp.linear_fc2.weight
[NeMo I 2025-11-10 18:41:04 utils:661] Setting up optimizer with config OptimizerConfig(optimizer='adam', lr=0.0006, min_lr=None, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp8_recipe='delayed', fp16=False, bf16=True, reuse_grad_buf_for_mxfp8_param_ag=False, params_dtype=torch.float32, use_precision_aware_optimizer=False, store_param_remainders=True, main_grads_dtype=torch.float32, main_params_dtype=torch.float32, exp_avg_dtype=torch.float32, exp_avg_sq_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_param_gather_with_optimizer_step=False, optimizer_cpu_offload=False, optimizer_offload_fraction=0.0, use_torch_optimizer_for_cpu_offload=False, overlap_cpu_optimizer_d2h_h2d=False, pin_cpu_grads=True, pin_cpu_params=True, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=False, timers=None, config_logger_dir='')
None
None
None
None
None
None
None
None
None
[Rank 1] Initialized num_microbatches=16 (gbs=128, micro=2, dp=4)
<megatron.core.num_microbatches_calculator.ConstantNumMicroBatchesCalculator object at 0x14ca35b1a2a0>
None
None
[Rank 2] Initialized num_microbatches=16 (gbs=128, micro=2, dp=4)
<megatron.core.num_microbatches_calculator.ConstantNumMicroBatchesCalculator object at 0x14e9304ce3c0>
[Rank 3] Initialized num_microbatches=16 (gbs=128, micro=2, dp=4)
<megatron.core.num_microbatches_calculator.ConstantNumMicroBatchesCalculator object at 0x14dd37f72150>
[NeMo I 2025-11-10 18:41:04 num_microbatches_calculator:228] setting number of microbatches to constant 16
None
None
Pre-loop Model MaxMemory for GPU:1 18546481152 Bytes
[Rank 8] Initialized num_microbatches=16 (gbs=128, micro=2, dp=4)
None
[Rank 28] Initialized num_microbatches=16 (gbs=128, micro=2, dp=4)
None
None
[Rank 17] Initialized num_microbatches=16 (gbs=128, micro=2, dp=4)
[Rank 0] Initialized num_microbatches=16 (gbs=128, micro=2, dp=4)
[Rank 9] Initialized num_microbatches=16 (gbs=128, micro=2, dp=4)
<megatron.core.num_microbatches_calculator.ConstantNumMicroBatchesCalculator object at 0x1508c37fd1f0>
[Rank 13] Initialized num_microbatches=16 (gbs=128, micro=2, dp=4)
<megatron.core.num_microbatches_calculator.ConstantNumMicroBatchesCalculator object at 0x15006c641d30>
[Rank 29] Initialized num_microbatches=16 (gbs=128, micro=2, dp=4)
None
[Rank 16] Initialized num_microbatches=16 (gbs=128, micro=2, dp=4)
<megatron.core.num_microbatches_calculator.ConstantNumMicroBatchesCalculator object at 0x153da1ab24b0>
<megatron.core.num_microbatches_calculator.ConstantNumMicroBatchesCalculator object at 0x154d772c5be0>
None
[Rank 20] Initialized num_microbatches=16 (gbs=128, micro=2, dp=4)
<megatron.core.num_microbatches_calculator.ConstantNumMicroBatchesCalculator object at 0x15215a822e10>
None
None
[Rank 24] Initialized num_microbatches=16 (gbs=128, micro=2, dp=4)
<megatron.core.num_microbatches_calculator.ConstantNumMicroBatchesCalculator object at 0x14ca30160470>
<megatron.core.num_microbatches_calculator.ConstantNumMicroBatchesCalculator object at 0x14846df3d910>
None
Pre-loop Model MaxMemory for GPU:3 18546481152 Bytes
None
None
None
<megatron.core.num_microbatches_calculator.ConstantNumMicroBatchesCalculator object at 0x1482d215c350>
[Rank 25] Initialized num_microbatches=16 (gbs=128, micro=2, dp=4)
<megatron.core.num_microbatches_calculator.ConstantNumMicroBatchesCalculator object at 0x14b3ded58c20>
None
[Rank 4] Initialized num_microbatches=16 (gbs=128, micro=2, dp=4)
Pre-loop Model MaxMemory for GPU:2 18546481152 Bytes
<megatron.core.num_microbatches_calculator.ConstantNumMicroBatchesCalculator object at 0x14d7684771d0>
None
[Rank 12] Initialized num_microbatches=16 (gbs=128, micro=2, dp=4)
<megatron.core.num_microbatches_calculator.ConstantNumMicroBatchesCalculator object at 0x1547c6f9a8d0>
<megatron.core.num_microbatches_calculator.ConstantNumMicroBatchesCalculator object at 0x15292ef41940>
None
None
[Rank 5] Initialized num_microbatches=16 (gbs=128, micro=2, dp=4)
<megatron.core.num_microbatches_calculator.ConstantNumMicroBatchesCalculator object at 0x14ac8f4f01d0>
[Rank 11] Initialized num_microbatches=16 (gbs=128, micro=2, dp=4)
[Rank 21] Initialized num_microbatches=16 (gbs=128, micro=2, dp=4)
<megatron.core.num_microbatches_calculator.ConstantNumMicroBatchesCalculator object at 0x15125fede510>
[Rank 14] Initialized num_microbatches=16 (gbs=128, micro=2, dp=4)
[Rank 31] Initialized num_microbatches=16 (gbs=128, micro=2, dp=4)
<megatron.core.num_microbatches_calculator.ConstantNumMicroBatchesCalculator object at 0x14c3c5a2a6f0>
[Rank 27] Initialized num_microbatches=16 (gbs=128, micro=2, dp=4)
<megatron.core.num_microbatches_calculator.ConstantNumMicroBatchesCalculator object at 0x153aa3d36300>
[Rank 19] Initialized num_microbatches=16 (gbs=128, micro=2, dp=4)
<megatron.core.num_microbatches_calculator.ConstantNumMicroBatchesCalculator object at 0x148c3714ddc0>
None
[Rank 10] Initialized num_microbatches=16 (gbs=128, micro=2, dp=4)
[Rank 23] Initialized num_microbatches=16 (gbs=128, micro=2, dp=4)
<megatron.core.num_microbatches_calculator.ConstantNumMicroBatchesCalculator object at 0x151dad711f40>
[Rank 15] Initialized num_microbatches=16 (gbs=128, micro=2, dp=4)
<megatron.core.num_microbatches_calculator.ConstantNumMicroBatchesCalculator object at 0x15407cb25490>
None
[Rank 26] Initialized num_microbatches=16 (gbs=128, micro=2, dp=4)
<megatron.core.num_microbatches_calculator.ConstantNumMicroBatchesCalculator object at 0x14fee4130170>
[Rank 18] Initialized num_microbatches=16 (gbs=128, micro=2, dp=4)
<megatron.core.num_microbatches_calculator.ConstantNumMicroBatchesCalculator object at 0x145ade1100e0>
None
<megatron.core.num_microbatches_calculator.ConstantNumMicroBatchesCalculator object at 0x14ea72bca1b0>
None
<megatron.core.num_microbatches_calculator.ConstantNumMicroBatchesCalculator object at 0x152fa2cee1e0>
[Rank 30] Initialized num_microbatches=16 (gbs=128, micro=2, dp=4)
Pre-loop Model MaxMemory for GPU:24 18900647936 Bytes
Pre-loop Model MaxMemory for GPU:17 18900647936 Bytes
<megatron.core.num_microbatches_calculator.ConstantNumMicroBatchesCalculator object at 0x146c70b21e20>
<megatron.core.num_microbatches_calculator.ConstantNumMicroBatchesCalculator object at 0x14e850d2a2a0>
[Rank 22] Initialized num_microbatches=16 (gbs=128, micro=2, dp=4)
Pre-loop Model MaxMemory for GPU:13 18546481152 Bytes
<megatron.core.num_microbatches_calculator.ConstantNumMicroBatchesCalculator object at 0x1503a5fb5be0>
Pre-loop Model MaxMemory for GPU:25 18900647936 Bytes
[Rank 7] Initialized num_microbatches=16 (gbs=128, micro=2, dp=4)
<megatron.core.num_microbatches_calculator.ConstantNumMicroBatchesCalculator object at 0x14967287da00>
Pre-loop Model MaxMemory for GPU:8 18546481152 Bytes
<megatron.core.num_microbatches_calculator.ConstantNumMicroBatchesCalculator object at 0x14fa312119a0>
Pre-loop Model MaxMemory for GPU:12 18546481152 Bytes
Pre-loop Model MaxMemory for GPU:28 18900647936 Bytes
Pre-loop Model MaxMemory for GPU:27 18900647936 Bytes
[Rank 6] Initialized num_microbatches=16 (gbs=128, micro=2, dp=4)
Pre-loop Model MaxMemory for GPU:29 18900647936 Bytes
Pre-loop Model MaxMemory for GPU:26 18900647936 Bytes
<megatron.core.num_microbatches_calculator.ConstantNumMicroBatchesCalculator object at 0x14d27314f050>
Pre-loop Model MaxMemory for GPU:31 18900647936 Bytes
Pre-loop Model MaxMemory for GPU:4 18546481152 Bytes
Pre-loop Model MaxMemory for GPU:9 18546481152 Bytes
Pre-loop Model MaxMemory for GPU:14 18546481152 Bytes
Pre-loop Model MaxMemory for GPU:7 18546481152 Bytes
Pre-loop Model MaxMemory for GPU:10 18546481152 Bytes
Pre-loop Model MaxMemory for GPU:20 18900647936 Bytes
Pre-loop Model MaxMemory for GPU:16 18900647936 Bytes
Pre-loop Model MaxMemory for GPU:5 18546481152 Bytes
Pre-loop Model MaxMemory for GPU:11 18546481152 Bytes
Pre-loop Model MaxMemory for GPU:21 18900647936 Bytes
Pre-loop Model MaxMemory for GPU:18 18900647936 Bytes
Pre-loop Model MaxMemory for GPU:6 18546481152 Bytes
Pre-loop Model MaxMemory for GPU:23 18900647936 Bytes
Pre-loop Model MaxMemory for GPU:19 18900647936 Bytes
Pre-loop Model MaxMemory for GPU:15 18546481152 Bytes
Pre-loop Model MaxMemory for GPU:30 18900647936 Bytes
Pre-loop Model MaxMemory for GPU:22 18900647936 Bytes
Pre-loop Model MaxMemory for GPU:0 18546481152 Bytes
Mon Nov 10 18:41:08 CET 2025
