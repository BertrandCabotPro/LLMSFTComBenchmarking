[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
Using FSDP2 with DP=16, TP=4, CP=1
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
[NeMo I 2025-11-09 13:37:11 nemo_logging:393] use_linear_ce_loss: False
Using FSDP2 with DP=16, TP=4, CP=1
[NeMo I 2025-11-09 13:37:11 nemo_logging:393] Bad message (TypeError('not all arguments converted during string formatting')): {'name': 'nemo_logger', 'msg': 'You are using a huggingface TP plan. Make sure your model is a huggingface model. Certain ', 'args': ('parallelizations might not be supported. SP option will also be ignored.',), 'levelname': 'INFO', 'levelno': 20, 'pathname': '/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/utils/nemo_logging.py', 'filename': 'nemo_logging.py', 'module': 'nemo_logging', 'exc_info': None, 'exc_text': None, 'stack_info': None, 'lineno': 393, 'funcName': 'info', 'created': 1762691831.6366994, 'msecs': 636.0, 'relativeCreated': 38802.76083946228, 'thread': 23352369916992, 'threadName': 'MainThread', 'processName': 'MainProcess', 'process': 298678, 'taskName': None}
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[NeMo I 2025-11-09 13:37:11 nemo_logging:393] Using passed HF dataset Dataset({
        features: ['id', 'messages', 'source'],
        num_rows: 939343
    })
[NeMo I 2025-11-09 13:37:11 nemo_logging:393] Experiments will be logged at /tmp/tmpt8pp1fiz/nemo2_finetune
[NeMo I 2025-11-09 13:37:18 nemo_logging:393] Configuring model with attn_implementation: sdpa
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/29355 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/29355 [00:00<?, ?it/s] Epoch 0:   0%|          | 0/29355 [00:04<?, ?it/s]
Sun Nov  9 13:38:01 CET 2025
