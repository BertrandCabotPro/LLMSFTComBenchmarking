[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
Using FSDP2 with DP=16, TP=4, CP=1
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
[NeMo I 2025-11-09 13:46:13 nemo_logging:393] use_linear_ce_loss: False
Using FSDP2 with DP=16, TP=4, CP=1
[NeMo I 2025-11-09 13:46:13 nemo_logging:393] Bad message (TypeError('not all arguments converted during string formatting')): {'name': 'nemo_logger', 'msg': 'You are using a huggingface TP plan. Make sure your model is a huggingface model. Certain ', 'args': ('parallelizations might not be supported. SP option will also be ignored.',), 'levelname': 'INFO', 'levelno': 20, 'pathname': '/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/utils/nemo_logging.py', 'filename': 'nemo_logging.py', 'module': 'nemo_logging', 'exc_info': None, 'exc_text': None, 'stack_info': None, 'lineno': 393, 'funcName': 'info', 'created': 1762692373.5281181, 'msecs': 528.0, 'relativeCreated': 38751.779079437256, 'thread': 23433355197504, 'threadName': 'MainThread', 'processName': 'MainProcess', 'process': 300277, 'taskName': None}
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[warn] tp_size>1 with HFAutoModel: enabling --use-hf-tp-plan
Accumulate grad batches: 4
Using FSDP2 with DP=16, TP=4, CP=1
[NeMo I 2025-11-09 13:46:13 nemo_logging:393] Using passed HF dataset Dataset({
        features: ['id', 'messages', 'source'],
        num_rows: 939343
    })
[NeMo I 2025-11-09 13:46:13 nemo_logging:393] Experiments will be logged at /tmp/tmpnzfxrt08/nemo2_finetune
[NeMo I 2025-11-09 13:46:19 nemo_logging:393] Configuring model with attn_implementation: sdpa
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/29355 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/29355 [00:00<?, ?it/s] Epoch 0:   0%|          | 1/29355 [00:02<16:21:05,  0.50it/s]Epoch 0:   0%|          | 1/29355 [00:02<16:49:22,  0.48it/s, global_step=0.000]Epoch 0:   0%|          | 2/29355 [00:03<12:50:20,  0.64it/s, global_step=0.000]Epoch 0:   0%|          | 2/29355 [00:03<13:35:34,  0.60it/s, global_step=0.000]Epoch 0:   0%|          | 3/29355 [00:04<12:00:09,  0.68it/s, global_step=0.000]Epoch 0:   0%|          | 3/29355 [00:04<12:30:04,  0.65it/s, global_step=0.000]Epoch 0:   0%|          | 3/29355 [00:08<23:14:52,  0.35it/s, global_step=0.000]
Sun Nov  9 13:47:06 CET 2025
