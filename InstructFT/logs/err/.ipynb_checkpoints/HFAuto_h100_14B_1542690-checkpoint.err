Loading nemo/2.4.0
  Loading requirement: gcc/11.4.1 cuda/12.8.0 nccl/2.27.3-1-cuda
    cudnn/9.10.2.21-12-cuda openmpi/4.1.6-cuda intel-oneapi-mkl/2024.1
    magma/2.9.0-cuda sox/14.4.2 ffmpeg/6.1.1-cuda hdf5/1.12.0-mpi-cuda
    libjpeg-turbo/2.1.3
+ srun python -u nemo_TPFSDP2.py --model Qwen/Qwen2.5-14B-Instruct --use-te-optimizer --strategy fsdp2 --devices 4 --num-nodes 16 --tp-size 4 --dp-size 16 --batch-size 8
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
[NeMo W 2025-11-09 13:30:07 nemo_logging:405] /lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lhotse/recipes/iwslt22_ta.py:323: SyntaxWarning: invalid escape sequence '\s'
      text = re.sub("\s+", " ", text)
    
[NeMo W 2025-11-09 13:30:07 nemo_logging:405] /lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lhotse/recipes/iwslt22_ta.py:324: SyntaxWarning: invalid escape sequence '\s'
      text = re.sub("\s+\.\s+", ".", text)
    
[NeMo W 2025-11-09 13:30:07 nemo_logging:405] 
    
    ************************************************************************************************************************
    ************************************************************************************************************************
    *****  Automodel on NVIDIA/NeMo is deprecated. Please, use https://github.com/NVIDIA-NeMo/Automodel repo instead.  *****
    ************************************************************************************************************************
    ************************************************************************************************************************
    
[NeMo W 2025-11-09 13:30:07 nemo_logging:405] Waiting for 2 seconds before this message disappears.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
[NeMo W 2025-11-09 13:30:30 nemo_logging:405] /lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/jieba/__init__.py:44: SyntaxWarning: invalid escape sequence '\.'
      re_han_default = re.compile("([\u4E00-\u9FD5a-zA-Z0-9+#&\._%\-]+)", re.U)
    
[NeMo W 2025-11-09 13:30:30 nemo_logging:405] /lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/jieba/__init__.py:46: SyntaxWarning: invalid escape sequence '\s'
      re_skip_default = re.compile("(\r\n|\s)", re.U)
    
[NeMo W 2025-11-09 13:30:30 nemo_logging:405] /lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/jieba/finalseg/__init__.py:78: SyntaxWarning: invalid escape sequence '\.'
      re_skip = re.compile("([a-zA-Z0-9]+(?:\.\d+)?%?)")
    
[NeMo W 2025-11-09 13:30:32 nemo_logging:405] /lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/pydub/utils.py:300: SyntaxWarning: invalid escape sequence '\('
      m = re.match('([su]([0-9]{1,2})p?) \(([0-9]{1,2}) bit\)$', token)
    
[NeMo W 2025-11-09 13:30:32 nemo_logging:405] /lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/pydub/utils.py:301: SyntaxWarning: invalid escape sequence '\('
      m2 = re.match('([su]([0-9]{1,2})p?)( \(default\))?$', token)
    
[NeMo W 2025-11-09 13:30:32 nemo_logging:405] /lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/pydub/utils.py:310: SyntaxWarning: invalid escape sequence '\('
      elif re.match('(flt)p?( \(default\))?$', token):
    
[NeMo W 2025-11-09 13:30:32 nemo_logging:405] /lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/pydub/utils.py:314: SyntaxWarning: invalid escape sequence '\('
      elif re.match('(dbl)p?( \(default\))?$', token):
    
[NeMo W 2025-11-09 13:30:35 nemo_logging:405] Dependency for linear CE loss is not available.                     Please refer to https://github.com/apple/ml-cross-entropy.
Using bfloat16 Automatic Mixed Precision (AMP)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
[NeMo W 2025-11-09 13:30:35 nemo_logging:405] "update_logger_directory" is True. Overwriting tensorboard logger "save_dir" to /tmp/tmp0hdbf1e5
You are using a CUDA device ('NVIDIA H100 80GB HBM3') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 64 processes
----------------------------------------------------------------------------------------------------

Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 139.36it/s]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 166.39it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 174.58it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 163.70it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 167.14it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 152.35it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 156.28it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 157.17it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 156.48it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 153.22it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 150.07it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 151.74it/s]
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 146.03it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 144.99it/s]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 145.95it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 147.35it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 152.72it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 146.26it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 146.16it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 146.11it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 145.72it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 150.73it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 151.13it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 150.88it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 151.57it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 150.62it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 148.12it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 149.91it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 149.89it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 147.14it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 147.56it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 152.33it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 151.41it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 152.48it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 149.95it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 149.54it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 148.99it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 149.39it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 146.01it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 140.03it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 145.05it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 147.00it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 151.15it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 149.40it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 150.70it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 140.63it/s]
LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 143.42it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 140.35it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 142.80it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 144.78it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 150.07it/s]
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 145.76it/s]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 141.64it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 140.44it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 148.36it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 140.10it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 142.25it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 143.88it/s]
LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 142.71it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 145.55it/s]
LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 160.84it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 153.26it/s]
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 152.84it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 148.81it/s]
LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
[rank10]: Traceback (most recent call last):
[rank10]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 528, in <module>
[rank10]:     main()
[rank10]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 498, in main
[rank10]:     llm.api.finetune(
[rank10]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank10]:     return train(
[rank10]:            ^^^^^^
[rank10]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank10]:     trainer.fit(model, data)
[rank10]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank10]:     call._call_and_handle_interrupt(
[rank10]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank10]:     return trainer_fn(*args, **kwargs)
[rank10]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank10]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank10]:     self._run(model, ckpt_path=ckpt_path)
[rank10]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank10]:     results = self._run_stage()
[rank10]:               ^^^^^^^^^^^^^^^^^
[rank10]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank10]:     self.fit_loop.run()
[rank10]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank10]:     self.advance()
[rank10]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank10]:     self.epoch_loop.run(self._data_fetcher)
[rank10]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank10]:     self.advance(data_fetcher)
[rank10]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank10]:     super().advance(data_fetcher)
[rank10]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank10]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank10]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank10]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 190, in run
[rank10]:     self._optimizer_step(batch_idx, closure)
[rank10]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank10]:     call._call_lightning_module_hook(
[rank10]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 167, in _call_lightning_module_hook
[rank10]:     output = fn(*args, **kwargs)
[rank10]:              ^^^^^^^^^^^^^^^^^^^
[rank10]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/module.py", line 1306, in optimizer_step
[rank10]:     optimizer.step(closure=optimizer_closure)
[rank10]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py", line 153, in step
[rank10]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank10]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank10]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py", line 238, in optimizer_step
[rank10]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank10]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank10]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/amp.py", line 75, in optimizer_step
[rank10]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank10]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank10]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 122, in optimizer_step
[rank10]:     return optimizer.step(closure=closure, **kwargs)
[rank10]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank10]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/optim/optimizer.py", line 516, in wrapper
[rank10]:     out = func(*args, **kwargs)
[rank10]:           ^^^^^^^^^^^^^^^^^^^^^
[rank10]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformer_engine/pytorch/optimizers/fused_adam.py", line 486, in step
[rank10]:     loss = closure()
[rank10]:            ^^^^^^^^^
[rank10]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 108, in _wrap_closure
[rank10]:     closure_result = closure()
[rank10]:                      ^^^^^^^^^
[rank10]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank10]:     self._result = self.closure(*args, **kwargs)
[rank10]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank10]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank10]:     return func(*args, **kwargs)
[rank10]:            ^^^^^^^^^^^^^^^^^^^^^
[rank10]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank10]:     step_output = self._step_fn()
[rank10]:                   ^^^^^^^^^^^^^^^
[rank10]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank10]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank10]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank10]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank10]:     output = fn(*args, **kwargs)
[rank10]:              ^^^^^^^^^^^^^^^^^^^
[rank10]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank10]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank10]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank10]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank10]:     outputs = self.forward(batch)
[rank10]:               ^^^^^^^^^^^^^^^^^^^
[rank10]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank10]:     return self.model(**batch)
[rank10]:            ^^^^^^^^^^^^^^^^^^^
[rank10]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank10]:     return self._call_impl(*args, **kwargs)
[rank10]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank10]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank10]:     return inner()
[rank10]:            ^^^^^^^
[rank10]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank10]:     result = forward_call(*args, **kwargs)
[rank10]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank10]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank10]:     output = func(self, *args, **kwargs)
[rank10]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank10]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank10]:     return func(*args, **kwargs)
[rank10]:            ^^^^^^^^^^^^^^^^^^^^^
[rank10]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank10]:     outputs: BaseModelOutputWithPast = self.model(
[rank10]:                                        ^^^^^^^^^^^
[rank10]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank10]:     return self._call_impl(*args, **kwargs)
[rank10]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank10]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank10]:     return forward_call(*args, **kwargs)
[rank10]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank10]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank10]:     output = func(self, *args, **kwargs)
[rank10]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank10]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 549, in forward
[rank10]:     layer_outputs = decoder_layer(
[rank10]:                     ^^^^^^^^^^^^^^
[rank10]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank10]:     return self._call_impl(*args, **kwargs)
[rank10]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank10]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank10]:     return inner()
[rank10]:            ^^^^^^^
[rank10]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank10]:     result = forward_call(*args, **kwargs)
[rank10]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank10]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 259, in forward
[rank10]:     hidden_states = self.input_layernorm(hidden_states)
[rank10]:                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank10]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank10]:     return self._call_impl(*args, **kwargs)
[rank10]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank10]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank10]:     return forward_call(*args, **kwargs)
[rank10]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank10]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 223, in forward
[rank10]:     variance = hidden_states.pow(2).mean(-1, keepdim=True)
[rank10]:                ^^^^^^^^^^^^^^^^^^^^
[rank10]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 640.00 MiB. GPU 2 has a total capacity of 79.19 GiB of which 395.81 MiB is free. Including non-PyTorch memory, this process has 78.79 GiB memory in use. Of the allocated memory 74.80 GiB is allocated by PyTorch, and 1.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank9]: Traceback (most recent call last):
[rank9]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 528, in <module>
[rank9]:     main()
[rank9]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 498, in main
[rank9]:     llm.api.finetune(
[rank9]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank9]:     return train(
[rank9]:            ^^^^^^
[rank9]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank9]:     trainer.fit(model, data)
[rank9]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank9]:     call._call_and_handle_interrupt(
[rank9]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank9]:     return trainer_fn(*args, **kwargs)
[rank9]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank9]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank9]:     self._run(model, ckpt_path=ckpt_path)
[rank9]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank9]:     results = self._run_stage()
[rank9]:               ^^^^^^^^^^^^^^^^^
[rank9]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank9]:     self.fit_loop.run()
[rank9]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank9]:     self.advance()
[rank9]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank9]:     self.epoch_loop.run(self._data_fetcher)
[rank9]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank9]:     self.advance(data_fetcher)
[rank9]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank9]:     super().advance(data_fetcher)
[rank9]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank9]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank9]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank9]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 190, in run
[rank9]:     self._optimizer_step(batch_idx, closure)
[rank9]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank9]:     call._call_lightning_module_hook(
[rank9]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 167, in _call_lightning_module_hook
[rank9]:     output = fn(*args, **kwargs)
[rank9]:              ^^^^^^^^^^^^^^^^^^^
[rank9]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/module.py", line 1306, in optimizer_step
[rank9]:     optimizer.step(closure=optimizer_closure)
[rank9]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py", line 153, in step
[rank9]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank9]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank9]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py", line 238, in optimizer_step
[rank9]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank9]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank9]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/amp.py", line 75, in optimizer_step
[rank9]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank9]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank9]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 122, in optimizer_step
[rank9]:     return optimizer.step(closure=closure, **kwargs)
[rank9]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank9]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/optim/optimizer.py", line 516, in wrapper
[rank9]:     out = func(*args, **kwargs)
[rank9]:           ^^^^^^^^^^^^^^^^^^^^^
[rank9]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformer_engine/pytorch/optimizers/fused_adam.py", line 486, in step
[rank9]:     loss = closure()
[rank9]:            ^^^^^^^^^
[rank9]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 108, in _wrap_closure
[rank9]:     closure_result = closure()
[rank9]:                      ^^^^^^^^^
[rank9]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank9]:     self._result = self.closure(*args, **kwargs)
[rank9]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank9]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank9]:     return func(*args, **kwargs)
[rank9]:            ^^^^^^^^^^^^^^^^^^^^^
[rank9]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank9]:     step_output = self._step_fn()
[rank9]:                   ^^^^^^^^^^^^^^^
[rank9]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank9]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank9]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank9]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank9]:     output = fn(*args, **kwargs)
[rank9]:              ^^^^^^^^^^^^^^^^^^^
[rank9]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank9]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank9]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank9]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank9]:     outputs = self.forward(batch)
[rank9]:               ^^^^^^^^^^^^^^^^^^^
[rank9]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank9]:     return self.model(**batch)
[rank9]:            ^^^^^^^^^^^^^^^^^^^
[rank9]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank9]:     return self._call_impl(*args, **kwargs)
[rank9]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank9]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank9]:     return inner()
[rank9]:            ^^^^^^^
[rank9]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank9]:     result = forward_call(*args, **kwargs)
[rank9]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank9]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank9]:     output = func(self, *args, **kwargs)
[rank9]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank9]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank9]:     return func(*args, **kwargs)
[rank9]:            ^^^^^^^^^^^^^^^^^^^^^
[rank9]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank9]:     outputs: BaseModelOutputWithPast = self.model(
[rank9]:                                        ^^^^^^^^^^^
[rank9]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank9]:     return self._call_impl(*args, **kwargs)
[rank9]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank9]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank9]:     return forward_call(*args, **kwargs)
[rank9]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank9]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank9]:     output = func(self, *args, **kwargs)
[rank9]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank9]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 549, in forward
[rank9]:     layer_outputs = decoder_layer(
[rank9]:                     ^^^^^^^^^^^^^^
[rank9]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank9]:     return self._call_impl(*args, **kwargs)
[rank9]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank9]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank9]:     return inner()
[rank9]:            ^^^^^^^
[rank9]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank9]:     result = forward_call(*args, **kwargs)
[rank9]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank9]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 259, in forward
[rank9]:     hidden_states = self.input_layernorm(hidden_states)
[rank9]:                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank9]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank9]:     return self._call_impl(*args, **kwargs)
[rank9]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank9]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank9]:     return forward_call(*args, **kwargs)
[rank9]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank9]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 223, in forward
[rank9]:     variance = hidden_states.pow(2).mean(-1, keepdim=True)
[rank9]:                ^^^^^^^^^^^^^^^^^^^^
[rank9]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 640.00 MiB. GPU 1 has a total capacity of 79.19 GiB of which 367.81 MiB is free. Including non-PyTorch memory, this process has 78.82 GiB memory in use. Of the allocated memory 74.80 GiB is allocated by PyTorch, and 1.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank11]: Traceback (most recent call last):
[rank11]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 528, in <module>
[rank11]:     main()
[rank11]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 498, in main
[rank11]:     llm.api.finetune(
[rank11]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank11]:     return train(
[rank11]:            ^^^^^^
[rank11]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank11]:     trainer.fit(model, data)
[rank11]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank11]:     call._call_and_handle_interrupt(
[rank11]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank11]:     return trainer_fn(*args, **kwargs)
[rank11]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank11]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank11]:     self._run(model, ckpt_path=ckpt_path)
[rank11]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank11]:     results = self._run_stage()
[rank11]:               ^^^^^^^^^^^^^^^^^
[rank11]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank11]:     self.fit_loop.run()
[rank11]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank11]:     self.advance()
[rank11]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank11]:     self.epoch_loop.run(self._data_fetcher)
[rank11]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank11]:     self.advance(data_fetcher)
[rank11]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank11]:     super().advance(data_fetcher)
[rank11]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank11]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank11]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank11]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 190, in run
[rank11]:     self._optimizer_step(batch_idx, closure)
[rank11]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank11]:     call._call_lightning_module_hook(
[rank11]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 167, in _call_lightning_module_hook
[rank11]:     output = fn(*args, **kwargs)
[rank11]:              ^^^^^^^^^^^^^^^^^^^
[rank11]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/module.py", line 1306, in optimizer_step
[rank11]:     optimizer.step(closure=optimizer_closure)
[rank11]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py", line 153, in step
[rank11]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank11]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank11]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py", line 238, in optimizer_step
[rank11]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank11]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank11]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/amp.py", line 75, in optimizer_step
[rank11]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank11]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank11]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 122, in optimizer_step
[rank11]:     return optimizer.step(closure=closure, **kwargs)
[rank11]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank11]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/optim/optimizer.py", line 516, in wrapper
[rank11]:     out = func(*args, **kwargs)
[rank11]:           ^^^^^^^^^^^^^^^^^^^^^
[rank11]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformer_engine/pytorch/optimizers/fused_adam.py", line 486, in step
[rank11]:     loss = closure()
[rank11]:            ^^^^^^^^^
[rank11]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 108, in _wrap_closure
[rank11]:     closure_result = closure()
[rank11]:                      ^^^^^^^^^
[rank11]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank11]:     self._result = self.closure(*args, **kwargs)
[rank11]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank11]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank11]:     return func(*args, **kwargs)
[rank11]:            ^^^^^^^^^^^^^^^^^^^^^
[rank11]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank11]:     step_output = self._step_fn()
[rank11]:                   ^^^^^^^^^^^^^^^
[rank11]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank11]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank11]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank11]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank11]:     output = fn(*args, **kwargs)
[rank11]:              ^^^^^^^^^^^^^^^^^^^
[rank11]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank11]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank11]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank11]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank11]:     outputs = self.forward(batch)
[rank11]:               ^^^^^^^^^^^^^^^^^^^
[rank11]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank11]:     return self.model(**batch)
[rank11]:            ^^^^^^^^^^^^^^^^^^^
[rank47]: Traceback (most recent call last):
[rank47]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 528, in <module>
[rank47]:     main()
[rank47]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 498, in main
[rank47]:     llm.api.finetune(
[rank47]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank47]:     return train(
[rank47]:            ^^^^^^
[rank47]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank47]:     trainer.fit(model, data)
[rank47]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank47]:     call._call_and_handle_interrupt(
[rank11]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank11]:     return self._call_impl(*args, **kwargs)
[rank11]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank11]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank11]:     return inner()
[rank11]:            ^^^^^^^
[rank11]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank11]:     result = forward_call(*args, **kwargs)
[rank11]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank11]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank11]:     output = func(self, *args, **kwargs)
[rank11]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank11]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank11]:     return func(*args, **kwargs)
[rank11]:            ^^^^^^^^^^^^^^^^^^^^^
[rank11]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank11]:     outputs: BaseModelOutputWithPast = self.model(
[rank11]:                                        ^^^^^^^^^^^
[rank11]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank11]:     return self._call_impl(*args, **kwargs)
[rank11]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank47]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank47]:     return trainer_fn(*args, **kwargs)
[rank47]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank47]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank47]:     self._run(model, ckpt_path=ckpt_path)
[rank47]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank47]:     results = self._run_stage()
[rank47]:               ^^^^^^^^^^^^^^^^^
[rank47]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank47]:     self.fit_loop.run()
[rank11]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank11]:     return forward_call(*args, **kwargs)
[rank11]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank11]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank11]:     output = func(self, *args, **kwargs)
[rank11]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank11]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 549, in forward
[rank11]:     layer_outputs = decoder_layer(
[rank11]:                     ^^^^^^^^^^^^^^
[rank11]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank47]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank47]:     self.advance()
[rank47]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank47]:     self.epoch_loop.run(self._data_fetcher)
[rank47]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank47]:     self.advance(data_fetcher)
[rank47]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank47]:     super().advance(data_fetcher)
[rank11]:     return self._call_impl(*args, **kwargs)
[rank11]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank47]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank47]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank47]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank47]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 190, in run
[rank47]:     self._optimizer_step(batch_idx, closure)
[rank47]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank47]:     call._call_lightning_module_hook(
[rank11]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank11]:     return inner()
[rank11]:            ^^^^^^^
[rank11]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank11]:     result = forward_call(*args, **kwargs)
[rank11]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank11]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 259, in forward
[rank11]:     hidden_states = self.input_layernorm(hidden_states)
[rank11]:                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank11]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank47]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 167, in _call_lightning_module_hook
[rank47]:     output = fn(*args, **kwargs)
[rank47]:              ^^^^^^^^^^^^^^^^^^^
[rank11]:     return self._call_impl(*args, **kwargs)
[rank11]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank11]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank11]:     return forward_call(*args, **kwargs)
[rank11]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank11]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 223, in forward
[rank11]:     variance = hidden_states.pow(2).mean(-1, keepdim=True)
[rank11]:                ^^^^^^^^^^^^^^^^^^^^
[rank47]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/module.py", line 1306, in optimizer_step
[rank47]:     optimizer.step(closure=optimizer_closure)
[rank47]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py", line 153, in step
[rank47]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank47]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank47]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py", line 238, in optimizer_step
[rank47]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank47]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank11]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 640.00 MiB. GPU 3 has a total capacity of 79.19 GiB of which 411.81 MiB is free. Including non-PyTorch memory, this process has 78.78 GiB memory in use. Of the allocated memory 74.80 GiB is allocated by PyTorch, and 1.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank47]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/amp.py", line 75, in optimizer_step
[rank47]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank47]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank47]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 122, in optimizer_step
[rank47]:     return optimizer.step(closure=closure, **kwargs)
[rank47]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank47]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/optim/optimizer.py", line 516, in wrapper
[rank47]:     out = func(*args, **kwargs)
[rank47]:           ^^^^^^^^^^^^^^^^^^^^^
[rank47]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformer_engine/pytorch/optimizers/fused_adam.py", line 486, in step
[rank47]:     loss = closure()
[rank47]:            ^^^^^^^^^
[rank47]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 108, in _wrap_closure
[rank47]:     closure_result = closure()
[rank47]:                      ^^^^^^^^^
[rank47]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank47]:     self._result = self.closure(*args, **kwargs)
[rank47]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank47]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank47]:     return func(*args, **kwargs)
[rank47]:            ^^^^^^^^^^^^^^^^^^^^^
[rank47]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank47]:     step_output = self._step_fn()
[rank47]:                   ^^^^^^^^^^^^^^^
[rank47]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank47]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank47]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank47]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank47]:     output = fn(*args, **kwargs)
[rank47]:              ^^^^^^^^^^^^^^^^^^^
[rank47]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank47]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank47]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank47]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank47]:     outputs = self.forward(batch)
[rank47]:               ^^^^^^^^^^^^^^^^^^^
[rank47]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank47]:     return self.model(**batch)
[rank47]:            ^^^^^^^^^^^^^^^^^^^
[rank47]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank47]:     return self._call_impl(*args, **kwargs)
[rank47]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank47]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank47]:     return inner()
[rank47]:            ^^^^^^^
[rank47]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank47]:     result = forward_call(*args, **kwargs)
[rank47]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank47]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank47]:     output = func(self, *args, **kwargs)
[rank47]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank47]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank47]:     return func(*args, **kwargs)
[rank47]:            ^^^^^^^^^^^^^^^^^^^^^
[rank47]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank47]:     outputs: BaseModelOutputWithPast = self.model(
[rank47]:                                        ^^^^^^^^^^^
[rank47]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank47]:     return self._call_impl(*args, **kwargs)
[rank47]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank47]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank47]:     return forward_call(*args, **kwargs)
[rank47]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank47]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank47]:     output = func(self, *args, **kwargs)
[rank47]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank47]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 549, in forward
[rank47]:     layer_outputs = decoder_layer(
[rank47]:                     ^^^^^^^^^^^^^^
[rank47]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank47]:     return self._call_impl(*args, **kwargs)
[rank47]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank47]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank47]:     return inner()
[rank47]:            ^^^^^^^
[rank47]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank47]:     result = forward_call(*args, **kwargs)
[rank47]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank47]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 259, in forward
[rank47]:     hidden_states = self.input_layernorm(hidden_states)
[rank47]:                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank47]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank47]:     return self._call_impl(*args, **kwargs)
[rank47]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank47]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank47]:     return forward_call(*args, **kwargs)
[rank47]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank47]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 223, in forward
[rank47]:     variance = hidden_states.pow(2).mean(-1, keepdim=True)
[rank47]:                ^^^^^^^^^^^^^^^^^^^^
[rank47]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 640.00 MiB. GPU 3 has a total capacity of 79.19 GiB of which 411.81 MiB is free. Including non-PyTorch memory, this process has 78.78 GiB memory in use. Of the allocated memory 74.80 GiB is allocated by PyTorch, and 1.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank44]: Traceback (most recent call last):
[rank44]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 528, in <module>
[rank44]:     main()
[rank44]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 498, in main
[rank44]:     llm.api.finetune(
[rank44]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank44]:     return train(
[rank44]:            ^^^^^^
[rank44]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank44]:     trainer.fit(model, data)
[rank44]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank44]:     call._call_and_handle_interrupt(
[rank44]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank44]:     return trainer_fn(*args, **kwargs)
[rank44]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank44]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank44]:     self._run(model, ckpt_path=ckpt_path)
[rank44]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank44]:     results = self._run_stage()
[rank44]:               ^^^^^^^^^^^^^^^^^
[rank44]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank44]:     self.fit_loop.run()
[rank44]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank44]:     self.advance()
[rank44]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank44]:     self.epoch_loop.run(self._data_fetcher)
[rank44]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank44]:     self.advance(data_fetcher)
[rank44]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank44]:     super().advance(data_fetcher)
[rank44]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank44]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank44]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank44]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 190, in run
[rank44]:     self._optimizer_step(batch_idx, closure)
[rank44]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank44]:     call._call_lightning_module_hook(
[rank44]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 167, in _call_lightning_module_hook
[rank44]:     output = fn(*args, **kwargs)
[rank44]:              ^^^^^^^^^^^^^^^^^^^
[rank44]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/module.py", line 1306, in optimizer_step
[rank44]:     optimizer.step(closure=optimizer_closure)
[rank44]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py", line 153, in step
[rank44]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank44]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank44]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py", line 238, in optimizer_step
[rank44]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank44]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank44]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/amp.py", line 75, in optimizer_step
[rank44]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank44]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank44]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 122, in optimizer_step
[rank44]:     return optimizer.step(closure=closure, **kwargs)
[rank44]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank44]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/optim/optimizer.py", line 516, in wrapper
[rank44]:     out = func(*args, **kwargs)
[rank44]:           ^^^^^^^^^^^^^^^^^^^^^
[rank44]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformer_engine/pytorch/optimizers/fused_adam.py", line 486, in step
[rank44]:     loss = closure()
[rank44]:            ^^^^^^^^^
[rank44]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 108, in _wrap_closure
[rank44]:     closure_result = closure()
[rank44]:                      ^^^^^^^^^
[rank44]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank44]:     self._result = self.closure(*args, **kwargs)
[rank44]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank44]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank44]:     return func(*args, **kwargs)
[rank44]:            ^^^^^^^^^^^^^^^^^^^^^
[rank44]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank44]:     step_output = self._step_fn()
[rank44]:                   ^^^^^^^^^^^^^^^
[rank44]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank44]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank44]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank44]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank44]:     output = fn(*args, **kwargs)
[rank44]:              ^^^^^^^^^^^^^^^^^^^
[rank44]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank44]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank44]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank44]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank44]:     outputs = self.forward(batch)
[rank44]:               ^^^^^^^^^^^^^^^^^^^
[rank44]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank44]:     return self.model(**batch)
[rank44]:            ^^^^^^^^^^^^^^^^^^^
[rank44]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank44]:     return self._call_impl(*args, **kwargs)
[rank44]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank44]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank44]:     return inner()
[rank44]:            ^^^^^^^
[rank44]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank44]:     result = forward_call(*args, **kwargs)
[rank44]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank44]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank44]:     output = func(self, *args, **kwargs)
[rank44]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank44]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank44]:     return func(*args, **kwargs)
[rank44]:            ^^^^^^^^^^^^^^^^^^^^^
[rank44]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank44]:     outputs: BaseModelOutputWithPast = self.model(
[rank44]:                                        ^^^^^^^^^^^
[rank44]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank44]:     return self._call_impl(*args, **kwargs)
[rank44]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank44]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank44]:     return forward_call(*args, **kwargs)
[rank44]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank44]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank44]:     output = func(self, *args, **kwargs)
[rank44]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank44]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 549, in forward
[rank44]:     layer_outputs = decoder_layer(
[rank44]:                     ^^^^^^^^^^^^^^
[rank44]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank44]:     return self._call_impl(*args, **kwargs)
[rank44]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank8]: Traceback (most recent call last):
[rank8]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 528, in <module>
[rank8]:     main()
[rank8]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 498, in main
[rank8]:     llm.api.finetune(
[rank8]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank8]:     return train(
[rank8]:            ^^^^^^
[rank8]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank8]:     trainer.fit(model, data)
[rank8]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank8]:     call._call_and_handle_interrupt(
[rank44]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank44]:     return inner()
[rank44]:            ^^^^^^^
[rank44]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank44]:     result = forward_call(*args, **kwargs)
[rank44]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank44]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 259, in forward
[rank44]:     hidden_states = self.input_layernorm(hidden_states)
[rank44]:                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank44]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank44]:     return self._call_impl(*args, **kwargs)
[rank44]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank44]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank44]:     return forward_call(*args, **kwargs)
[rank44]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank44]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 223, in forward
[rank44]:     variance = hidden_states.pow(2).mean(-1, keepdim=True)
[rank44]:                ^^^^^^^^^^^^^^^^^^^^
[rank44]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 640.00 MiB. GPU 0 has a total capacity of 79.19 GiB of which 399.81 MiB is free. Including non-PyTorch memory, this process has 78.79 GiB memory in use. Of the allocated memory 74.80 GiB is allocated by PyTorch, and 1.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank8]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank8]:     return trainer_fn(*args, **kwargs)
[rank8]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank8]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank8]:     self._run(model, ckpt_path=ckpt_path)
[rank8]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank8]:     results = self._run_stage()
[rank8]:               ^^^^^^^^^^^^^^^^^
[rank8]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank8]:     self.fit_loop.run()
[rank8]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank8]:     self.advance()
[rank8]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank8]:     self.epoch_loop.run(self._data_fetcher)
[rank8]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank8]:     self.advance(data_fetcher)
[rank8]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank8]:     super().advance(data_fetcher)
[rank8]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank8]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank8]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank8]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 190, in run
[rank8]:     self._optimizer_step(batch_idx, closure)
[rank8]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank8]:     call._call_lightning_module_hook(
[rank8]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 167, in _call_lightning_module_hook
[rank8]:     output = fn(*args, **kwargs)
[rank8]:              ^^^^^^^^^^^^^^^^^^^
[rank8]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/module.py", line 1306, in optimizer_step
[rank8]:     optimizer.step(closure=optimizer_closure)
[rank8]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py", line 153, in step
[rank8]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank8]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank8]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py", line 238, in optimizer_step
[rank8]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank8]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank8]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/amp.py", line 75, in optimizer_step
[rank8]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank8]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank8]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 122, in optimizer_step
[rank8]:     return optimizer.step(closure=closure, **kwargs)
[rank8]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank8]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/optim/optimizer.py", line 516, in wrapper
[rank8]:     out = func(*args, **kwargs)
[rank8]:           ^^^^^^^^^^^^^^^^^^^^^
[rank8]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformer_engine/pytorch/optimizers/fused_adam.py", line 486, in step
[rank8]:     loss = closure()
[rank8]:            ^^^^^^^^^
[rank8]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 108, in _wrap_closure
[rank8]:     closure_result = closure()
[rank8]:                      ^^^^^^^^^
[rank8]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank8]:     self._result = self.closure(*args, **kwargs)
[rank8]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank8]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank8]:     return func(*args, **kwargs)
[rank8]:            ^^^^^^^^^^^^^^^^^^^^^
[rank8]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank8]:     step_output = self._step_fn()
[rank8]:                   ^^^^^^^^^^^^^^^
[rank8]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank8]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank8]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank8]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank8]:     output = fn(*args, **kwargs)
[rank8]:              ^^^^^^^^^^^^^^^^^^^
[rank8]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank8]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank8]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank8]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank8]:     outputs = self.forward(batch)
[rank8]:               ^^^^^^^^^^^^^^^^^^^
[rank8]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank8]:     return self.model(**batch)
[rank8]:            ^^^^^^^^^^^^^^^^^^^
[rank8]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank8]:     return self._call_impl(*args, **kwargs)
[rank8]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank8]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank8]:     return inner()
[rank8]:            ^^^^^^^
[rank8]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank8]:     result = forward_call(*args, **kwargs)
[rank8]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank8]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank8]:     output = func(self, *args, **kwargs)
[rank8]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank8]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank8]:     return func(*args, **kwargs)
[rank8]:            ^^^^^^^^^^^^^^^^^^^^^
[rank8]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank8]:     outputs: BaseModelOutputWithPast = self.model(
[rank8]:                                        ^^^^^^^^^^^
[rank8]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank8]:     return self._call_impl(*args, **kwargs)
[rank8]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank8]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank8]:     return forward_call(*args, **kwargs)
[rank8]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank8]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank8]:     output = func(self, *args, **kwargs)
[rank8]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank8]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 549, in forward
[rank8]:     layer_outputs = decoder_layer(
[rank8]:                     ^^^^^^^^^^^^^^
[rank8]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank8]:     return self._call_impl(*args, **kwargs)
[rank8]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank8]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank8]:     return inner()
[rank8]:            ^^^^^^^
[rank8]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank8]:     result = forward_call(*args, **kwargs)
[rank8]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank8]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 259, in forward
[rank8]:     hidden_states = self.input_layernorm(hidden_states)
[rank8]:                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank8]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank8]:     return self._call_impl(*args, **kwargs)
[rank8]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank8]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank8]:     return forward_call(*args, **kwargs)
[rank8]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank8]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 223, in forward
[rank8]:     variance = hidden_states.pow(2).mean(-1, keepdim=True)
[rank8]:                ^^^^^^^^^^^^^^^^^^^^
[rank8]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 640.00 MiB. GPU 0 has a total capacity of 79.19 GiB of which 399.81 MiB is free. Including non-PyTorch memory, this process has 78.79 GiB memory in use. Of the allocated memory 74.80 GiB is allocated by PyTorch, and 1.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank5]: Traceback (most recent call last):
[rank5]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 528, in <module>
[rank5]:     main()
[rank5]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 498, in main
[rank5]:     llm.api.finetune(
[rank5]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank5]:     return train(
[rank5]:            ^^^^^^
[rank5]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank5]:     trainer.fit(model, data)
[rank5]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank5]:     call._call_and_handle_interrupt(
[rank5]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank5]:     return trainer_fn(*args, **kwargs)
[rank5]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank5]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank5]:     self._run(model, ckpt_path=ckpt_path)
[rank5]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank5]:     results = self._run_stage()
[rank5]:               ^^^^^^^^^^^^^^^^^
[rank5]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank5]:     self.fit_loop.run()
[rank5]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank5]:     self.advance()
[rank5]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank5]:     self.epoch_loop.run(self._data_fetcher)
[rank5]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank5]:     self.advance(data_fetcher)
[rank5]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank5]:     super().advance(data_fetcher)
[rank5]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank5]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank5]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank5]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 190, in run
[rank5]:     self._optimizer_step(batch_idx, closure)
[rank5]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank5]:     call._call_lightning_module_hook(
[rank45]: Traceback (most recent call last):
[rank45]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 528, in <module>
[rank45]:     main()
[rank45]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 498, in main
[rank45]:     llm.api.finetune(
[rank45]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank45]:     return train(
[rank45]:            ^^^^^^
[rank45]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank45]:     trainer.fit(model, data)
[rank45]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank45]:     call._call_and_handle_interrupt(
[rank5]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 167, in _call_lightning_module_hook
[rank5]:     output = fn(*args, **kwargs)
[rank5]:              ^^^^^^^^^^^^^^^^^^^
[rank5]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/module.py", line 1306, in optimizer_step
[rank5]:     optimizer.step(closure=optimizer_closure)
[rank5]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py", line 153, in step
[rank5]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank5]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank5]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py", line 238, in optimizer_step
[rank5]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank5]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank5]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/amp.py", line 75, in optimizer_step
[rank5]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank5]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank5]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 122, in optimizer_step
[rank5]:     return optimizer.step(closure=closure, **kwargs)
[rank5]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank5]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/optim/optimizer.py", line 516, in wrapper
[rank5]:     out = func(*args, **kwargs)
[rank5]:           ^^^^^^^^^^^^^^^^^^^^^
[rank45]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank45]:     return trainer_fn(*args, **kwargs)
[rank45]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank45]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank45]:     self._run(model, ckpt_path=ckpt_path)
[rank45]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank45]:     results = self._run_stage()
[rank45]:               ^^^^^^^^^^^^^^^^^
[rank45]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank45]:     self.fit_loop.run()
[rank45]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank45]:     self.advance()
[rank45]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank45]:     self.epoch_loop.run(self._data_fetcher)
[rank45]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank45]:     self.advance(data_fetcher)
[rank45]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank45]:     super().advance(data_fetcher)
[rank45]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank45]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank45]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank45]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 190, in run
[rank45]:     self._optimizer_step(batch_idx, closure)
[rank45]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank45]:     call._call_lightning_module_hook(
[rank5]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformer_engine/pytorch/optimizers/fused_adam.py", line 486, in step
[rank5]:     loss = closure()
[rank5]:            ^^^^^^^^^
[rank5]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 108, in _wrap_closure
[rank5]:     closure_result = closure()
[rank5]:                      ^^^^^^^^^
[rank5]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank5]:     self._result = self.closure(*args, **kwargs)
[rank5]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank5]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank5]:     return func(*args, **kwargs)
[rank5]:            ^^^^^^^^^^^^^^^^^^^^^
[rank5]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank5]:     step_output = self._step_fn()
[rank5]:                   ^^^^^^^^^^^^^^^
[rank5]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank5]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank5]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank5]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank5]:     output = fn(*args, **kwargs)
[rank5]:              ^^^^^^^^^^^^^^^^^^^
[rank5]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank5]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank5]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank5]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank5]:     outputs = self.forward(batch)
[rank5]:               ^^^^^^^^^^^^^^^^^^^
[rank5]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank5]:     return self.model(**batch)
[rank5]:            ^^^^^^^^^^^^^^^^^^^
[rank45]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 167, in _call_lightning_module_hook
[rank45]:     output = fn(*args, **kwargs)
[rank45]:              ^^^^^^^^^^^^^^^^^^^
[rank5]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank5]:     return self._call_impl(*args, **kwargs)
[rank5]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank5]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank5]:     return inner()
[rank5]:            ^^^^^^^
[rank5]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank5]:     result = forward_call(*args, **kwargs)
[rank5]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank5]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank5]:     output = func(self, *args, **kwargs)
[rank45]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/module.py", line 1306, in optimizer_step
[rank45]:     optimizer.step(closure=optimizer_closure)
[rank45]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py", line 153, in step
[rank45]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank45]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank45]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py", line 238, in optimizer_step
[rank45]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank45]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank5]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank5]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank5]:     return func(*args, **kwargs)
[rank5]:            ^^^^^^^^^^^^^^^^^^^^^
[rank5]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank5]:     outputs: BaseModelOutputWithPast = self.model(
[rank5]:                                        ^^^^^^^^^^^
[rank5]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank5]:     return self._call_impl(*args, **kwargs)
[rank5]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank45]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/amp.py", line 75, in optimizer_step
[rank45]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank45]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank45]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 122, in optimizer_step
[rank45]:     return optimizer.step(closure=closure, **kwargs)
[rank45]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank45]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/optim/optimizer.py", line 516, in wrapper
[rank45]:     out = func(*args, **kwargs)
[rank45]:           ^^^^^^^^^^^^^^^^^^^^^
[rank5]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank5]:     return forward_call(*args, **kwargs)
[rank5]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank5]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank5]:     output = func(self, *args, **kwargs)
[rank5]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank5]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 549, in forward
[rank5]:     layer_outputs = decoder_layer(
[rank5]:                     ^^^^^^^^^^^^^^
[rank5]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank45]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformer_engine/pytorch/optimizers/fused_adam.py", line 486, in step
[rank45]:     loss = closure()
[rank45]:            ^^^^^^^^^
[rank45]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 108, in _wrap_closure
[rank45]:     closure_result = closure()
[rank45]:                      ^^^^^^^^^
[rank45]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank45]:     self._result = self.closure(*args, **kwargs)
[rank45]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank45]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank5]:     return self._call_impl(*args, **kwargs)
[rank5]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank5]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank5]:     return inner()
[rank45]:     return func(*args, **kwargs)
[rank45]:            ^^^^^^^^^^^^^^^^^^^^^
[rank45]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank45]:     step_output = self._step_fn()
[rank45]:                   ^^^^^^^^^^^^^^^
[rank45]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank45]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank45]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank45]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank45]:     output = fn(*args, **kwargs)
[rank5]:            ^^^^^^^
[rank5]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank5]:     result = forward_call(*args, **kwargs)
[rank5]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank5]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 259, in forward
[rank5]:     hidden_states = self.input_layernorm(hidden_states)
[rank5]:                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank5]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank5]:     return self._call_impl(*args, **kwargs)
[rank5]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank45]:              ^^^^^^^^^^^^^^^^^^^
[rank5]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank5]:     return forward_call(*args, **kwargs)
[rank5]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank5]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 223, in forward
[rank5]:     variance = hidden_states.pow(2).mean(-1, keepdim=True)
[rank5]:                ^^^^^^^^^^^^^^^^^^^^
[rank45]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank45]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank45]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank45]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank45]:     outputs = self.forward(batch)
[rank45]:               ^^^^^^^^^^^^^^^^^^^
[rank45]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank45]:     return self.model(**batch)
[rank45]:            ^^^^^^^^^^^^^^^^^^^
[rank5]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 640.00 MiB. GPU 1 has a total capacity of 79.19 GiB of which 367.81 MiB is free. Including non-PyTorch memory, this process has 78.82 GiB memory in use. Of the allocated memory 74.80 GiB is allocated by PyTorch, and 1.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank45]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank45]:     return self._call_impl(*args, **kwargs)
[rank45]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank45]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank45]:     return inner()
[rank45]:            ^^^^^^^
[rank45]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank45]:     result = forward_call(*args, **kwargs)
[rank45]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank45]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank45]:     output = func(self, *args, **kwargs)
[rank6]: Traceback (most recent call last):
[rank6]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 528, in <module>
[rank6]:     main()
[rank6]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 498, in main
[rank6]:     llm.api.finetune(
[rank6]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank6]:     return train(
[rank6]:            ^^^^^^
[rank6]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank6]:     trainer.fit(model, data)
[rank6]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank6]:     call._call_and_handle_interrupt(
[rank45]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank45]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank45]:     return func(*args, **kwargs)
[rank45]:            ^^^^^^^^^^^^^^^^^^^^^
[rank45]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank45]:     outputs: BaseModelOutputWithPast = self.model(
[rank45]:                                        ^^^^^^^^^^^
[rank45]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank45]:     return self._call_impl(*args, **kwargs)
[rank45]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank6]:     return trainer_fn(*args, **kwargs)
[rank6]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank6]:     self._run(model, ckpt_path=ckpt_path)
[rank6]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank6]:     results = self._run_stage()
[rank6]:               ^^^^^^^^^^^^^^^^^
[rank6]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank6]:     self.fit_loop.run()
[rank45]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank45]:     return forward_call(*args, **kwargs)
[rank45]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank45]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank45]:     output = func(self, *args, **kwargs)
[rank45]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank45]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 549, in forward
[rank45]:     layer_outputs = decoder_layer(
[rank45]:                     ^^^^^^^^^^^^^^
[rank45]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank6]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank6]:     self.advance()
[rank6]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank6]:     self.epoch_loop.run(self._data_fetcher)
[rank6]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank6]:     self.advance(data_fetcher)
[rank6]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank6]:     super().advance(data_fetcher)
[rank45]:     return self._call_impl(*args, **kwargs)
[rank45]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank6]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank6]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 190, in run
[rank6]:     self._optimizer_step(batch_idx, closure)
[rank6]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank6]:     call._call_lightning_module_hook(
[rank45]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank45]:     return inner()
[rank45]:            ^^^^^^^
[rank45]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank45]:     result = forward_call(*args, **kwargs)
[rank45]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank45]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 259, in forward
[rank45]:     hidden_states = self.input_layernorm(hidden_states)
[rank45]:                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank45]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank6]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 167, in _call_lightning_module_hook
[rank6]:     output = fn(*args, **kwargs)
[rank6]:              ^^^^^^^^^^^^^^^^^^^
[rank45]:     return self._call_impl(*args, **kwargs)
[rank45]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank45]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank45]:     return forward_call(*args, **kwargs)
[rank45]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank45]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 223, in forward
[rank45]:     variance = hidden_states.pow(2).mean(-1, keepdim=True)
[rank45]:                ^^^^^^^^^^^^^^^^^^^^
[rank6]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/module.py", line 1306, in optimizer_step
[rank6]:     optimizer.step(closure=optimizer_closure)
[rank6]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py", line 153, in step
[rank6]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank6]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py", line 238, in optimizer_step
[rank6]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank6]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank45]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 640.00 MiB. GPU 1 has a total capacity of 79.19 GiB of which 367.81 MiB is free. Including non-PyTorch memory, this process has 78.82 GiB memory in use. Of the allocated memory 74.80 GiB is allocated by PyTorch, and 1.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank6]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/amp.py", line 75, in optimizer_step
[rank6]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank6]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 122, in optimizer_step
[rank6]:     return optimizer.step(closure=closure, **kwargs)
[rank6]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/optim/optimizer.py", line 516, in wrapper
[rank6]:     out = func(*args, **kwargs)
[rank6]:           ^^^^^^^^^^^^^^^^^^^^^
[rank6]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformer_engine/pytorch/optimizers/fused_adam.py", line 486, in step
[rank6]:     loss = closure()
[rank6]:            ^^^^^^^^^
[rank6]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 108, in _wrap_closure
[rank6]:     closure_result = closure()
[rank6]:                      ^^^^^^^^^
[rank6]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank6]:     self._result = self.closure(*args, **kwargs)
[rank6]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank6]:     return func(*args, **kwargs)
[rank6]:            ^^^^^^^^^^^^^^^^^^^^^
[rank6]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank6]:     step_output = self._step_fn()
[rank6]:                   ^^^^^^^^^^^^^^^
[rank6]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank6]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank6]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank6]:     output = fn(*args, **kwargs)
[rank6]:              ^^^^^^^^^^^^^^^^^^^
[rank6]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank6]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank6]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank6]:     outputs = self.forward(batch)
[rank6]:               ^^^^^^^^^^^^^^^^^^^
[rank6]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank6]:     return self.model(**batch)
[rank6]:            ^^^^^^^^^^^^^^^^^^^
[rank6]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank6]:     return self._call_impl(*args, **kwargs)
[rank6]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank6]:     return inner()
[rank6]:            ^^^^^^^
[rank6]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank6]:     result = forward_call(*args, **kwargs)
[rank6]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank6]:     output = func(self, *args, **kwargs)
[rank6]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank6]:     return func(*args, **kwargs)
[rank6]:            ^^^^^^^^^^^^^^^^^^^^^
[rank6]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank6]:     outputs: BaseModelOutputWithPast = self.model(
[rank6]:                                        ^^^^^^^^^^^
[rank6]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank6]:     return self._call_impl(*args, **kwargs)
[rank6]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank6]:     return forward_call(*args, **kwargs)
[rank6]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank6]:     output = func(self, *args, **kwargs)
[rank6]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 549, in forward
[rank6]:     layer_outputs = decoder_layer(
[rank6]:                     ^^^^^^^^^^^^^^
[rank6]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank41]: Traceback (most recent call last):
[rank41]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 528, in <module>
[rank41]:     main()
[rank41]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 498, in main
[rank41]:     llm.api.finetune(
[rank41]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank41]:     return train(
[rank41]:            ^^^^^^
[rank41]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank41]:     trainer.fit(model, data)
[rank41]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank41]:     call._call_and_handle_interrupt(
[rank6]:     return self._call_impl(*args, **kwargs)
[rank6]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank6]:     return inner()
[rank41]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank41]:     return trainer_fn(*args, **kwargs)
[rank41]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank41]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank41]:     self._run(model, ckpt_path=ckpt_path)
[rank41]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank41]:     results = self._run_stage()
[rank41]:               ^^^^^^^^^^^^^^^^^
[rank41]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank41]:     self.fit_loop.run()
[rank6]:            ^^^^^^^
[rank6]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank6]:     result = forward_call(*args, **kwargs)
[rank6]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 259, in forward
[rank6]:     hidden_states = self.input_layernorm(hidden_states)
[rank6]:                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank6]:     return self._call_impl(*args, **kwargs)
[rank6]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank6]:     return forward_call(*args, **kwargs)
[rank6]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 223, in forward
[rank6]:     variance = hidden_states.pow(2).mean(-1, keepdim=True)
[rank6]:                ^^^^^^^^^^^^^^^^^^^^
[rank6]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 640.00 MiB. GPU 2 has a total capacity of 79.19 GiB of which 395.81 MiB is free. Including non-PyTorch memory, this process has 78.79 GiB memory in use. Of the allocated memory 74.80 GiB is allocated by PyTorch, and 1.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank41]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank41]:     self.advance()
[rank41]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank41]:     self.epoch_loop.run(self._data_fetcher)
[rank41]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank41]:     self.advance(data_fetcher)
[rank41]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank41]:     super().advance(data_fetcher)
[rank41]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank41]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank41]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank41]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 190, in run
[rank41]:     self._optimizer_step(batch_idx, closure)
[rank41]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank41]:     call._call_lightning_module_hook(
[rank41]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 167, in _call_lightning_module_hook
[rank41]:     output = fn(*args, **kwargs)
[rank41]:              ^^^^^^^^^^^^^^^^^^^
[rank41]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/module.py", line 1306, in optimizer_step
[rank41]:     optimizer.step(closure=optimizer_closure)
[rank41]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py", line 153, in step
[rank41]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank41]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank41]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py", line 238, in optimizer_step
[rank41]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank41]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank41]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/amp.py", line 75, in optimizer_step
[rank41]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank41]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank41]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 122, in optimizer_step
[rank41]:     return optimizer.step(closure=closure, **kwargs)
[rank41]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank41]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/optim/optimizer.py", line 516, in wrapper
[rank41]:     out = func(*args, **kwargs)
[rank41]:           ^^^^^^^^^^^^^^^^^^^^^
[rank41]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformer_engine/pytorch/optimizers/fused_adam.py", line 486, in step
[rank41]:     loss = closure()
[rank41]:            ^^^^^^^^^
[rank41]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 108, in _wrap_closure
[rank41]:     closure_result = closure()
[rank41]:                      ^^^^^^^^^
[rank41]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank41]:     self._result = self.closure(*args, **kwargs)
[rank41]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank41]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank41]:     return func(*args, **kwargs)
[rank41]:            ^^^^^^^^^^^^^^^^^^^^^
[rank41]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank41]:     step_output = self._step_fn()
[rank41]:                   ^^^^^^^^^^^^^^^
[rank41]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank41]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank41]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank41]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank41]:     output = fn(*args, **kwargs)
[rank41]:              ^^^^^^^^^^^^^^^^^^^
[rank41]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank41]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank41]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank41]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank41]:     outputs = self.forward(batch)
[rank41]:               ^^^^^^^^^^^^^^^^^^^
[rank41]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank41]:     return self.model(**batch)
[rank41]:            ^^^^^^^^^^^^^^^^^^^
[rank41]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank41]:     return self._call_impl(*args, **kwargs)
[rank41]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank41]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank41]:     return inner()
[rank41]:            ^^^^^^^
[rank41]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank41]:     result = forward_call(*args, **kwargs)
[rank41]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank41]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank41]:     output = func(self, *args, **kwargs)
[rank41]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank41]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank41]:     return func(*args, **kwargs)
[rank41]:            ^^^^^^^^^^^^^^^^^^^^^
[rank41]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank41]:     outputs: BaseModelOutputWithPast = self.model(
[rank41]:                                        ^^^^^^^^^^^
[rank41]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank41]:     return self._call_impl(*args, **kwargs)
[rank41]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank41]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank41]:     return forward_call(*args, **kwargs)
[rank41]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank41]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank41]:     output = func(self, *args, **kwargs)
[rank41]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank41]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 549, in forward
[rank41]:     layer_outputs = decoder_layer(
[rank41]:                     ^^^^^^^^^^^^^^
[rank41]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank41]:     return self._call_impl(*args, **kwargs)
[rank41]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank41]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank41]:     return inner()
[rank41]:            ^^^^^^^
[rank41]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank41]:     result = forward_call(*args, **kwargs)
[rank41]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank41]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 259, in forward
[rank41]:     hidden_states = self.input_layernorm(hidden_states)
[rank41]:                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank41]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank41]:     return self._call_impl(*args, **kwargs)
[rank41]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank41]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank41]:     return forward_call(*args, **kwargs)
[rank41]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank41]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 223, in forward
[rank41]:     variance = hidden_states.pow(2).mean(-1, keepdim=True)
[rank41]:                ^^^^^^^^^^^^^^^^^^^^
[rank41]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 640.00 MiB. GPU 1 has a total capacity of 79.19 GiB of which 367.81 MiB is free. Including non-PyTorch memory, this process has 78.82 GiB memory in use. Of the allocated memory 74.80 GiB is allocated by PyTorch, and 1.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank39]: Traceback (most recent call last):
[rank39]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 528, in <module>
[rank39]:     main()
[rank39]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 498, in main
[rank39]:     llm.api.finetune(
[rank39]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank39]:     return train(
[rank39]:            ^^^^^^
[rank39]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank39]:     trainer.fit(model, data)
[rank39]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank39]:     call._call_and_handle_interrupt(
[rank39]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank39]:     return trainer_fn(*args, **kwargs)
[rank39]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank39]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank39]:     self._run(model, ckpt_path=ckpt_path)
[rank39]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank39]:     results = self._run_stage()
[rank39]:               ^^^^^^^^^^^^^^^^^
[rank39]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank39]:     self.fit_loop.run()
[rank39]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank39]:     self.advance()
[rank39]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank39]:     self.epoch_loop.run(self._data_fetcher)
[rank39]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank39]:     self.advance(data_fetcher)
[rank39]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank39]:     super().advance(data_fetcher)
[rank39]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank39]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank39]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank39]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 190, in run
[rank39]:     self._optimizer_step(batch_idx, closure)
[rank39]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank39]:     call._call_lightning_module_hook(
[rank39]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 167, in _call_lightning_module_hook
[rank39]:     output = fn(*args, **kwargs)
[rank39]:              ^^^^^^^^^^^^^^^^^^^
[rank39]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/module.py", line 1306, in optimizer_step
[rank39]:     optimizer.step(closure=optimizer_closure)
[rank39]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py", line 153, in step
[rank39]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank39]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank39]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py", line 238, in optimizer_step
[rank39]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank39]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank39]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/amp.py", line 75, in optimizer_step
[rank39]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank39]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank39]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 122, in optimizer_step
[rank39]:     return optimizer.step(closure=closure, **kwargs)
[rank39]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank39]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/optim/optimizer.py", line 516, in wrapper
[rank39]:     out = func(*args, **kwargs)
[rank39]:           ^^^^^^^^^^^^^^^^^^^^^
[rank39]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformer_engine/pytorch/optimizers/fused_adam.py", line 486, in step
[rank39]:     loss = closure()
[rank39]:            ^^^^^^^^^
[rank39]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 108, in _wrap_closure
[rank39]:     closure_result = closure()
[rank39]:                      ^^^^^^^^^
[rank39]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank39]:     self._result = self.closure(*args, **kwargs)
[rank39]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank39]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank39]:     return func(*args, **kwargs)
[rank39]:            ^^^^^^^^^^^^^^^^^^^^^
[rank39]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank39]:     step_output = self._step_fn()
[rank39]:                   ^^^^^^^^^^^^^^^
[rank39]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank39]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank39]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank39]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank39]:     output = fn(*args, **kwargs)
[rank39]:              ^^^^^^^^^^^^^^^^^^^
[rank39]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank39]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank39]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank39]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank39]:     outputs = self.forward(batch)
[rank39]:               ^^^^^^^^^^^^^^^^^^^
[rank39]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank39]:     return self.model(**batch)
[rank39]:            ^^^^^^^^^^^^^^^^^^^
[rank39]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank39]:     return self._call_impl(*args, **kwargs)
[rank39]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank39]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank39]:     return inner()
[rank39]:            ^^^^^^^
[rank39]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank39]:     result = forward_call(*args, **kwargs)
[rank39]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank39]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank39]:     output = func(self, *args, **kwargs)
[rank39]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank39]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank39]:     return func(*args, **kwargs)
[rank39]:            ^^^^^^^^^^^^^^^^^^^^^
[rank39]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank39]:     outputs: BaseModelOutputWithPast = self.model(
[rank39]:                                        ^^^^^^^^^^^
[rank39]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank39]:     return self._call_impl(*args, **kwargs)
[rank39]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank39]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank39]:     return forward_call(*args, **kwargs)
[rank39]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank39]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank39]:     output = func(self, *args, **kwargs)
[rank39]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank39]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 549, in forward
[rank39]:     layer_outputs = decoder_layer(
[rank39]:                     ^^^^^^^^^^^^^^
[rank39]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank39]:     return self._call_impl(*args, **kwargs)
[rank39]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank39]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank39]:     return inner()
[rank39]:            ^^^^^^^
[rank39]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank39]:     result = forward_call(*args, **kwargs)
[rank39]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank39]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 259, in forward
[rank39]:     hidden_states = self.input_layernorm(hidden_states)
[rank39]:                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank39]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank39]:     return self._call_impl(*args, **kwargs)
[rank39]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank39]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank39]:     return forward_call(*args, **kwargs)
[rank39]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank39]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 223, in forward
[rank39]:     variance = hidden_states.pow(2).mean(-1, keepdim=True)
[rank39]:                ^^^^^^^^^^^^^^^^^^^^
[rank39]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 640.00 MiB. GPU 3 has a total capacity of 79.19 GiB of which 411.81 MiB is free. Including non-PyTorch memory, this process has 78.78 GiB memory in use. Of the allocated memory 74.80 GiB is allocated by PyTorch, and 1.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank49]: Traceback (most recent call last):
[rank49]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 528, in <module>
[rank49]:     main()
[rank49]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 498, in main
[rank49]:     llm.api.finetune(
[rank49]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank49]:     return train(
[rank49]:            ^^^^^^
[rank49]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank49]:     trainer.fit(model, data)
[rank49]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank49]:     call._call_and_handle_interrupt(
[rank49]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank49]:     return trainer_fn(*args, **kwargs)
[rank49]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank49]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank49]:     self._run(model, ckpt_path=ckpt_path)
[rank49]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank49]:     results = self._run_stage()
[rank49]:               ^^^^^^^^^^^^^^^^^
[rank49]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank49]:     self.fit_loop.run()
[rank49]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank49]:     self.advance()
[rank49]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank49]:     self.epoch_loop.run(self._data_fetcher)
[rank49]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank49]:     self.advance(data_fetcher)
[rank49]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank49]:     super().advance(data_fetcher)
[rank49]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank49]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank49]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank49]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 190, in run
[rank49]:     self._optimizer_step(batch_idx, closure)
[rank49]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank49]:     call._call_lightning_module_hook(
[rank17]: Traceback (most recent call last):
[rank17]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 528, in <module>
[rank17]:     main()
[rank17]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 498, in main
[rank17]:     llm.api.finetune(
[rank17]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank17]:     return train(
[rank17]:            ^^^^^^
[rank17]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank17]:     trainer.fit(model, data)
[rank17]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank17]:     call._call_and_handle_interrupt(
[rank49]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 167, in _call_lightning_module_hook
[rank49]:     output = fn(*args, **kwargs)
[rank49]:              ^^^^^^^^^^^^^^^^^^^
[rank17]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank17]:     return trainer_fn(*args, **kwargs)
[rank17]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank17]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank17]:     self._run(model, ckpt_path=ckpt_path)
[rank17]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank17]:     results = self._run_stage()
[rank17]:               ^^^^^^^^^^^^^^^^^
[rank17]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank17]:     self.fit_loop.run()
[rank49]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/module.py", line 1306, in optimizer_step
[rank49]:     optimizer.step(closure=optimizer_closure)
[rank49]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py", line 153, in step
[rank49]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank49]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank49]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py", line 238, in optimizer_step
[rank49]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank49]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank17]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank17]:     self.advance()
[rank17]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank17]:     self.epoch_loop.run(self._data_fetcher)
[rank17]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank17]:     self.advance(data_fetcher)
[rank17]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank17]:     super().advance(data_fetcher)
[rank49]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/amp.py", line 75, in optimizer_step
[rank49]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank49]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank49]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 122, in optimizer_step
[rank49]:     return optimizer.step(closure=closure, **kwargs)
[rank49]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank49]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/optim/optimizer.py", line 516, in wrapper
[rank49]:     out = func(*args, **kwargs)
[rank49]:           ^^^^^^^^^^^^^^^^^^^^^
[rank17]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank17]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank17]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank17]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 190, in run
[rank17]:     self._optimizer_step(batch_idx, closure)
[rank17]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank17]:     call._call_lightning_module_hook(
[rank49]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformer_engine/pytorch/optimizers/fused_adam.py", line 486, in step
[rank49]:     loss = closure()
[rank49]:            ^^^^^^^^^
[rank49]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 108, in _wrap_closure
[rank49]:     closure_result = closure()
[rank49]:                      ^^^^^^^^^
[rank49]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank49]:     self._result = self.closure(*args, **kwargs)
[rank49]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank49]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank17]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 167, in _call_lightning_module_hook
[rank17]:     output = fn(*args, **kwargs)
[rank17]:              ^^^^^^^^^^^^^^^^^^^
[rank49]:     return func(*args, **kwargs)
[rank49]:            ^^^^^^^^^^^^^^^^^^^^^
[rank49]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank49]:     step_output = self._step_fn()
[rank49]:                   ^^^^^^^^^^^^^^^
[rank49]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank49]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank49]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank49]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank49]:     output = fn(*args, **kwargs)
[rank17]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/module.py", line 1306, in optimizer_step
[rank17]:     optimizer.step(closure=optimizer_closure)
[rank17]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py", line 153, in step
[rank17]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank17]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank17]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py", line 238, in optimizer_step
[rank17]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank17]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank49]:              ^^^^^^^^^^^^^^^^^^^
[rank17]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/amp.py", line 75, in optimizer_step
[rank17]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank17]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank17]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 122, in optimizer_step
[rank17]:     return optimizer.step(closure=closure, **kwargs)
[rank17]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank17]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/optim/optimizer.py", line 516, in wrapper
[rank17]:     out = func(*args, **kwargs)
[rank17]:           ^^^^^^^^^^^^^^^^^^^^^
[rank49]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank49]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank49]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank49]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank49]:     outputs = self.forward(batch)
[rank49]:               ^^^^^^^^^^^^^^^^^^^
[rank49]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank49]:     return self.model(**batch)
[rank49]:            ^^^^^^^^^^^^^^^^^^^
[rank17]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformer_engine/pytorch/optimizers/fused_adam.py", line 486, in step
[rank17]:     loss = closure()
[rank17]:            ^^^^^^^^^
[rank17]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 108, in _wrap_closure
[rank17]:     closure_result = closure()
[rank17]:                      ^^^^^^^^^
[rank17]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank17]:     self._result = self.closure(*args, **kwargs)
[rank17]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank17]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank49]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank49]:     return self._call_impl(*args, **kwargs)
[rank49]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank49]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank49]:     return inner()
[rank49]:            ^^^^^^^
[rank49]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank49]:     result = forward_call(*args, **kwargs)
[rank49]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank49]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank49]:     output = func(self, *args, **kwargs)
[rank17]:     return func(*args, **kwargs)
[rank17]:            ^^^^^^^^^^^^^^^^^^^^^
[rank17]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank17]:     step_output = self._step_fn()
[rank17]:                   ^^^^^^^^^^^^^^^
[rank17]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank17]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank17]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank17]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank17]:     output = fn(*args, **kwargs)
[rank49]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank49]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank49]:     return func(*args, **kwargs)
[rank49]:            ^^^^^^^^^^^^^^^^^^^^^
[rank49]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank49]:     outputs: BaseModelOutputWithPast = self.model(
[rank49]:                                        ^^^^^^^^^^^
[rank49]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank49]:     return self._call_impl(*args, **kwargs)
[rank49]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank17]:              ^^^^^^^^^^^^^^^^^^^
[rank49]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank49]:     return forward_call(*args, **kwargs)
[rank49]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank49]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank49]:     output = func(self, *args, **kwargs)
[rank49]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank49]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 549, in forward
[rank49]:     layer_outputs = decoder_layer(
[rank49]:                     ^^^^^^^^^^^^^^
[rank49]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank17]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank17]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank17]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank17]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank17]:     outputs = self.forward(batch)
[rank17]:               ^^^^^^^^^^^^^^^^^^^
[rank17]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank17]:     return self.model(**batch)
[rank17]:            ^^^^^^^^^^^^^^^^^^^
[rank49]:     return self._call_impl(*args, **kwargs)
[rank49]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank17]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank17]:     return self._call_impl(*args, **kwargs)
[rank17]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank17]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank17]:     return inner()
[rank17]:            ^^^^^^^
[rank17]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank17]:     result = forward_call(*args, **kwargs)
[rank17]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank17]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank17]:     output = func(self, *args, **kwargs)
[rank49]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank49]:     return inner()
[rank49]:            ^^^^^^^
[rank49]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank49]:     result = forward_call(*args, **kwargs)
[rank49]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank49]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 259, in forward
[rank49]:     hidden_states = self.input_layernorm(hidden_states)
[rank49]:                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank49]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank17]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank17]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank17]:     return func(*args, **kwargs)
[rank17]:            ^^^^^^^^^^^^^^^^^^^^^
[rank17]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank17]:     outputs: BaseModelOutputWithPast = self.model(
[rank17]:                                        ^^^^^^^^^^^
[rank17]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank17]:     return self._call_impl(*args, **kwargs)
[rank17]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank49]:     return self._call_impl(*args, **kwargs)
[rank49]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank49]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank49]:     return forward_call(*args, **kwargs)
[rank49]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank49]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 223, in forward
[rank49]:     variance = hidden_states.pow(2).mean(-1, keepdim=True)
[rank49]:                ^^^^^^^^^^^^^^^^^^^^
[rank17]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank17]:     return forward_call(*args, **kwargs)
[rank17]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank17]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank17]:     output = func(self, *args, **kwargs)
[rank17]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank17]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 549, in forward
[rank17]:     layer_outputs = decoder_layer(
[rank17]:                     ^^^^^^^^^^^^^^
[rank17]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank49]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 640.00 MiB. GPU 1 has a total capacity of 79.19 GiB of which 367.81 MiB is free. Including non-PyTorch memory, this process has 78.82 GiB memory in use. Of the allocated memory 74.80 GiB is allocated by PyTorch, and 1.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank17]:     return self._call_impl(*args, **kwargs)
[rank17]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank17]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank17]:     return inner()
[rank17]:            ^^^^^^^
[rank17]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank17]:     result = forward_call(*args, **kwargs)
[rank17]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank17]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 259, in forward
[rank17]:     hidden_states = self.input_layernorm(hidden_states)
[rank17]:                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank17]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank17]:     return self._call_impl(*args, **kwargs)
[rank17]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank17]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank17]:     return forward_call(*args, **kwargs)
[rank17]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank17]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 223, in forward
[rank17]:     variance = hidden_states.pow(2).mean(-1, keepdim=True)
[rank17]:                ^^^^^^^^^^^^^^^^^^^^
[rank17]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 640.00 MiB. GPU 1 has a total capacity of 79.19 GiB of which 367.81 MiB is free. Including non-PyTorch memory, this process has 78.82 GiB memory in use. Of the allocated memory 74.80 GiB is allocated by PyTorch, and 1.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank43]: Traceback (most recent call last):
[rank43]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 528, in <module>
[rank43]:     main()
[rank43]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 498, in main
[rank43]:     llm.api.finetune(
[rank43]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank43]:     return train(
[rank43]:            ^^^^^^
[rank43]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank43]:     trainer.fit(model, data)
[rank43]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank43]:     call._call_and_handle_interrupt(
[rank4]: Traceback (most recent call last):
[rank4]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 528, in <module>
[rank4]:     main()
[rank4]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 498, in main
[rank4]:     llm.api.finetune(
[rank4]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank4]:     return train(
[rank4]:            ^^^^^^
[rank4]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank4]:     trainer.fit(model, data)
[rank4]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank4]:     call._call_and_handle_interrupt(
[rank43]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank43]:     return trainer_fn(*args, **kwargs)
[rank43]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank43]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank43]:     self._run(model, ckpt_path=ckpt_path)
[rank43]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank43]:     results = self._run_stage()
[rank43]:               ^^^^^^^^^^^^^^^^^
[rank43]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank43]:     self.fit_loop.run()
[rank43]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank43]:     self.advance()
[rank43]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank43]:     self.epoch_loop.run(self._data_fetcher)
[rank43]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank43]:     self.advance(data_fetcher)
[rank43]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank43]:     super().advance(data_fetcher)
[rank43]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank43]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank43]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank43]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 190, in run
[rank43]:     self._optimizer_step(batch_idx, closure)
[rank43]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank43]:     call._call_lightning_module_hook(
[rank43]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 167, in _call_lightning_module_hook
[rank43]:     output = fn(*args, **kwargs)
[rank43]:              ^^^^^^^^^^^^^^^^^^^
[rank43]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/module.py", line 1306, in optimizer_step
[rank43]:     optimizer.step(closure=optimizer_closure)
[rank43]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py", line 153, in step
[rank43]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank43]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank43]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py", line 238, in optimizer_step
[rank43]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank43]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank43]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/amp.py", line 75, in optimizer_step
[rank43]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank43]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank43]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 122, in optimizer_step
[rank43]:     return optimizer.step(closure=closure, **kwargs)
[rank43]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank43]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/optim/optimizer.py", line 516, in wrapper
[rank43]:     out = func(*args, **kwargs)
[rank43]:           ^^^^^^^^^^^^^^^^^^^^^
[rank1]: Traceback (most recent call last):
[rank1]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 528, in <module>
[rank1]:     main()
[rank1]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 498, in main
[rank1]:     llm.api.finetune(
[rank1]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank1]:     return train(
[rank1]:            ^^^^^^
[rank1]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank1]:     trainer.fit(model, data)
[rank1]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank1]:     call._call_and_handle_interrupt(
[rank4]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank4]:     return trainer_fn(*args, **kwargs)
[rank4]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank4]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank4]:     self._run(model, ckpt_path=ckpt_path)
[rank4]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank4]:     results = self._run_stage()
[rank4]:               ^^^^^^^^^^^^^^^^^
[rank4]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank4]:     self.fit_loop.run()
[rank43]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformer_engine/pytorch/optimizers/fused_adam.py", line 486, in step
[rank43]:     loss = closure()
[rank43]:            ^^^^^^^^^
[rank43]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 108, in _wrap_closure
[rank43]:     closure_result = closure()
[rank43]:                      ^^^^^^^^^
[rank43]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank43]:     self._result = self.closure(*args, **kwargs)
[rank43]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank43]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank4]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank4]:     self.advance()
[rank4]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank4]:     self.epoch_loop.run(self._data_fetcher)
[rank4]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank4]:     self.advance(data_fetcher)
[rank4]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank4]:     super().advance(data_fetcher)
[rank43]:     return func(*args, **kwargs)
[rank43]:            ^^^^^^^^^^^^^^^^^^^^^
[rank43]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank43]:     step_output = self._step_fn()
[rank43]:                   ^^^^^^^^^^^^^^^
[rank43]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank43]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank43]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank43]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank43]:     output = fn(*args, **kwargs)
[rank1]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank1]:     return trainer_fn(*args, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank1]:     self._run(model, ckpt_path=ckpt_path)
[rank1]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank1]:     results = self._run_stage()
[rank1]:               ^^^^^^^^^^^^^^^^^
[rank1]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank1]:     self.fit_loop.run()
[rank4]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank4]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank4]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank4]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 190, in run
[rank4]:     self._optimizer_step(batch_idx, closure)
[rank4]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank4]:     call._call_lightning_module_hook(
[rank43]:              ^^^^^^^^^^^^^^^^^^^
[rank16]: Traceback (most recent call last):
[rank16]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 528, in <module>
[rank16]:     main()
[rank16]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 498, in main
[rank16]:     llm.api.finetune(
[rank16]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank16]:     return train(
[rank16]:            ^^^^^^
[rank16]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank16]:     trainer.fit(model, data)
[rank16]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank16]:     call._call_and_handle_interrupt(
[rank1]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank1]:     self.advance()
[rank1]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank1]:     self.epoch_loop.run(self._data_fetcher)
[rank1]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank1]:     self.advance(data_fetcher)
[rank1]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank1]:     super().advance(data_fetcher)
[rank4]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 167, in _call_lightning_module_hook
[rank4]:     output = fn(*args, **kwargs)
[rank4]:              ^^^^^^^^^^^^^^^^^^^
[rank43]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank43]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank43]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank43]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank43]:     outputs = self.forward(batch)
[rank43]:               ^^^^^^^^^^^^^^^^^^^
[rank43]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank43]:     return self.model(**batch)
[rank43]:            ^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank1]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank1]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 190, in run
[rank1]:     self._optimizer_step(batch_idx, closure)
[rank1]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank1]:     call._call_lightning_module_hook(
[rank4]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/module.py", line 1306, in optimizer_step
[rank4]:     optimizer.step(closure=optimizer_closure)
[rank4]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py", line 153, in step
[rank4]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank4]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank4]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py", line 238, in optimizer_step
[rank4]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank4]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank43]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank43]:     return self._call_impl(*args, **kwargs)
[rank43]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank43]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank43]:     return inner()
[rank43]:            ^^^^^^^
[rank43]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank43]:     result = forward_call(*args, **kwargs)
[rank43]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank43]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank43]:     output = func(self, *args, **kwargs)
[rank55]: Traceback (most recent call last):
[rank55]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 528, in <module>
[rank55]:     main()
[rank55]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 498, in main
[rank55]:     llm.api.finetune(
[rank55]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank55]:     return train(
[rank55]:            ^^^^^^
[rank55]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank55]:     trainer.fit(model, data)
[rank55]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank55]:     call._call_and_handle_interrupt(
[rank1]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 167, in _call_lightning_module_hook
[rank1]:     output = fn(*args, **kwargs)
[rank1]:              ^^^^^^^^^^^^^^^^^^^
[rank4]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/amp.py", line 75, in optimizer_step
[rank4]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank4]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank4]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 122, in optimizer_step
[rank4]:     return optimizer.step(closure=closure, **kwargs)
[rank4]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank4]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/optim/optimizer.py", line 516, in wrapper
[rank4]:     out = func(*args, **kwargs)
[rank4]:           ^^^^^^^^^^^^^^^^^^^^^
[rank43]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank43]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank43]:     return func(*args, **kwargs)
[rank43]:            ^^^^^^^^^^^^^^^^^^^^^
[rank43]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank43]:     outputs: BaseModelOutputWithPast = self.model(
[rank43]:                                        ^^^^^^^^^^^
[rank43]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank43]:     return self._call_impl(*args, **kwargs)
[rank43]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/module.py", line 1306, in optimizer_step
[rank1]:     optimizer.step(closure=optimizer_closure)
[rank1]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py", line 153, in step
[rank1]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank1]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py", line 238, in optimizer_step
[rank1]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank4]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformer_engine/pytorch/optimizers/fused_adam.py", line 486, in step
[rank4]:     loss = closure()
[rank4]:            ^^^^^^^^^
[rank4]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 108, in _wrap_closure
[rank4]:     closure_result = closure()
[rank4]:                      ^^^^^^^^^
[rank4]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank4]:     self._result = self.closure(*args, **kwargs)
[rank4]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank4]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank43]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank43]:     return forward_call(*args, **kwargs)
[rank43]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank43]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank43]:     output = func(self, *args, **kwargs)
[rank43]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank43]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 549, in forward
[rank43]:     layer_outputs = decoder_layer(
[rank43]:                     ^^^^^^^^^^^^^^
[rank43]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank55]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank55]:     return trainer_fn(*args, **kwargs)
[rank55]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank55]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank55]:     self._run(model, ckpt_path=ckpt_path)
[rank55]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank55]:     results = self._run_stage()
[rank55]:               ^^^^^^^^^^^^^^^^^
[rank55]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank55]:     self.fit_loop.run()
[rank16]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank16]:     return trainer_fn(*args, **kwargs)
[rank16]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank16]:     self._run(model, ckpt_path=ckpt_path)
[rank16]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank16]:     results = self._run_stage()
[rank16]:               ^^^^^^^^^^^^^^^^^
[rank16]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank16]:     self.fit_loop.run()
[rank1]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/amp.py", line 75, in optimizer_step
[rank1]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 122, in optimizer_step
[rank1]:     return optimizer.step(closure=closure, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/optim/optimizer.py", line 516, in wrapper
[rank1]:     out = func(*args, **kwargs)
[rank1]:           ^^^^^^^^^^^^^^^^^^^^^
[rank4]:     return func(*args, **kwargs)
[rank4]:            ^^^^^^^^^^^^^^^^^^^^^
[rank4]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank4]:     step_output = self._step_fn()
[rank4]:                   ^^^^^^^^^^^^^^^
[rank4]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank4]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank4]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank4]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank4]:     output = fn(*args, **kwargs)
[rank43]:     return self._call_impl(*args, **kwargs)
[rank43]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank16]:     self.advance()
[rank16]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank16]:     self.epoch_loop.run(self._data_fetcher)
[rank16]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank16]:     self.advance(data_fetcher)
[rank16]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank16]:     super().advance(data_fetcher)
[rank1]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformer_engine/pytorch/optimizers/fused_adam.py", line 486, in step
[rank1]:     loss = closure()
[rank1]:            ^^^^^^^^^
[rank1]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 108, in _wrap_closure
[rank1]:     closure_result = closure()
[rank1]:                      ^^^^^^^^^
[rank1]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank1]:     self._result = self.closure(*args, **kwargs)
[rank1]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank4]:              ^^^^^^^^^^^^^^^^^^^
[rank43]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank43]:     return inner()
[rank43]:            ^^^^^^^
[rank43]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank43]:     result = forward_call(*args, **kwargs)
[rank43]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank43]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 259, in forward
[rank43]:     hidden_states = self.input_layernorm(hidden_states)
[rank43]:                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank43]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank16]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank16]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank16]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 190, in run
[rank16]:     self._optimizer_step(batch_idx, closure)
[rank16]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank16]:     call._call_lightning_module_hook(
[rank1]:     return func(*args, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank1]:     step_output = self._step_fn()
[rank1]:                   ^^^^^^^^^^^^^^^
[rank1]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank1]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank1]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank1]:     output = fn(*args, **kwargs)
[rank4]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank4]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank4]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank4]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank4]:     outputs = self.forward(batch)
[rank4]:               ^^^^^^^^^^^^^^^^^^^
[rank4]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank4]:     return self.model(**batch)
[rank4]:            ^^^^^^^^^^^^^^^^^^^
[rank43]:     return self._call_impl(*args, **kwargs)
[rank43]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank43]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank43]:     return forward_call(*args, **kwargs)
[rank43]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank43]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 223, in forward
[rank43]:     variance = hidden_states.pow(2).mean(-1, keepdim=True)
[rank43]:                ^^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 167, in _call_lightning_module_hook
[rank16]:     output = fn(*args, **kwargs)
[rank16]:              ^^^^^^^^^^^^^^^^^^^
[rank1]:              ^^^^^^^^^^^^^^^^^^^
[rank4]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank4]:     return self._call_impl(*args, **kwargs)
[rank4]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank4]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank4]:     return inner()
[rank4]:            ^^^^^^^
[rank4]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank4]:     result = forward_call(*args, **kwargs)
[rank4]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank4]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank4]:     output = func(self, *args, **kwargs)
[rank43]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 640.00 MiB. GPU 3 has a total capacity of 79.19 GiB of which 411.81 MiB is free. Including non-PyTorch memory, this process has 78.78 GiB memory in use. Of the allocated memory 74.80 GiB is allocated by PyTorch, and 1.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank16]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/module.py", line 1306, in optimizer_step
[rank16]:     optimizer.step(closure=optimizer_closure)
[rank16]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py", line 153, in step
[rank16]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank16]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py", line 238, in optimizer_step
[rank16]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank16]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank1]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank1]:     outputs = self.forward(batch)
[rank1]:               ^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank1]:     return self.model(**batch)
[rank1]:            ^^^^^^^^^^^^^^^^^^^
[rank4]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank4]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank4]:     return func(*args, **kwargs)
[rank4]:            ^^^^^^^^^^^^^^^^^^^^^
[rank4]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank4]:     outputs: BaseModelOutputWithPast = self.model(
[rank4]:                                        ^^^^^^^^^^^
[rank4]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank4]:     return self._call_impl(*args, **kwargs)
[rank4]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/amp.py", line 75, in optimizer_step
[rank16]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank16]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 122, in optimizer_step
[rank16]:     return optimizer.step(closure=closure, **kwargs)
[rank16]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/optim/optimizer.py", line 516, in wrapper
[rank16]:     out = func(*args, **kwargs)
[rank16]:           ^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank1]:     return inner()
[rank1]:            ^^^^^^^
[rank1]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank1]:     result = forward_call(*args, **kwargs)
[rank1]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank1]:     output = func(self, *args, **kwargs)
[rank4]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank4]:     return forward_call(*args, **kwargs)
[rank4]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank4]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank4]:     output = func(self, *args, **kwargs)
[rank4]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank4]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 549, in forward
[rank4]:     layer_outputs = decoder_layer(
[rank4]:                     ^^^^^^^^^^^^^^
[rank4]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank55]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank55]:     self.advance()
[rank55]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank55]:     self.epoch_loop.run(self._data_fetcher)
[rank55]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank55]:     self.advance(data_fetcher)
[rank55]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank55]:     super().advance(data_fetcher)
[rank16]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformer_engine/pytorch/optimizers/fused_adam.py", line 486, in step
[rank16]:     loss = closure()
[rank16]:            ^^^^^^^^^
[rank16]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 108, in _wrap_closure
[rank16]:     closure_result = closure()
[rank16]:                      ^^^^^^^^^
[rank16]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank16]:     self._result = self.closure(*args, **kwargs)
[rank16]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank1]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank1]:     return func(*args, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank1]:     outputs: BaseModelOutputWithPast = self.model(
[rank1]:                                        ^^^^^^^^^^^
[rank1]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank4]:     return self._call_impl(*args, **kwargs)
[rank4]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank4]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank4]:     return inner()
[rank55]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank55]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank55]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank55]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 190, in run
[rank55]:     self._optimizer_step(batch_idx, closure)
[rank55]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank55]:     call._call_lightning_module_hook(
[rank16]:     return func(*args, **kwargs)
[rank16]:            ^^^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank16]:     step_output = self._step_fn()
[rank16]:                   ^^^^^^^^^^^^^^^
[rank16]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank16]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank16]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank16]:     output = fn(*args, **kwargs)
[rank1]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank1]:     return forward_call(*args, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank1]:     output = func(self, *args, **kwargs)
[rank1]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 549, in forward
[rank1]:     layer_outputs = decoder_layer(
[rank1]:                     ^^^^^^^^^^^^^^
[rank1]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank4]:            ^^^^^^^
[rank4]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank4]:     result = forward_call(*args, **kwargs)
[rank4]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank4]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 259, in forward
[rank4]:     hidden_states = self.input_layernorm(hidden_states)
[rank4]:                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank4]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank4]:     return self._call_impl(*args, **kwargs)
[rank4]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank46]: Traceback (most recent call last):
[rank46]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 528, in <module>
[rank46]:     main()
[rank46]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 498, in main
[rank46]:     llm.api.finetune(
[rank46]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank46]:     return train(
[rank46]:            ^^^^^^
[rank46]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank46]:     trainer.fit(model, data)
[rank46]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank46]:     call._call_and_handle_interrupt(
[rank55]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 167, in _call_lightning_module_hook
[rank55]:     output = fn(*args, **kwargs)
[rank55]:              ^^^^^^^^^^^^^^^^^^^
[rank16]:              ^^^^^^^^^^^^^^^^^^^
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank1]:     return inner()
[rank4]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank4]:     return forward_call(*args, **kwargs)
[rank4]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank4]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 223, in forward
[rank4]:     variance = hidden_states.pow(2).mean(-1, keepdim=True)
[rank4]:                ^^^^^^^^^^^^^^^^^^^^
[rank55]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/module.py", line 1306, in optimizer_step
[rank55]:     optimizer.step(closure=optimizer_closure)
[rank55]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py", line 153, in step
[rank55]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank55]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank55]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py", line 238, in optimizer_step
[rank55]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank55]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank16]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank16]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank16]:     outputs = self.forward(batch)
[rank16]:               ^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank16]:     return self.model(**batch)
[rank16]:            ^^^^^^^^^^^^^^^^^^^
[rank1]:            ^^^^^^^
[rank1]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank1]:     result = forward_call(*args, **kwargs)
[rank1]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 259, in forward
[rank1]:     hidden_states = self.input_layernorm(hidden_states)
[rank1]:                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank4]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 640.00 MiB. GPU 0 has a total capacity of 79.19 GiB of which 399.81 MiB is free. Including non-PyTorch memory, this process has 78.79 GiB memory in use. Of the allocated memory 74.80 GiB is allocated by PyTorch, and 1.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank46]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank46]:     return trainer_fn(*args, **kwargs)
[rank46]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank46]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank46]:     self._run(model, ckpt_path=ckpt_path)
[rank46]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank46]:     results = self._run_stage()
[rank46]:               ^^^^^^^^^^^^^^^^^
[rank46]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank46]:     self.fit_loop.run()
[rank55]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/amp.py", line 75, in optimizer_step
[rank55]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank55]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank55]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 122, in optimizer_step
[rank55]:     return optimizer.step(closure=closure, **kwargs)
[rank55]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank55]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/optim/optimizer.py", line 516, in wrapper
[rank55]:     out = func(*args, **kwargs)
[rank55]:           ^^^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank16]:     return self._call_impl(*args, **kwargs)
[rank16]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank16]:     return inner()
[rank16]:            ^^^^^^^
[rank16]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank16]:     result = forward_call(*args, **kwargs)
[rank16]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank16]:     output = func(self, *args, **kwargs)
[rank1]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank1]:     return forward_call(*args, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 223, in forward
[rank1]:     variance = hidden_states.pow(2).mean(-1, keepdim=True)
[rank1]:                ^^^^^^^^^^^^^^^^^^^^
[rank46]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank46]:     self.advance()
[rank46]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank46]:     self.epoch_loop.run(self._data_fetcher)
[rank46]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank46]:     self.advance(data_fetcher)
[rank46]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank46]:     super().advance(data_fetcher)
[rank55]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformer_engine/pytorch/optimizers/fused_adam.py", line 486, in step
[rank55]:     loss = closure()
[rank55]:            ^^^^^^^^^
[rank55]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 108, in _wrap_closure
[rank55]:     closure_result = closure()
[rank55]:                      ^^^^^^^^^
[rank55]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank55]:     self._result = self.closure(*args, **kwargs)
[rank55]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank55]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank16]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank16]:     return func(*args, **kwargs)
[rank16]:            ^^^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank16]:     outputs: BaseModelOutputWithPast = self.model(
[rank16]:                                        ^^^^^^^^^^^
[rank16]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank16]:     return self._call_impl(*args, **kwargs)
[rank16]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 640.00 MiB. GPU 1 has a total capacity of 79.19 GiB of which 447.81 MiB is free. Including non-PyTorch memory, this process has 78.74 GiB memory in use. Of the allocated memory 74.80 GiB is allocated by PyTorch, and 1.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank46]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank46]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank46]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank46]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 190, in run
[rank46]:     self._optimizer_step(batch_idx, closure)
[rank46]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank46]:     call._call_lightning_module_hook(
[rank55]:     return func(*args, **kwargs)
[rank55]:            ^^^^^^^^^^^^^^^^^^^^^
[rank55]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank55]:     step_output = self._step_fn()
[rank55]:                   ^^^^^^^^^^^^^^^
[rank55]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank55]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank55]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank55]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank55]:     output = fn(*args, **kwargs)
[rank16]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank16]:     return forward_call(*args, **kwargs)
[rank16]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank16]:     output = func(self, *args, **kwargs)
[rank16]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 549, in forward
[rank16]:     layer_outputs = decoder_layer(
[rank16]:                     ^^^^^^^^^^^^^^
[rank16]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank46]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 167, in _call_lightning_module_hook
[rank46]:     output = fn(*args, **kwargs)
[rank46]:              ^^^^^^^^^^^^^^^^^^^
[rank55]:              ^^^^^^^^^^^^^^^^^^^
[rank16]:     return self._call_impl(*args, **kwargs)
[rank16]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank46]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/module.py", line 1306, in optimizer_step
[rank46]:     optimizer.step(closure=optimizer_closure)
[rank46]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py", line 153, in step
[rank46]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank46]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank46]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py", line 238, in optimizer_step
[rank46]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank46]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank55]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank55]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank55]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank55]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank55]:     outputs = self.forward(batch)
[rank55]:               ^^^^^^^^^^^^^^^^^^^
[rank55]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank55]:     return self.model(**batch)
[rank55]:            ^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank16]:     return inner()
[rank16]:            ^^^^^^^
[rank16]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank16]:     result = forward_call(*args, **kwargs)
[rank16]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 259, in forward
[rank16]:     hidden_states = self.input_layernorm(hidden_states)
[rank16]:                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank40]: Traceback (most recent call last):
[rank40]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 528, in <module>
[rank40]:     main()
[rank40]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 498, in main
[rank40]:     llm.api.finetune(
[rank40]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank40]:     return train(
[rank40]:            ^^^^^^
[rank40]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank40]:     trainer.fit(model, data)
[rank40]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank40]:     call._call_and_handle_interrupt(
[rank46]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/amp.py", line 75, in optimizer_step
[rank46]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank46]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank46]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 122, in optimizer_step
[rank46]:     return optimizer.step(closure=closure, **kwargs)
[rank46]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank46]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/optim/optimizer.py", line 516, in wrapper
[rank46]:     out = func(*args, **kwargs)
[rank46]:           ^^^^^^^^^^^^^^^^^^^^^
[rank55]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank55]:     return self._call_impl(*args, **kwargs)
[rank55]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank55]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank55]:     return inner()
[rank55]:            ^^^^^^^
[rank55]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank55]:     result = forward_call(*args, **kwargs)
[rank55]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank55]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank55]:     output = func(self, *args, **kwargs)
[rank16]:     return self._call_impl(*args, **kwargs)
[rank16]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank16]:     return forward_call(*args, **kwargs)
[rank16]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 223, in forward
[rank16]:     variance = hidden_states.pow(2).mean(-1, keepdim=True)
[rank16]:                ^^^^^^^^^^^^^^^^^^^^
[rank46]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformer_engine/pytorch/optimizers/fused_adam.py", line 486, in step
[rank46]:     loss = closure()
[rank46]:            ^^^^^^^^^
[rank46]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 108, in _wrap_closure
[rank46]:     closure_result = closure()
[rank46]:                      ^^^^^^^^^
[rank46]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank46]:     self._result = self.closure(*args, **kwargs)
[rank46]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank46]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank55]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank55]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank55]:     return func(*args, **kwargs)
[rank55]:            ^^^^^^^^^^^^^^^^^^^^^
[rank55]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank55]:     outputs: BaseModelOutputWithPast = self.model(
[rank55]:                                        ^^^^^^^^^^^
[rank55]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank55]:     return self._call_impl(*args, **kwargs)
[rank55]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank16]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 640.00 MiB. GPU 0 has a total capacity of 79.19 GiB of which 399.81 MiB is free. Including non-PyTorch memory, this process has 78.79 GiB memory in use. Of the allocated memory 74.80 GiB is allocated by PyTorch, and 1.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank46]:     return func(*args, **kwargs)
[rank46]:            ^^^^^^^^^^^^^^^^^^^^^
[rank46]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank46]:     step_output = self._step_fn()
[rank46]:                   ^^^^^^^^^^^^^^^
[rank46]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank46]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank46]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank46]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank46]:     output = fn(*args, **kwargs)
[rank55]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank55]:     return forward_call(*args, **kwargs)
[rank55]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank55]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank55]:     output = func(self, *args, **kwargs)
[rank55]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank55]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 549, in forward
[rank55]:     layer_outputs = decoder_layer(
[rank55]:                     ^^^^^^^^^^^^^^
[rank55]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank46]:              ^^^^^^^^^^^^^^^^^^^
[rank55]:     return self._call_impl(*args, **kwargs)
[rank55]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank46]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank46]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank46]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank46]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank46]:     outputs = self.forward(batch)
[rank46]:               ^^^^^^^^^^^^^^^^^^^
[rank46]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank46]:     return self.model(**batch)
[rank46]:            ^^^^^^^^^^^^^^^^^^^
[rank55]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank55]:     return inner()
[rank55]:            ^^^^^^^
[rank55]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank55]:     result = forward_call(*args, **kwargs)
[rank55]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank55]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 259, in forward
[rank55]:     hidden_states = self.input_layernorm(hidden_states)
[rank55]:                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank55]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank46]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank46]:     return self._call_impl(*args, **kwargs)
[rank46]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank46]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank46]:     return inner()
[rank46]:            ^^^^^^^
[rank46]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank46]:     result = forward_call(*args, **kwargs)
[rank46]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank46]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank46]:     output = func(self, *args, **kwargs)
[rank55]:     return self._call_impl(*args, **kwargs)
[rank55]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank55]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank55]:     return forward_call(*args, **kwargs)
[rank55]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank55]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 223, in forward
[rank55]:     variance = hidden_states.pow(2).mean(-1, keepdim=True)
[rank55]:                ^^^^^^^^^^^^^^^^^^^^
[rank40]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank40]:     return trainer_fn(*args, **kwargs)
[rank40]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank40]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank40]:     self._run(model, ckpt_path=ckpt_path)
[rank40]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank40]:     results = self._run_stage()
[rank40]:               ^^^^^^^^^^^^^^^^^
[rank40]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank40]:     self.fit_loop.run()
[rank46]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank46]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank46]:     return func(*args, **kwargs)
[rank46]:            ^^^^^^^^^^^^^^^^^^^^^
[rank46]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank46]:     outputs: BaseModelOutputWithPast = self.model(
[rank46]:                                        ^^^^^^^^^^^
[rank46]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank46]:     return self._call_impl(*args, **kwargs)
[rank46]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank55]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 640.00 MiB. GPU 3 has a total capacity of 79.19 GiB of which 411.81 MiB is free. Including non-PyTorch memory, this process has 78.78 GiB memory in use. Of the allocated memory 74.80 GiB is allocated by PyTorch, and 1.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank40]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank40]:     self.advance()
[rank40]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank40]:     self.epoch_loop.run(self._data_fetcher)
[rank40]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank40]:     self.advance(data_fetcher)
[rank40]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank40]:     super().advance(data_fetcher)
[rank46]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank46]:     return forward_call(*args, **kwargs)
[rank46]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank46]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank46]:     output = func(self, *args, **kwargs)
[rank46]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank46]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 549, in forward
[rank46]:     layer_outputs = decoder_layer(
[rank46]:                     ^^^^^^^^^^^^^^
[rank46]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank40]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank40]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank40]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank40]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 190, in run
[rank40]:     self._optimizer_step(batch_idx, closure)
[rank40]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank40]:     call._call_lightning_module_hook(
[rank46]:     return self._call_impl(*args, **kwargs)
[rank46]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank40]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 167, in _call_lightning_module_hook
[rank40]:     output = fn(*args, **kwargs)
[rank40]:              ^^^^^^^^^^^^^^^^^^^
[rank46]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank46]:     return inner()
[rank46]:            ^^^^^^^
[rank46]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank46]:     result = forward_call(*args, **kwargs)
[rank46]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank46]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 259, in forward
[rank46]:     hidden_states = self.input_layernorm(hidden_states)
[rank46]:                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank46]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank40]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/module.py", line 1306, in optimizer_step
[rank40]:     optimizer.step(closure=optimizer_closure)
[rank40]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py", line 153, in step
[rank40]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank40]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank40]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py", line 238, in optimizer_step
[rank40]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank40]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank46]:     return self._call_impl(*args, **kwargs)
[rank46]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank46]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank46]:     return forward_call(*args, **kwargs)
[rank46]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank46]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 223, in forward
[rank46]:     variance = hidden_states.pow(2).mean(-1, keepdim=True)
[rank46]:                ^^^^^^^^^^^^^^^^^^^^
[rank40]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/amp.py", line 75, in optimizer_step
[rank40]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank40]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank40]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 122, in optimizer_step
[rank40]:     return optimizer.step(closure=closure, **kwargs)
[rank40]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank40]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/optim/optimizer.py", line 516, in wrapper
[rank40]:     out = func(*args, **kwargs)
[rank40]:           ^^^^^^^^^^^^^^^^^^^^^
[rank46]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 640.00 MiB. GPU 2 has a total capacity of 79.19 GiB of which 395.81 MiB is free. Including non-PyTorch memory, this process has 78.79 GiB memory in use. Of the allocated memory 74.80 GiB is allocated by PyTorch, and 1.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank40]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformer_engine/pytorch/optimizers/fused_adam.py", line 486, in step
[rank40]:     loss = closure()
[rank40]:            ^^^^^^^^^
[rank40]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 108, in _wrap_closure
[rank40]:     closure_result = closure()
[rank40]:                      ^^^^^^^^^
[rank40]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank40]:     self._result = self.closure(*args, **kwargs)
[rank40]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank40]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank40]:     return func(*args, **kwargs)
[rank40]:            ^^^^^^^^^^^^^^^^^^^^^
[rank40]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank40]:     step_output = self._step_fn()
[rank40]:                   ^^^^^^^^^^^^^^^
[rank40]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank40]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank40]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank40]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank40]:     output = fn(*args, **kwargs)
[rank3]: Traceback (most recent call last):
[rank3]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 528, in <module>
[rank3]:     main()
[rank3]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 498, in main
[rank3]:     llm.api.finetune(
[rank3]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank3]:     return train(
[rank3]:            ^^^^^^
[rank3]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank3]:     trainer.fit(model, data)
[rank3]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank3]:     call._call_and_handle_interrupt(
[rank40]:              ^^^^^^^^^^^^^^^^^^^
[rank40]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank40]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank40]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank40]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank40]:     outputs = self.forward(batch)
[rank40]:               ^^^^^^^^^^^^^^^^^^^
[rank40]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank40]:     return self.model(**batch)
[rank40]:            ^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank3]:     return trainer_fn(*args, **kwargs)
[rank3]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank3]:     self._run(model, ckpt_path=ckpt_path)
[rank3]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank3]:     results = self._run_stage()
[rank3]:               ^^^^^^^^^^^^^^^^^
[rank3]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank3]:     self.fit_loop.run()
[rank40]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank40]:     return self._call_impl(*args, **kwargs)
[rank40]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank40]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank40]:     return inner()
[rank40]:            ^^^^^^^
[rank40]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank40]:     result = forward_call(*args, **kwargs)
[rank40]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank40]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank40]:     output = func(self, *args, **kwargs)
[rank3]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank3]:     self.advance()
[rank3]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank3]:     self.epoch_loop.run(self._data_fetcher)
[rank3]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank3]:     self.advance(data_fetcher)
[rank3]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank3]:     super().advance(data_fetcher)
[rank40]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank40]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank40]:     return func(*args, **kwargs)
[rank40]:            ^^^^^^^^^^^^^^^^^^^^^
[rank40]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank40]:     outputs: BaseModelOutputWithPast = self.model(
[rank40]:                                        ^^^^^^^^^^^
[rank40]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank40]:     return self._call_impl(*args, **kwargs)
[rank40]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank38]: Traceback (most recent call last):
[rank38]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 528, in <module>
[rank38]:     main()
[rank38]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 498, in main
[rank38]:     llm.api.finetune(
[rank38]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank38]:     return train(
[rank38]:            ^^^^^^
[rank38]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank38]:     trainer.fit(model, data)
[rank38]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank38]:     call._call_and_handle_interrupt(
[rank3]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank3]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank3]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 190, in run
[rank3]:     self._optimizer_step(batch_idx, closure)
[rank3]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank3]:     call._call_lightning_module_hook(
[rank40]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank40]:     return forward_call(*args, **kwargs)
[rank40]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank40]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank40]:     output = func(self, *args, **kwargs)
[rank40]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank40]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 549, in forward
[rank40]:     layer_outputs = decoder_layer(
[rank40]:                     ^^^^^^^^^^^^^^
[rank40]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank38]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank38]:     return trainer_fn(*args, **kwargs)
[rank38]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank38]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank38]:     self._run(model, ckpt_path=ckpt_path)
[rank38]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank38]:     results = self._run_stage()
[rank38]:               ^^^^^^^^^^^^^^^^^
[rank38]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank38]:     self.fit_loop.run()
[rank3]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 167, in _call_lightning_module_hook
[rank3]:     output = fn(*args, **kwargs)
[rank3]:              ^^^^^^^^^^^^^^^^^^^
[rank40]:     return self._call_impl(*args, **kwargs)
[rank40]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank38]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank38]:     self.advance()
[rank38]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank38]:     self.epoch_loop.run(self._data_fetcher)
[rank38]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank38]:     self.advance(data_fetcher)
[rank38]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank38]:     super().advance(data_fetcher)
[rank3]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/module.py", line 1306, in optimizer_step
[rank3]:     optimizer.step(closure=optimizer_closure)
[rank3]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py", line 153, in step
[rank3]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank3]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py", line 238, in optimizer_step
[rank3]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank3]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank40]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank40]:     return inner()
[rank40]:            ^^^^^^^
[rank40]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank40]:     result = forward_call(*args, **kwargs)
[rank40]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank40]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 259, in forward
[rank40]:     hidden_states = self.input_layernorm(hidden_states)
[rank40]:                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank40]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank38]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank38]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank38]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank38]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 190, in run
[rank38]:     self._optimizer_step(batch_idx, closure)
[rank38]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank38]:     call._call_lightning_module_hook(
[rank3]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/amp.py", line 75, in optimizer_step
[rank3]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank3]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 122, in optimizer_step
[rank3]:     return optimizer.step(closure=closure, **kwargs)
[rank3]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/optim/optimizer.py", line 516, in wrapper
[rank3]:     out = func(*args, **kwargs)
[rank3]:           ^^^^^^^^^^^^^^^^^^^^^
[rank40]:     return self._call_impl(*args, **kwargs)
[rank40]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank40]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank40]:     return forward_call(*args, **kwargs)
[rank40]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank40]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 223, in forward
[rank40]:     variance = hidden_states.pow(2).mean(-1, keepdim=True)
[rank40]:                ^^^^^^^^^^^^^^^^^^^^
[rank38]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 167, in _call_lightning_module_hook
[rank38]:     output = fn(*args, **kwargs)
[rank38]:              ^^^^^^^^^^^^^^^^^^^
[rank23]: Traceback (most recent call last):
[rank23]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 528, in <module>
[rank23]:     main()
[rank23]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 498, in main
[rank23]:     llm.api.finetune(
[rank23]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank23]:     return train(
[rank23]:            ^^^^^^
[rank23]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank23]:     trainer.fit(model, data)
[rank23]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank23]:     call._call_and_handle_interrupt(
[rank3]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformer_engine/pytorch/optimizers/fused_adam.py", line 486, in step
[rank3]:     loss = closure()
[rank3]:            ^^^^^^^^^
[rank3]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 108, in _wrap_closure
[rank3]:     closure_result = closure()
[rank3]:                      ^^^^^^^^^
[rank3]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank3]:     self._result = self.closure(*args, **kwargs)
[rank3]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank40]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 640.00 MiB. GPU 0 has a total capacity of 79.19 GiB of which 399.81 MiB is free. Including non-PyTorch memory, this process has 78.79 GiB memory in use. Of the allocated memory 74.80 GiB is allocated by PyTorch, and 1.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank38]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/module.py", line 1306, in optimizer_step
[rank38]:     optimizer.step(closure=optimizer_closure)
[rank38]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py", line 153, in step
[rank38]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank38]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank38]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py", line 238, in optimizer_step
[rank38]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank38]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:     return func(*args, **kwargs)
[rank3]:            ^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank3]:     step_output = self._step_fn()
[rank3]:                   ^^^^^^^^^^^^^^^
[rank3]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank3]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank3]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank3]:     output = fn(*args, **kwargs)
[rank38]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/amp.py", line 75, in optimizer_step
[rank38]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank38]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank38]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 122, in optimizer_step
[rank38]:     return optimizer.step(closure=closure, **kwargs)
[rank38]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank38]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/optim/optimizer.py", line 516, in wrapper
[rank38]:     out = func(*args, **kwargs)
[rank38]:           ^^^^^^^^^^^^^^^^^^^^^
[rank3]:              ^^^^^^^^^^^^^^^^^^^
[rank38]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformer_engine/pytorch/optimizers/fused_adam.py", line 486, in step
[rank38]:     loss = closure()
[rank38]:            ^^^^^^^^^
[rank38]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 108, in _wrap_closure
[rank38]:     closure_result = closure()
[rank38]:                      ^^^^^^^^^
[rank38]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank38]:     self._result = self.closure(*args, **kwargs)
[rank38]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank38]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank3]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank3]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank3]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank3]:     outputs = self.forward(batch)
[rank3]:               ^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank3]:     return self.model(**batch)
[rank3]:            ^^^^^^^^^^^^^^^^^^^
[rank38]:     return func(*args, **kwargs)
[rank38]:            ^^^^^^^^^^^^^^^^^^^^^
[rank38]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank38]:     step_output = self._step_fn()
[rank38]:                   ^^^^^^^^^^^^^^^
[rank38]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank38]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank38]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank38]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank38]:     output = fn(*args, **kwargs)
[rank3]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank3]:     return self._call_impl(*args, **kwargs)
[rank3]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank3]:     return inner()
[rank3]:            ^^^^^^^
[rank3]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank3]:     result = forward_call(*args, **kwargs)
[rank3]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank3]:     output = func(self, *args, **kwargs)
[rank38]:              ^^^^^^^^^^^^^^^^^^^
[rank3]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank3]:     return func(*args, **kwargs)
[rank3]:            ^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank3]:     outputs: BaseModelOutputWithPast = self.model(
[rank3]:                                        ^^^^^^^^^^^
[rank3]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank3]:     return self._call_impl(*args, **kwargs)
[rank3]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank38]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank38]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank38]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank38]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank38]:     outputs = self.forward(batch)
[rank38]:               ^^^^^^^^^^^^^^^^^^^
[rank38]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank38]:     return self.model(**batch)
[rank38]:            ^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank3]:     return forward_call(*args, **kwargs)
[rank3]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank3]:     output = func(self, *args, **kwargs)
[rank3]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 549, in forward
[rank3]:     layer_outputs = decoder_layer(
[rank3]:                     ^^^^^^^^^^^^^^
[rank3]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank38]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank38]:     return self._call_impl(*args, **kwargs)
[rank38]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank38]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank38]:     return inner()
[rank38]:            ^^^^^^^
[rank38]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank38]:     result = forward_call(*args, **kwargs)
[rank38]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank38]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank38]:     output = func(self, *args, **kwargs)
[rank3]:     return self._call_impl(*args, **kwargs)
[rank3]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank3]:     return inner()
[rank51]: Traceback (most recent call last):
[rank51]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 528, in <module>
[rank51]:     main()
[rank51]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 498, in main
[rank51]:     llm.api.finetune(
[rank51]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank51]:     return train(
[rank51]:            ^^^^^^
[rank51]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank51]:     trainer.fit(model, data)
[rank51]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank51]:     call._call_and_handle_interrupt(
[rank38]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank38]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank38]:     return func(*args, **kwargs)
[rank38]:            ^^^^^^^^^^^^^^^^^^^^^
[rank38]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank38]:     outputs: BaseModelOutputWithPast = self.model(
[rank38]:                                        ^^^^^^^^^^^
[rank38]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank38]:     return self._call_impl(*args, **kwargs)
[rank38]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank23]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank23]:     return trainer_fn(*args, **kwargs)
[rank23]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank23]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank23]:     self._run(model, ckpt_path=ckpt_path)
[rank23]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank23]:     results = self._run_stage()
[rank23]:               ^^^^^^^^^^^^^^^^^
[rank23]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank23]:     self.fit_loop.run()
[rank3]:            ^^^^^^^
[rank3]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank3]:     result = forward_call(*args, **kwargs)
[rank3]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 259, in forward
[rank3]:     hidden_states = self.input_layernorm(hidden_states)
[rank3]:                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank3]:     return self._call_impl(*args, **kwargs)
[rank3]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank51]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank51]:     return trainer_fn(*args, **kwargs)
[rank51]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank51]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank51]:     self._run(model, ckpt_path=ckpt_path)
[rank51]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank51]:     results = self._run_stage()
[rank51]:               ^^^^^^^^^^^^^^^^^
[rank51]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank51]:     self.fit_loop.run()
[rank38]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank38]:     return forward_call(*args, **kwargs)
[rank38]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank38]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank38]:     output = func(self, *args, **kwargs)
[rank38]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank38]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 549, in forward
[rank38]:     layer_outputs = decoder_layer(
[rank38]:                     ^^^^^^^^^^^^^^
[rank38]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank23]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank23]:     self.advance()
[rank23]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank23]:     self.epoch_loop.run(self._data_fetcher)
[rank23]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank23]:     self.advance(data_fetcher)
[rank23]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank23]:     super().advance(data_fetcher)
[rank3]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank3]:     return forward_call(*args, **kwargs)
[rank3]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 223, in forward
[rank3]:     variance = hidden_states.pow(2).mean(-1, keepdim=True)
[rank3]:                ^^^^^^^^^^^^^^^^^^^^
[rank51]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank51]:     self.advance()
[rank51]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank51]:     self.epoch_loop.run(self._data_fetcher)
[rank51]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank51]:     self.advance(data_fetcher)
[rank51]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank51]:     super().advance(data_fetcher)
[rank38]:     return self._call_impl(*args, **kwargs)
[rank38]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank23]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank23]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank23]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank23]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 190, in run
[rank23]:     self._optimizer_step(batch_idx, closure)
[rank23]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank23]:     call._call_lightning_module_hook(
[rank3]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 640.00 MiB. GPU 3 has a total capacity of 79.19 GiB of which 491.81 MiB is free. Including non-PyTorch memory, this process has 78.70 GiB memory in use. Of the allocated memory 74.80 GiB is allocated by PyTorch, and 1.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank51]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank51]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank51]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank51]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 190, in run
[rank51]:     self._optimizer_step(batch_idx, closure)
[rank51]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank51]:     call._call_lightning_module_hook(
[rank38]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank38]:     return inner()
[rank38]:            ^^^^^^^
[rank38]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank38]:     result = forward_call(*args, **kwargs)
[rank38]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank38]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 259, in forward
[rank38]:     hidden_states = self.input_layernorm(hidden_states)
[rank38]:                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank38]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank23]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 167, in _call_lightning_module_hook
[rank23]:     output = fn(*args, **kwargs)
[rank23]:              ^^^^^^^^^^^^^^^^^^^
[rank51]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 167, in _call_lightning_module_hook
[rank51]:     output = fn(*args, **kwargs)
[rank51]:              ^^^^^^^^^^^^^^^^^^^
[rank38]:     return self._call_impl(*args, **kwargs)
[rank38]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank38]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank38]:     return forward_call(*args, **kwargs)
[rank38]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank38]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 223, in forward
[rank38]:     variance = hidden_states.pow(2).mean(-1, keepdim=True)
[rank38]:                ^^^^^^^^^^^^^^^^^^^^
[rank23]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/module.py", line 1306, in optimizer_step
[rank23]:     optimizer.step(closure=optimizer_closure)
[rank23]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py", line 153, in step
[rank23]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank23]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank23]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py", line 238, in optimizer_step
[rank23]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank23]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank7]: Traceback (most recent call last):
[rank7]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 528, in <module>
[rank7]:     main()
[rank7]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 498, in main
[rank7]:     llm.api.finetune(
[rank7]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank7]:     return train(
[rank7]:            ^^^^^^
[rank7]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank7]:     trainer.fit(model, data)
[rank7]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank7]:     call._call_and_handle_interrupt(
[rank51]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/module.py", line 1306, in optimizer_step
[rank51]:     optimizer.step(closure=optimizer_closure)
[rank51]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py", line 153, in step
[rank51]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank51]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank51]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py", line 238, in optimizer_step
[rank51]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank51]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank38]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 640.00 MiB. GPU 2 has a total capacity of 79.19 GiB of which 395.81 MiB is free. Including non-PyTorch memory, this process has 78.79 GiB memory in use. Of the allocated memory 74.80 GiB is allocated by PyTorch, and 1.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank23]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/amp.py", line 75, in optimizer_step
[rank23]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank23]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank23]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 122, in optimizer_step
[rank23]:     return optimizer.step(closure=closure, **kwargs)
[rank23]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank23]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/optim/optimizer.py", line 516, in wrapper
[rank23]:     out = func(*args, **kwargs)
[rank23]:           ^^^^^^^^^^^^^^^^^^^^^
[rank51]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/amp.py", line 75, in optimizer_step
[rank51]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank51]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank51]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 122, in optimizer_step
[rank51]:     return optimizer.step(closure=closure, **kwargs)
[rank51]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank51]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/optim/optimizer.py", line 516, in wrapper
[rank51]:     out = func(*args, **kwargs)
[rank51]:           ^^^^^^^^^^^^^^^^^^^^^
[rank23]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformer_engine/pytorch/optimizers/fused_adam.py", line 486, in step
[rank23]:     loss = closure()
[rank23]:            ^^^^^^^^^
[rank23]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 108, in _wrap_closure
[rank23]:     closure_result = closure()
[rank23]:                      ^^^^^^^^^
[rank23]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank23]:     self._result = self.closure(*args, **kwargs)
[rank23]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank23]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank7]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank7]:     return trainer_fn(*args, **kwargs)
[rank7]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank7]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank7]:     self._run(model, ckpt_path=ckpt_path)
[rank7]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank7]:     results = self._run_stage()
[rank7]:               ^^^^^^^^^^^^^^^^^
[rank7]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank7]:     self.fit_loop.run()
[rank51]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformer_engine/pytorch/optimizers/fused_adam.py", line 486, in step
[rank51]:     loss = closure()
[rank51]:            ^^^^^^^^^
[rank51]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 108, in _wrap_closure
[rank51]:     closure_result = closure()
[rank51]:                      ^^^^^^^^^
[rank51]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank51]:     self._result = self.closure(*args, **kwargs)
[rank51]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank51]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank23]:     return func(*args, **kwargs)
[rank23]:            ^^^^^^^^^^^^^^^^^^^^^
[rank23]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank23]:     step_output = self._step_fn()
[rank23]:                   ^^^^^^^^^^^^^^^
[rank23]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank23]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank23]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank23]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank23]:     output = fn(*args, **kwargs)
[rank7]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank7]:     self.advance()
[rank7]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank7]:     self.epoch_loop.run(self._data_fetcher)
[rank7]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank7]:     self.advance(data_fetcher)
[rank7]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank7]:     super().advance(data_fetcher)
[rank51]:     return func(*args, **kwargs)
[rank51]:            ^^^^^^^^^^^^^^^^^^^^^
[rank51]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank51]:     step_output = self._step_fn()
[rank51]:                   ^^^^^^^^^^^^^^^
[rank51]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank51]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank51]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank51]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank51]:     output = fn(*args, **kwargs)
[rank23]:              ^^^^^^^^^^^^^^^^^^^
[rank7]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank7]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank7]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank7]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 190, in run
[rank7]:     self._optimizer_step(batch_idx, closure)
[rank7]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank7]:     call._call_lightning_module_hook(
[rank51]:              ^^^^^^^^^^^^^^^^^^^
[rank23]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank23]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank23]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank23]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank23]:     outputs = self.forward(batch)
[rank23]:               ^^^^^^^^^^^^^^^^^^^
[rank23]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank23]:     return self.model(**batch)
[rank23]:            ^^^^^^^^^^^^^^^^^^^
[rank7]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 167, in _call_lightning_module_hook
[rank7]:     output = fn(*args, **kwargs)
[rank7]:              ^^^^^^^^^^^^^^^^^^^
[rank51]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank51]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank51]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank51]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank51]:     outputs = self.forward(batch)
[rank51]:               ^^^^^^^^^^^^^^^^^^^
[rank51]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank51]:     return self.model(**batch)
[rank51]:            ^^^^^^^^^^^^^^^^^^^
[rank23]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank23]:     return self._call_impl(*args, **kwargs)
[rank23]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank23]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank23]:     return inner()
[rank23]:            ^^^^^^^
[rank23]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank23]:     result = forward_call(*args, **kwargs)
[rank23]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank23]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank23]:     output = func(self, *args, **kwargs)
[rank7]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/module.py", line 1306, in optimizer_step
[rank7]:     optimizer.step(closure=optimizer_closure)
[rank7]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py", line 153, in step
[rank7]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank7]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank7]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py", line 238, in optimizer_step
[rank7]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank7]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank51]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank51]:     return self._call_impl(*args, **kwargs)
[rank51]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank51]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank51]:     return inner()
[rank51]:            ^^^^^^^
[rank51]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank51]:     result = forward_call(*args, **kwargs)
[rank51]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank51]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank51]:     output = func(self, *args, **kwargs)
[rank23]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank23]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank23]:     return func(*args, **kwargs)
[rank23]:            ^^^^^^^^^^^^^^^^^^^^^
[rank23]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank23]:     outputs: BaseModelOutputWithPast = self.model(
[rank23]:                                        ^^^^^^^^^^^
[rank23]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank23]:     return self._call_impl(*args, **kwargs)
[rank23]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank7]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/amp.py", line 75, in optimizer_step
[rank7]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank7]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank7]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 122, in optimizer_step
[rank7]:     return optimizer.step(closure=closure, **kwargs)
[rank7]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank7]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/optim/optimizer.py", line 516, in wrapper
[rank7]:     out = func(*args, **kwargs)
[rank7]:           ^^^^^^^^^^^^^^^^^^^^^
[rank51]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank51]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank51]:     return func(*args, **kwargs)
[rank51]:            ^^^^^^^^^^^^^^^^^^^^^
[rank51]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank51]:     outputs: BaseModelOutputWithPast = self.model(
[rank51]:                                        ^^^^^^^^^^^
[rank51]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank51]:     return self._call_impl(*args, **kwargs)
[rank51]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank23]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank23]:     return forward_call(*args, **kwargs)
[rank23]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank23]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank23]:     output = func(self, *args, **kwargs)
[rank23]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank23]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 549, in forward
[rank23]:     layer_outputs = decoder_layer(
[rank23]:                     ^^^^^^^^^^^^^^
[rank23]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank7]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformer_engine/pytorch/optimizers/fused_adam.py", line 486, in step
[rank7]:     loss = closure()
[rank7]:            ^^^^^^^^^
[rank7]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 108, in _wrap_closure
[rank7]:     closure_result = closure()
[rank7]:                      ^^^^^^^^^
[rank7]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank7]:     self._result = self.closure(*args, **kwargs)
[rank7]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank7]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank51]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank51]:     return forward_call(*args, **kwargs)
[rank51]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank51]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank51]:     output = func(self, *args, **kwargs)
[rank51]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank51]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 549, in forward
[rank51]:     layer_outputs = decoder_layer(
[rank51]:                     ^^^^^^^^^^^^^^
[rank51]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank23]:     return self._call_impl(*args, **kwargs)
[rank23]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank7]:     return func(*args, **kwargs)
[rank7]:            ^^^^^^^^^^^^^^^^^^^^^
[rank7]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank7]:     step_output = self._step_fn()
[rank7]:                   ^^^^^^^^^^^^^^^
[rank7]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank7]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank7]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank7]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank7]:     output = fn(*args, **kwargs)
[rank51]:     return self._call_impl(*args, **kwargs)
[rank51]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank23]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank23]:     return inner()
[rank23]:            ^^^^^^^
[rank23]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank23]:     result = forward_call(*args, **kwargs)
[rank23]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank23]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 259, in forward
[rank23]:     hidden_states = self.input_layernorm(hidden_states)
[rank23]:                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank23]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank7]:              ^^^^^^^^^^^^^^^^^^^
[rank51]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank51]:     return inner()
[rank51]:            ^^^^^^^
[rank51]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank51]:     result = forward_call(*args, **kwargs)
[rank51]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank51]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 259, in forward
[rank51]:     hidden_states = self.input_layernorm(hidden_states)
[rank51]:                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank51]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank23]:     return self._call_impl(*args, **kwargs)
[rank23]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank23]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank23]:     return forward_call(*args, **kwargs)
[rank23]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank23]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 223, in forward
[rank23]:     variance = hidden_states.pow(2).mean(-1, keepdim=True)
[rank23]:                ^^^^^^^^^^^^^^^^^^^^
[rank7]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank7]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank7]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank7]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank7]:     outputs = self.forward(batch)
[rank7]:               ^^^^^^^^^^^^^^^^^^^
[rank7]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank7]:     return self.model(**batch)
[rank7]:            ^^^^^^^^^^^^^^^^^^^
[rank51]:     return self._call_impl(*args, **kwargs)
[rank51]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank51]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank51]:     return forward_call(*args, **kwargs)
[rank51]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank51]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 223, in forward
[rank51]:     variance = hidden_states.pow(2).mean(-1, keepdim=True)
[rank51]:                ^^^^^^^^^^^^^^^^^^^^
[rank23]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 640.00 MiB. GPU 3 has a total capacity of 79.19 GiB of which 411.81 MiB is free. Including non-PyTorch memory, this process has 78.78 GiB memory in use. Of the allocated memory 74.80 GiB is allocated by PyTorch, and 1.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank7]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank7]:     return self._call_impl(*args, **kwargs)
[rank7]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank7]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank7]:     return inner()
[rank7]:            ^^^^^^^
[rank7]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank7]:     result = forward_call(*args, **kwargs)
[rank7]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank7]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank7]:     output = func(self, *args, **kwargs)
[rank51]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 640.00 MiB. GPU 3 has a total capacity of 79.19 GiB of which 411.81 MiB is free. Including non-PyTorch memory, this process has 78.78 GiB memory in use. Of the allocated memory 74.80 GiB is allocated by PyTorch, and 1.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank7]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank7]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank7]:     return func(*args, **kwargs)
[rank7]:            ^^^^^^^^^^^^^^^^^^^^^
[rank7]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank7]:     outputs: BaseModelOutputWithPast = self.model(
[rank7]:                                        ^^^^^^^^^^^
[rank7]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank7]:     return self._call_impl(*args, **kwargs)
[rank7]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank7]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank7]:     return forward_call(*args, **kwargs)
[rank7]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank7]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank7]:     output = func(self, *args, **kwargs)
[rank7]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank7]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 549, in forward
[rank7]:     layer_outputs = decoder_layer(
[rank7]:                     ^^^^^^^^^^^^^^
[rank7]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank7]:     return self._call_impl(*args, **kwargs)
[rank7]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank7]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank7]:     return inner()
[rank7]:            ^^^^^^^
[rank7]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank7]:     result = forward_call(*args, **kwargs)
[rank7]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank7]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 259, in forward
[rank7]:     hidden_states = self.input_layernorm(hidden_states)
[rank7]:                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank7]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank7]:     return self._call_impl(*args, **kwargs)
[rank7]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank7]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank7]:     return forward_call(*args, **kwargs)
[rank7]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank7]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 223, in forward
[rank7]:     variance = hidden_states.pow(2).mean(-1, keepdim=True)
[rank7]:                ^^^^^^^^^^^^^^^^^^^^
[rank7]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 640.00 MiB. GPU 3 has a total capacity of 79.19 GiB of which 411.81 MiB is free. Including non-PyTorch memory, this process has 78.78 GiB memory in use. Of the allocated memory 74.80 GiB is allocated by PyTorch, and 1.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank20]: Traceback (most recent call last):
[rank20]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 528, in <module>
[rank20]:     main()
[rank20]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 498, in main
[rank20]:     llm.api.finetune(
[rank20]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank20]:     return train(
[rank20]:            ^^^^^^
[rank20]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank20]:     trainer.fit(model, data)
[rank20]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank20]:     call._call_and_handle_interrupt(
[rank37]: Traceback (most recent call last):
[rank37]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 528, in <module>
[rank37]:     main()
[rank37]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 498, in main
[rank37]:     llm.api.finetune(
[rank37]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank37]:     return train(
[rank37]:            ^^^^^^
[rank37]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank37]:     trainer.fit(model, data)
[rank37]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank37]:     call._call_and_handle_interrupt(
[rank20]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank20]:     return trainer_fn(*args, **kwargs)
[rank20]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank20]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank20]:     self._run(model, ckpt_path=ckpt_path)
[rank20]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank20]:     results = self._run_stage()
[rank20]:               ^^^^^^^^^^^^^^^^^
[rank20]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank20]:     self.fit_loop.run()
[rank20]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank20]:     self.advance()
[rank20]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank20]:     self.epoch_loop.run(self._data_fetcher)
[rank20]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank20]:     self.advance(data_fetcher)
[rank20]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank20]:     super().advance(data_fetcher)
[rank20]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank20]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank20]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank20]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 190, in run
[rank20]:     self._optimizer_step(batch_idx, closure)
[rank20]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank20]:     call._call_lightning_module_hook(
[rank20]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 167, in _call_lightning_module_hook
[rank20]:     output = fn(*args, **kwargs)
[rank20]:              ^^^^^^^^^^^^^^^^^^^
[rank20]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/module.py", line 1306, in optimizer_step
[rank20]:     optimizer.step(closure=optimizer_closure)
[rank20]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py", line 153, in step
[rank20]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank20]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank20]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py", line 238, in optimizer_step
[rank20]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank20]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank20]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/amp.py", line 75, in optimizer_step
[rank20]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank20]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank20]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 122, in optimizer_step
[rank20]:     return optimizer.step(closure=closure, **kwargs)
[rank20]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank20]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/optim/optimizer.py", line 516, in wrapper
[rank20]:     out = func(*args, **kwargs)
[rank20]:           ^^^^^^^^^^^^^^^^^^^^^
[rank20]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformer_engine/pytorch/optimizers/fused_adam.py", line 486, in step
[rank20]:     loss = closure()
[rank20]:            ^^^^^^^^^
[rank20]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 108, in _wrap_closure
[rank20]:     closure_result = closure()
[rank20]:                      ^^^^^^^^^
[rank20]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank20]:     self._result = self.closure(*args, **kwargs)
[rank20]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank20]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank20]:     return func(*args, **kwargs)
[rank20]:            ^^^^^^^^^^^^^^^^^^^^^
[rank20]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank20]:     step_output = self._step_fn()
[rank20]:                   ^^^^^^^^^^^^^^^
[rank20]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank20]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank20]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank20]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank20]:     output = fn(*args, **kwargs)
[rank37]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank37]:     return trainer_fn(*args, **kwargs)
[rank37]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank37]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank37]:     self._run(model, ckpt_path=ckpt_path)
[rank37]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank37]:     results = self._run_stage()
[rank37]:               ^^^^^^^^^^^^^^^^^
[rank37]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank37]:     self.fit_loop.run()
[rank20]:              ^^^^^^^^^^^^^^^^^^^
[rank54]: Traceback (most recent call last):
[rank54]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 528, in <module>
[rank54]:     main()
[rank54]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 498, in main
[rank54]:     llm.api.finetune(
[rank54]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank54]:     return train(
[rank54]:            ^^^^^^
[rank54]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank54]:     trainer.fit(model, data)
[rank54]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank54]:     call._call_and_handle_interrupt(
[rank37]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank37]:     self.advance()
[rank37]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank37]:     self.epoch_loop.run(self._data_fetcher)
[rank37]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank37]:     self.advance(data_fetcher)
[rank37]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank37]:     super().advance(data_fetcher)
[rank20]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank20]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank20]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank20]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank20]:     outputs = self.forward(batch)
[rank20]:               ^^^^^^^^^^^^^^^^^^^
[rank20]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank20]:     return self.model(**batch)
[rank20]:            ^^^^^^^^^^^^^^^^^^^
[rank37]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank37]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank37]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank37]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 190, in run
[rank37]:     self._optimizer_step(batch_idx, closure)
[rank37]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank37]:     call._call_lightning_module_hook(
[rank20]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank20]:     return self._call_impl(*args, **kwargs)
[rank20]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank20]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank20]:     return inner()
[rank20]:            ^^^^^^^
[rank20]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank20]:     result = forward_call(*args, **kwargs)
[rank20]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank20]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank20]:     output = func(self, *args, **kwargs)
[rank57]: Traceback (most recent call last):
[rank57]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 528, in <module>
[rank57]:     main()
[rank57]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 498, in main
[rank57]:     llm.api.finetune(
[rank57]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank57]:     return train(
[rank57]:            ^^^^^^
[rank57]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank57]:     trainer.fit(model, data)
[rank57]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank57]:     call._call_and_handle_interrupt(
[rank37]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 167, in _call_lightning_module_hook
[rank37]:     output = fn(*args, **kwargs)
[rank37]:              ^^^^^^^^^^^^^^^^^^^
[rank20]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank20]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank20]:     return func(*args, **kwargs)
[rank20]:            ^^^^^^^^^^^^^^^^^^^^^
[rank20]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank20]:     outputs: BaseModelOutputWithPast = self.model(
[rank20]:                                        ^^^^^^^^^^^
[rank20]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank20]:     return self._call_impl(*args, **kwargs)
[rank20]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank57]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank57]:     return trainer_fn(*args, **kwargs)
[rank57]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank57]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank57]:     self._run(model, ckpt_path=ckpt_path)
[rank57]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank57]:     results = self._run_stage()
[rank57]:               ^^^^^^^^^^^^^^^^^
[rank57]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank57]:     self.fit_loop.run()
[rank37]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/module.py", line 1306, in optimizer_step
[rank37]:     optimizer.step(closure=optimizer_closure)
[rank37]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py", line 153, in step
[rank37]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank37]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank37]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py", line 238, in optimizer_step
[rank37]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank37]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank20]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank20]:     return forward_call(*args, **kwargs)
[rank20]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank20]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank20]:     output = func(self, *args, **kwargs)
[rank20]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank20]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 549, in forward
[rank20]:     layer_outputs = decoder_layer(
[rank20]:                     ^^^^^^^^^^^^^^
[rank20]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank54]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank54]:     return trainer_fn(*args, **kwargs)
[rank54]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank54]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank54]:     self._run(model, ckpt_path=ckpt_path)
[rank54]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank54]:     results = self._run_stage()
[rank54]:               ^^^^^^^^^^^^^^^^^
[rank54]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank54]:     self.fit_loop.run()
[rank57]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank57]:     self.advance()
[rank57]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank57]:     self.epoch_loop.run(self._data_fetcher)
[rank57]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank57]:     self.advance(data_fetcher)
[rank57]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank57]:     super().advance(data_fetcher)
[rank37]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/amp.py", line 75, in optimizer_step
[rank37]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank37]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank37]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 122, in optimizer_step
[rank37]:     return optimizer.step(closure=closure, **kwargs)
[rank37]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank37]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/optim/optimizer.py", line 516, in wrapper
[rank37]:     out = func(*args, **kwargs)
[rank37]:           ^^^^^^^^^^^^^^^^^^^^^
[rank20]:     return self._call_impl(*args, **kwargs)
[rank20]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank54]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank54]:     self.advance()
[rank54]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank54]:     self.epoch_loop.run(self._data_fetcher)
[rank54]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank54]:     self.advance(data_fetcher)
[rank54]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank54]:     super().advance(data_fetcher)
[rank57]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank57]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank57]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank57]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 190, in run
[rank57]:     self._optimizer_step(batch_idx, closure)
[rank57]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank57]:     call._call_lightning_module_hook(
[rank37]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformer_engine/pytorch/optimizers/fused_adam.py", line 486, in step
[rank37]:     loss = closure()
[rank37]:            ^^^^^^^^^
[rank37]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 108, in _wrap_closure
[rank37]:     closure_result = closure()
[rank37]:                      ^^^^^^^^^
[rank37]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank37]:     self._result = self.closure(*args, **kwargs)
[rank37]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank37]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank20]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank20]:     return inner()
[rank20]:            ^^^^^^^
[rank20]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank20]:     result = forward_call(*args, **kwargs)
[rank20]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank20]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 259, in forward
[rank20]:     hidden_states = self.input_layernorm(hidden_states)
[rank20]:                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank20]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank54]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank54]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank54]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank54]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 190, in run
[rank54]:     self._optimizer_step(batch_idx, closure)
[rank54]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank54]:     call._call_lightning_module_hook(
[rank57]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 167, in _call_lightning_module_hook
[rank57]:     output = fn(*args, **kwargs)
[rank57]:              ^^^^^^^^^^^^^^^^^^^
[rank37]:     return func(*args, **kwargs)
[rank37]:            ^^^^^^^^^^^^^^^^^^^^^
[rank37]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank37]:     step_output = self._step_fn()
[rank37]:                   ^^^^^^^^^^^^^^^
[rank37]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank37]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank37]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank37]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank37]:     output = fn(*args, **kwargs)
[rank20]:     return self._call_impl(*args, **kwargs)
[rank20]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank20]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank20]:     return forward_call(*args, **kwargs)
[rank20]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank20]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 223, in forward
[rank20]:     variance = hidden_states.pow(2).mean(-1, keepdim=True)
[rank20]:                ^^^^^^^^^^^^^^^^^^^^
[rank54]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 167, in _call_lightning_module_hook
[rank54]:     output = fn(*args, **kwargs)
[rank54]:              ^^^^^^^^^^^^^^^^^^^
[rank57]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/module.py", line 1306, in optimizer_step
[rank57]:     optimizer.step(closure=optimizer_closure)
[rank57]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py", line 153, in step
[rank57]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank57]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank57]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py", line 238, in optimizer_step
[rank57]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank57]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank37]:              ^^^^^^^^^^^^^^^^^^^
[rank20]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 640.00 MiB. GPU 0 has a total capacity of 79.19 GiB of which 399.81 MiB is free. Including non-PyTorch memory, this process has 78.79 GiB memory in use. Of the allocated memory 74.80 GiB is allocated by PyTorch, and 1.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank54]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/module.py", line 1306, in optimizer_step
[rank54]:     optimizer.step(closure=optimizer_closure)
[rank54]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py", line 153, in step
[rank54]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank54]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank54]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py", line 238, in optimizer_step
[rank54]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank54]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank57]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/amp.py", line 75, in optimizer_step
[rank57]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank57]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank57]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 122, in optimizer_step
[rank57]:     return optimizer.step(closure=closure, **kwargs)
[rank57]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank57]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/optim/optimizer.py", line 516, in wrapper
[rank57]:     out = func(*args, **kwargs)
[rank57]:           ^^^^^^^^^^^^^^^^^^^^^
[rank37]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank37]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank37]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank37]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank37]:     outputs = self.forward(batch)
[rank37]:               ^^^^^^^^^^^^^^^^^^^
[rank37]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank37]:     return self.model(**batch)
[rank37]:            ^^^^^^^^^^^^^^^^^^^
[rank54]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/amp.py", line 75, in optimizer_step
[rank54]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank54]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank54]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 122, in optimizer_step
[rank54]:     return optimizer.step(closure=closure, **kwargs)
[rank54]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank54]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/optim/optimizer.py", line 516, in wrapper
[rank54]:     out = func(*args, **kwargs)
[rank54]:           ^^^^^^^^^^^^^^^^^^^^^
[rank57]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformer_engine/pytorch/optimizers/fused_adam.py", line 486, in step
[rank57]:     loss = closure()
[rank57]:            ^^^^^^^^^
[rank57]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 108, in _wrap_closure
[rank57]:     closure_result = closure()
[rank57]:                      ^^^^^^^^^
[rank57]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank57]:     self._result = self.closure(*args, **kwargs)
[rank57]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank57]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank50]: Traceback (most recent call last):
[rank50]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 528, in <module>
[rank50]:     main()
[rank50]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 498, in main
[rank50]:     llm.api.finetune(
[rank50]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank50]:     return train(
[rank50]:            ^^^^^^
[rank50]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank50]:     trainer.fit(model, data)
[rank50]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank50]:     call._call_and_handle_interrupt(
[rank37]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank37]:     return self._call_impl(*args, **kwargs)
[rank37]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank37]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank37]:     return inner()
[rank37]:            ^^^^^^^
[rank37]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank37]:     result = forward_call(*args, **kwargs)
[rank37]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank37]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank37]:     output = func(self, *args, **kwargs)
[rank54]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformer_engine/pytorch/optimizers/fused_adam.py", line 486, in step
[rank54]:     loss = closure()
[rank54]:            ^^^^^^^^^
[rank54]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 108, in _wrap_closure
[rank54]:     closure_result = closure()
[rank54]:                      ^^^^^^^^^
[rank54]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank54]:     self._result = self.closure(*args, **kwargs)
[rank54]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank54]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank57]:     return func(*args, **kwargs)
[rank57]:            ^^^^^^^^^^^^^^^^^^^^^
[rank57]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank57]:     step_output = self._step_fn()
[rank57]:                   ^^^^^^^^^^^^^^^
[rank57]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank57]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank57]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank57]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank57]:     output = fn(*args, **kwargs)
[rank50]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank50]:     return trainer_fn(*args, **kwargs)
[rank50]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank50]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank50]:     self._run(model, ckpt_path=ckpt_path)
[rank50]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank50]:     results = self._run_stage()
[rank50]:               ^^^^^^^^^^^^^^^^^
[rank50]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank50]:     self.fit_loop.run()
[rank37]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank37]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank37]:     return func(*args, **kwargs)
[rank37]:            ^^^^^^^^^^^^^^^^^^^^^
[rank37]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank37]:     outputs: BaseModelOutputWithPast = self.model(
[rank37]:                                        ^^^^^^^^^^^
[rank37]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank37]:     return self._call_impl(*args, **kwargs)
[rank37]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank54]:     return func(*args, **kwargs)
[rank54]:            ^^^^^^^^^^^^^^^^^^^^^
[rank54]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank54]:     step_output = self._step_fn()
[rank54]:                   ^^^^^^^^^^^^^^^
[rank54]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank54]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank54]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank54]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank54]:     output = fn(*args, **kwargs)
[rank18]: Traceback (most recent call last):
[rank18]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 528, in <module>
[rank18]:     main()
[rank18]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 498, in main
[rank18]:     llm.api.finetune(
[rank18]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank18]:     return train(
[rank18]:            ^^^^^^
[rank18]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank18]:     trainer.fit(model, data)
[rank18]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank18]:     call._call_and_handle_interrupt(
[rank57]:              ^^^^^^^^^^^^^^^^^^^
[rank50]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank50]:     self.advance()
[rank50]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank50]:     self.epoch_loop.run(self._data_fetcher)
[rank50]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank50]:     self.advance(data_fetcher)
[rank50]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank50]:     super().advance(data_fetcher)
[rank37]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank37]:     return forward_call(*args, **kwargs)
[rank37]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank37]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank37]:     output = func(self, *args, **kwargs)
[rank37]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank37]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 549, in forward
[rank37]:     layer_outputs = decoder_layer(
[rank37]:                     ^^^^^^^^^^^^^^
[rank37]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank24]: Traceback (most recent call last):
[rank24]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 528, in <module>
[rank24]:     main()
[rank24]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 498, in main
[rank24]:     llm.api.finetune(
[rank24]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank24]:     return train(
[rank24]:            ^^^^^^
[rank24]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank24]:     trainer.fit(model, data)
[rank24]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank24]:     call._call_and_handle_interrupt(
[rank54]:              ^^^^^^^^^^^^^^^^^^^
[rank18]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank18]:     return trainer_fn(*args, **kwargs)
[rank18]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank18]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank18]:     self._run(model, ckpt_path=ckpt_path)
[rank18]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank18]:     results = self._run_stage()
[rank18]:               ^^^^^^^^^^^^^^^^^
[rank18]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank18]:     self.fit_loop.run()
[rank32]: Traceback (most recent call last):
[rank32]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 528, in <module>
[rank32]:     main()
[rank32]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 498, in main
[rank32]:     llm.api.finetune(
[rank32]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank32]:     return train(
[rank32]:            ^^^^^^
[rank32]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank32]:     trainer.fit(model, data)
[rank32]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank32]:     call._call_and_handle_interrupt(
[rank57]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank57]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank57]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank57]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank57]:     outputs = self.forward(batch)
[rank57]:               ^^^^^^^^^^^^^^^^^^^
[rank57]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank57]:     return self.model(**batch)
[rank57]:            ^^^^^^^^^^^^^^^^^^^
[rank50]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank50]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank50]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank50]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 190, in run
[rank50]:     self._optimizer_step(batch_idx, closure)
[rank50]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank50]:     call._call_lightning_module_hook(
[rank37]:     return self._call_impl(*args, **kwargs)
[rank37]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank54]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank54]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank54]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank54]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank54]:     outputs = self.forward(batch)
[rank54]:               ^^^^^^^^^^^^^^^^^^^
[rank54]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank54]:     return self.model(**batch)
[rank54]:            ^^^^^^^^^^^^^^^^^^^
[rank18]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank18]:     self.advance()
[rank18]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank18]:     self.epoch_loop.run(self._data_fetcher)
[rank18]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank18]:     self.advance(data_fetcher)
[rank18]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank18]:     super().advance(data_fetcher)
[rank57]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank57]:     return self._call_impl(*args, **kwargs)
[rank57]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank57]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank57]:     return inner()
[rank57]:            ^^^^^^^
[rank57]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank57]:     result = forward_call(*args, **kwargs)
[rank57]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank57]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank57]:     output = func(self, *args, **kwargs)
[rank50]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 167, in _call_lightning_module_hook
[rank50]:     output = fn(*args, **kwargs)
[rank50]:              ^^^^^^^^^^^^^^^^^^^
[rank37]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank37]:     return inner()
[rank37]:            ^^^^^^^
[rank37]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank37]:     result = forward_call(*args, **kwargs)
[rank37]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank37]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 259, in forward
[rank37]:     hidden_states = self.input_layernorm(hidden_states)
[rank37]:                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank37]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank24]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank24]:     return trainer_fn(*args, **kwargs)
[rank24]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank24]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank24]:     self._run(model, ckpt_path=ckpt_path)
[rank24]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank24]:     results = self._run_stage()
[rank24]:               ^^^^^^^^^^^^^^^^^
[rank24]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank24]:     self.fit_loop.run()
[rank54]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank54]:     return self._call_impl(*args, **kwargs)
[rank54]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank54]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank54]:     return inner()
[rank54]:            ^^^^^^^
[rank54]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank54]:     result = forward_call(*args, **kwargs)
[rank54]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank54]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank54]:     output = func(self, *args, **kwargs)
[rank18]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank18]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank18]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank18]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 190, in run
[rank18]:     self._optimizer_step(batch_idx, closure)
[rank18]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank18]:     call._call_lightning_module_hook(
[rank57]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank57]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank57]:     return func(*args, **kwargs)
[rank57]:            ^^^^^^^^^^^^^^^^^^^^^
[rank57]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank57]:     outputs: BaseModelOutputWithPast = self.model(
[rank57]:                                        ^^^^^^^^^^^
[rank57]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank57]:     return self._call_impl(*args, **kwargs)
[rank57]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank50]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/module.py", line 1306, in optimizer_step
[rank50]:     optimizer.step(closure=optimizer_closure)
[rank50]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py", line 153, in step
[rank50]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank50]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank50]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py", line 238, in optimizer_step
[rank50]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank50]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank37]:     return self._call_impl(*args, **kwargs)
[rank37]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank37]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank37]:     return forward_call(*args, **kwargs)
[rank37]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank37]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 223, in forward
[rank37]:     variance = hidden_states.pow(2).mean(-1, keepdim=True)
[rank37]:                ^^^^^^^^^^^^^^^^^^^^
[rank24]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank24]:     self.advance()
[rank24]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank24]:     self.epoch_loop.run(self._data_fetcher)
[rank24]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank24]:     self.advance(data_fetcher)
[rank24]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank24]:     super().advance(data_fetcher)
[rank54]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank54]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank54]:     return func(*args, **kwargs)
[rank54]:            ^^^^^^^^^^^^^^^^^^^^^
[rank54]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank54]:     outputs: BaseModelOutputWithPast = self.model(
[rank54]:                                        ^^^^^^^^^^^
[rank54]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank54]:     return self._call_impl(*args, **kwargs)
[rank54]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank18]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 167, in _call_lightning_module_hook
[rank18]:     output = fn(*args, **kwargs)
[rank18]:              ^^^^^^^^^^^^^^^^^^^
[rank57]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank57]:     return forward_call(*args, **kwargs)
[rank57]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank57]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank57]:     output = func(self, *args, **kwargs)
[rank57]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank57]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 549, in forward
[rank57]:     layer_outputs = decoder_layer(
[rank57]:                     ^^^^^^^^^^^^^^
[rank57]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank50]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/amp.py", line 75, in optimizer_step
[rank50]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank50]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank50]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 122, in optimizer_step
[rank50]:     return optimizer.step(closure=closure, **kwargs)
[rank50]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank50]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/optim/optimizer.py", line 516, in wrapper
[rank50]:     out = func(*args, **kwargs)
[rank50]:           ^^^^^^^^^^^^^^^^^^^^^
[rank37]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 640.00 MiB. GPU 1 has a total capacity of 79.19 GiB of which 367.81 MiB is free. Including non-PyTorch memory, this process has 78.82 GiB memory in use. Of the allocated memory 74.80 GiB is allocated by PyTorch, and 1.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank24]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank24]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank24]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank24]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 190, in run
[rank24]:     self._optimizer_step(batch_idx, closure)
[rank24]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank24]:     call._call_lightning_module_hook(
[rank54]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank54]:     return forward_call(*args, **kwargs)
[rank54]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank54]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank54]:     output = func(self, *args, **kwargs)
[rank54]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank54]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 549, in forward
[rank54]:     layer_outputs = decoder_layer(
[rank54]:                     ^^^^^^^^^^^^^^
[rank54]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank18]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/module.py", line 1306, in optimizer_step
[rank18]:     optimizer.step(closure=optimizer_closure)
[rank18]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py", line 153, in step
[rank18]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank18]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank18]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py", line 238, in optimizer_step
[rank18]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank18]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank32]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank32]:     return trainer_fn(*args, **kwargs)
[rank32]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank32]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank32]:     self._run(model, ckpt_path=ckpt_path)
[rank32]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank32]:     results = self._run_stage()
[rank32]:               ^^^^^^^^^^^^^^^^^
[rank32]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank32]:     self.fit_loop.run()
[rank57]:     return self._call_impl(*args, **kwargs)
[rank57]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank50]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformer_engine/pytorch/optimizers/fused_adam.py", line 486, in step
[rank50]:     loss = closure()
[rank50]:            ^^^^^^^^^
[rank50]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 108, in _wrap_closure
[rank50]:     closure_result = closure()
[rank50]:                      ^^^^^^^^^
[rank50]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank50]:     self._result = self.closure(*args, **kwargs)
[rank50]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank50]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank24]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 167, in _call_lightning_module_hook
[rank24]:     output = fn(*args, **kwargs)
[rank24]:              ^^^^^^^^^^^^^^^^^^^
[rank54]:     return self._call_impl(*args, **kwargs)
[rank54]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank18]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/amp.py", line 75, in optimizer_step
[rank18]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank18]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank18]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 122, in optimizer_step
[rank18]:     return optimizer.step(closure=closure, **kwargs)
[rank18]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank18]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/optim/optimizer.py", line 516, in wrapper
[rank18]:     out = func(*args, **kwargs)
[rank18]:           ^^^^^^^^^^^^^^^^^^^^^
[rank57]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank57]:     return inner()
[rank57]:            ^^^^^^^
[rank57]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank57]:     result = forward_call(*args, **kwargs)
[rank57]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank57]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 259, in forward
[rank57]:     hidden_states = self.input_layernorm(hidden_states)
[rank57]:                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank57]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank50]:     return func(*args, **kwargs)
[rank50]:            ^^^^^^^^^^^^^^^^^^^^^
[rank50]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank50]:     step_output = self._step_fn()
[rank50]:                   ^^^^^^^^^^^^^^^
[rank50]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank50]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank50]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank50]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank50]:     output = fn(*args, **kwargs)
[rank24]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/module.py", line 1306, in optimizer_step
[rank24]:     optimizer.step(closure=optimizer_closure)
[rank24]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py", line 153, in step
[rank24]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank24]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank24]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py", line 238, in optimizer_step
[rank24]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank24]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank54]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank54]:     return inner()
[rank54]:            ^^^^^^^
[rank54]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank54]:     result = forward_call(*args, **kwargs)
[rank54]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank54]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 259, in forward
[rank54]:     hidden_states = self.input_layernorm(hidden_states)
[rank54]:                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank54]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank18]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformer_engine/pytorch/optimizers/fused_adam.py", line 486, in step
[rank18]:     loss = closure()
[rank18]:            ^^^^^^^^^
[rank18]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 108, in _wrap_closure
[rank18]:     closure_result = closure()
[rank18]:                      ^^^^^^^^^
[rank18]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank18]:     self._result = self.closure(*args, **kwargs)
[rank18]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank18]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank57]:     return self._call_impl(*args, **kwargs)
[rank57]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank57]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank57]:     return forward_call(*args, **kwargs)
[rank57]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank57]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 223, in forward
[rank57]:     variance = hidden_states.pow(2).mean(-1, keepdim=True)
[rank57]:                ^^^^^^^^^^^^^^^^^^^^
[rank50]:              ^^^^^^^^^^^^^^^^^^^
[rank24]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/amp.py", line 75, in optimizer_step
[rank24]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank24]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank24]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 122, in optimizer_step
[rank24]:     return optimizer.step(closure=closure, **kwargs)
[rank24]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank24]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/optim/optimizer.py", line 516, in wrapper
[rank24]:     out = func(*args, **kwargs)
[rank24]:           ^^^^^^^^^^^^^^^^^^^^^
[rank54]:     return self._call_impl(*args, **kwargs)
[rank54]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank54]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank54]:     return forward_call(*args, **kwargs)
[rank54]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank54]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 223, in forward
[rank54]:     variance = hidden_states.pow(2).mean(-1, keepdim=True)
[rank54]:                ^^^^^^^^^^^^^^^^^^^^
[rank18]:     return func(*args, **kwargs)
[rank18]:            ^^^^^^^^^^^^^^^^^^^^^
[rank18]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank18]:     step_output = self._step_fn()
[rank18]:                   ^^^^^^^^^^^^^^^
[rank18]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank18]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank18]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank18]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank18]:     output = fn(*args, **kwargs)
[rank57]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 640.00 MiB. GPU 1 has a total capacity of 79.19 GiB of which 367.81 MiB is free. Including non-PyTorch memory, this process has 78.82 GiB memory in use. Of the allocated memory 74.80 GiB is allocated by PyTorch, and 1.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank50]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank50]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank50]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank50]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank50]:     outputs = self.forward(batch)
[rank50]:               ^^^^^^^^^^^^^^^^^^^
[rank50]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank50]:     return self.model(**batch)
[rank50]:            ^^^^^^^^^^^^^^^^^^^
[rank24]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformer_engine/pytorch/optimizers/fused_adam.py", line 486, in step
[rank24]:     loss = closure()
[rank24]:            ^^^^^^^^^
[rank24]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 108, in _wrap_closure
[rank24]:     closure_result = closure()
[rank24]:                      ^^^^^^^^^
[rank24]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank24]:     self._result = self.closure(*args, **kwargs)
[rank24]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank24]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank54]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 640.00 MiB. GPU 2 has a total capacity of 79.19 GiB of which 395.81 MiB is free. Including non-PyTorch memory, this process has 78.79 GiB memory in use. Of the allocated memory 74.80 GiB is allocated by PyTorch, and 1.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank18]:              ^^^^^^^^^^^^^^^^^^^
[rank32]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank32]:     self.advance()
[rank32]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank32]:     self.epoch_loop.run(self._data_fetcher)
[rank32]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank32]:     self.advance(data_fetcher)
[rank32]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank32]:     super().advance(data_fetcher)
[rank50]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank50]:     return self._call_impl(*args, **kwargs)
[rank50]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank50]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank50]:     return inner()
[rank50]:            ^^^^^^^
[rank50]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank50]:     result = forward_call(*args, **kwargs)
[rank50]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank50]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank50]:     output = func(self, *args, **kwargs)
[rank24]:     return func(*args, **kwargs)
[rank24]:            ^^^^^^^^^^^^^^^^^^^^^
[rank24]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank24]:     step_output = self._step_fn()
[rank24]:                   ^^^^^^^^^^^^^^^
[rank24]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank24]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank24]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank24]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank24]:     output = fn(*args, **kwargs)
[rank32]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank32]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank32]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank32]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 190, in run
[rank32]:     self._optimizer_step(batch_idx, closure)
[rank32]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank32]:     call._call_lightning_module_hook(
[rank50]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank50]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank50]:     return func(*args, **kwargs)
[rank50]:            ^^^^^^^^^^^^^^^^^^^^^
[rank50]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank50]:     outputs: BaseModelOutputWithPast = self.model(
[rank50]:                                        ^^^^^^^^^^^
[rank50]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank50]:     return self._call_impl(*args, **kwargs)
[rank50]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank36]: Traceback (most recent call last):
[rank36]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 528, in <module>
[rank36]:     main()
[rank36]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 498, in main
[rank36]:     llm.api.finetune(
[rank36]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank36]:     return train(
[rank36]:            ^^^^^^
[rank36]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank36]:     trainer.fit(model, data)
[rank36]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank36]:     call._call_and_handle_interrupt(
[rank24]:              ^^^^^^^^^^^^^^^^^^^
[rank32]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 167, in _call_lightning_module_hook
[rank32]:     output = fn(*args, **kwargs)
[rank32]:              ^^^^^^^^^^^^^^^^^^^
[rank42]: Traceback (most recent call last):
[rank42]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 528, in <module>
[rank42]:     main()
[rank42]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 498, in main
[rank42]:     llm.api.finetune(
[rank42]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank42]:     return train(
[rank42]:            ^^^^^^
[rank42]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank42]:     trainer.fit(model, data)
[rank42]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank42]:     call._call_and_handle_interrupt(
[rank50]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank50]:     return forward_call(*args, **kwargs)
[rank50]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank50]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank50]:     output = func(self, *args, **kwargs)
[rank50]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank50]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 549, in forward
[rank50]:     layer_outputs = decoder_layer(
[rank50]:                     ^^^^^^^^^^^^^^
[rank50]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank24]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank24]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank24]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank24]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank24]:     outputs = self.forward(batch)
[rank24]:               ^^^^^^^^^^^^^^^^^^^
[rank24]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank24]:     return self.model(**batch)
[rank24]:            ^^^^^^^^^^^^^^^^^^^
[rank18]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank18]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank18]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank18]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank18]:     outputs = self.forward(batch)
[rank18]:               ^^^^^^^^^^^^^^^^^^^
[rank18]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank18]:     return self.model(**batch)
[rank18]:            ^^^^^^^^^^^^^^^^^^^
[rank32]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/module.py", line 1306, in optimizer_step
[rank32]:     optimizer.step(closure=optimizer_closure)
[rank32]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py", line 153, in step
[rank32]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank32]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank32]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py", line 238, in optimizer_step
[rank32]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank32]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank42]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank42]:     return trainer_fn(*args, **kwargs)
[rank42]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank42]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank42]:     self._run(model, ckpt_path=ckpt_path)
[rank42]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank42]:     results = self._run_stage()
[rank42]:               ^^^^^^^^^^^^^^^^^
[rank42]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank42]:     self.fit_loop.run()
[rank50]:     return self._call_impl(*args, **kwargs)
[rank50]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank36]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank36]:     return trainer_fn(*args, **kwargs)
[rank36]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank36]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank36]:     self._run(model, ckpt_path=ckpt_path)
[rank36]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank36]:     results = self._run_stage()
[rank36]:               ^^^^^^^^^^^^^^^^^
[rank36]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank36]:     self.fit_loop.run()
[rank24]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank24]:     return self._call_impl(*args, **kwargs)
[rank24]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank24]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank24]:     return inner()
[rank24]:            ^^^^^^^
[rank24]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank24]:     result = forward_call(*args, **kwargs)
[rank24]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank24]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank24]:     output = func(self, *args, **kwargs)
[rank18]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank18]:     return self._call_impl(*args, **kwargs)
[rank18]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank18]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank18]:     return inner()
[rank18]:            ^^^^^^^
[rank18]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank18]:     result = forward_call(*args, **kwargs)
[rank18]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank18]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank18]:     output = func(self, *args, **kwargs)
[rank32]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/amp.py", line 75, in optimizer_step
[rank32]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank32]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank32]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 122, in optimizer_step
[rank32]:     return optimizer.step(closure=closure, **kwargs)
[rank32]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank32]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/optim/optimizer.py", line 516, in wrapper
[rank32]:     out = func(*args, **kwargs)
[rank32]:           ^^^^^^^^^^^^^^^^^^^^^
[rank42]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank42]:     self.advance()
[rank42]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank42]:     self.epoch_loop.run(self._data_fetcher)
[rank42]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank42]:     self.advance(data_fetcher)
[rank42]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank42]:     super().advance(data_fetcher)
[rank50]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank50]:     return inner()
[rank50]:            ^^^^^^^
[rank50]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank50]:     result = forward_call(*args, **kwargs)
[rank50]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank50]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 259, in forward
[rank50]:     hidden_states = self.input_layernorm(hidden_states)
[rank50]:                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank50]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank24]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank24]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank24]:     return func(*args, **kwargs)
[rank24]:            ^^^^^^^^^^^^^^^^^^^^^
[rank24]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank24]:     outputs: BaseModelOutputWithPast = self.model(
[rank24]:                                        ^^^^^^^^^^^
[rank24]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank24]:     return self._call_impl(*args, **kwargs)
[rank24]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank18]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank18]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank18]:     return func(*args, **kwargs)
[rank18]:            ^^^^^^^^^^^^^^^^^^^^^
[rank18]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank18]:     outputs: BaseModelOutputWithPast = self.model(
[rank18]:                                        ^^^^^^^^^^^
[rank18]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank18]:     return self._call_impl(*args, **kwargs)
[rank18]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank32]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformer_engine/pytorch/optimizers/fused_adam.py", line 486, in step
[rank32]:     loss = closure()
[rank32]:            ^^^^^^^^^
[rank32]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 108, in _wrap_closure
[rank32]:     closure_result = closure()
[rank32]:                      ^^^^^^^^^
[rank32]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank32]:     self._result = self.closure(*args, **kwargs)
[rank32]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank32]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank42]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank42]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank42]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank42]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 190, in run
[rank42]:     self._optimizer_step(batch_idx, closure)
[rank42]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank42]:     call._call_lightning_module_hook(
[rank50]:     return self._call_impl(*args, **kwargs)
[rank50]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank50]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank50]:     return forward_call(*args, **kwargs)
[rank50]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank50]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 223, in forward
[rank50]:     variance = hidden_states.pow(2).mean(-1, keepdim=True)
[rank50]:                ^^^^^^^^^^^^^^^^^^^^
[rank24]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank24]:     return forward_call(*args, **kwargs)
[rank24]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank24]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank24]:     output = func(self, *args, **kwargs)
[rank24]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank24]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 549, in forward
[rank24]:     layer_outputs = decoder_layer(
[rank24]:                     ^^^^^^^^^^^^^^
[rank24]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank18]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank18]:     return forward_call(*args, **kwargs)
[rank18]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank18]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank18]:     output = func(self, *args, **kwargs)
[rank18]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank18]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 549, in forward
[rank18]:     layer_outputs = decoder_layer(
[rank18]:                     ^^^^^^^^^^^^^^
[rank18]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank32]:     return func(*args, **kwargs)
[rank32]:            ^^^^^^^^^^^^^^^^^^^^^
[rank32]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank32]:     step_output = self._step_fn()
[rank32]:                   ^^^^^^^^^^^^^^^
[rank32]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank32]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank32]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank32]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank32]:     output = fn(*args, **kwargs)
[rank42]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 167, in _call_lightning_module_hook
[rank42]:     output = fn(*args, **kwargs)
[rank42]:              ^^^^^^^^^^^^^^^^^^^
[rank50]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 640.00 MiB. GPU 2 has a total capacity of 79.19 GiB of which 395.81 MiB is free. Including non-PyTorch memory, this process has 78.79 GiB memory in use. Of the allocated memory 74.80 GiB is allocated by PyTorch, and 1.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank24]:     return self._call_impl(*args, **kwargs)
[rank24]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank18]:     return self._call_impl(*args, **kwargs)
[rank18]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank32]:              ^^^^^^^^^^^^^^^^^^^
[rank42]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/module.py", line 1306, in optimizer_step
[rank42]:     optimizer.step(closure=optimizer_closure)
[rank42]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py", line 153, in step
[rank42]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank42]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank42]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py", line 238, in optimizer_step
[rank42]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank42]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank24]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank24]:     return inner()
[rank24]:            ^^^^^^^
[rank24]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank24]:     result = forward_call(*args, **kwargs)
[rank24]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank24]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 259, in forward
[rank24]:     hidden_states = self.input_layernorm(hidden_states)
[rank24]:                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank24]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank18]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank18]:     return inner()
[rank18]:            ^^^^^^^
[rank18]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank18]:     result = forward_call(*args, **kwargs)
[rank18]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank18]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 259, in forward
[rank18]:     hidden_states = self.input_layernorm(hidden_states)
[rank18]:                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank18]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank32]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank32]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank32]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank32]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank32]:     outputs = self.forward(batch)
[rank32]:               ^^^^^^^^^^^^^^^^^^^
[rank32]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank32]:     return self.model(**batch)
[rank32]:            ^^^^^^^^^^^^^^^^^^^
[rank42]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/amp.py", line 75, in optimizer_step
[rank42]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank42]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank42]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 122, in optimizer_step
[rank42]:     return optimizer.step(closure=closure, **kwargs)
[rank42]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank42]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/optim/optimizer.py", line 516, in wrapper
[rank42]:     out = func(*args, **kwargs)
[rank42]:           ^^^^^^^^^^^^^^^^^^^^^
[rank62]: Traceback (most recent call last):
[rank62]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 528, in <module>
[rank62]:     main()
[rank62]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 498, in main
[rank62]:     llm.api.finetune(
[rank62]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank62]:     return train(
[rank62]:            ^^^^^^
[rank62]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank62]:     trainer.fit(model, data)
[rank62]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank62]:     call._call_and_handle_interrupt(
[rank36]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank36]:     self.advance()
[rank36]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank36]:     self.epoch_loop.run(self._data_fetcher)
[rank36]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank36]:     self.advance(data_fetcher)
[rank36]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank36]:     super().advance(data_fetcher)
[rank24]:     return self._call_impl(*args, **kwargs)
[rank24]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank24]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank24]:     return forward_call(*args, **kwargs)
[rank24]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank24]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 223, in forward
[rank24]:     variance = hidden_states.pow(2).mean(-1, keepdim=True)
[rank24]:                ^^^^^^^^^^^^^^^^^^^^
[rank18]:     return self._call_impl(*args, **kwargs)
[rank18]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank18]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank18]:     return forward_call(*args, **kwargs)
[rank18]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank18]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 223, in forward
[rank18]:     variance = hidden_states.pow(2).mean(-1, keepdim=True)
[rank18]:                ^^^^^^^^^^^^^^^^^^^^
[rank32]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank32]:     return self._call_impl(*args, **kwargs)
[rank32]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank32]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank32]:     return inner()
[rank32]:            ^^^^^^^
[rank32]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank32]:     result = forward_call(*args, **kwargs)
[rank32]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank32]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank32]:     output = func(self, *args, **kwargs)
[rank42]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformer_engine/pytorch/optimizers/fused_adam.py", line 486, in step
[rank42]:     loss = closure()
[rank42]:            ^^^^^^^^^
[rank42]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 108, in _wrap_closure
[rank42]:     closure_result = closure()
[rank42]:                      ^^^^^^^^^
[rank42]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank42]:     self._result = self.closure(*args, **kwargs)
[rank42]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank42]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank36]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank36]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank36]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank36]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 190, in run
[rank36]:     self._optimizer_step(batch_idx, closure)
[rank36]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank36]:     call._call_lightning_module_hook(
[rank24]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 640.00 MiB. GPU 0 has a total capacity of 79.19 GiB of which 399.81 MiB is free. Including non-PyTorch memory, this process has 78.79 GiB memory in use. Of the allocated memory 74.80 GiB is allocated by PyTorch, and 1.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank18]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 640.00 MiB. GPU 2 has a total capacity of 79.19 GiB of which 395.81 MiB is free. Including non-PyTorch memory, this process has 78.79 GiB memory in use. Of the allocated memory 74.80 GiB is allocated by PyTorch, and 1.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank32]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank32]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank32]:     return func(*args, **kwargs)
[rank32]:            ^^^^^^^^^^^^^^^^^^^^^
[rank32]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank32]:     outputs: BaseModelOutputWithPast = self.model(
[rank32]:                                        ^^^^^^^^^^^
[rank32]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank32]:     return self._call_impl(*args, **kwargs)
[rank32]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank42]:     return func(*args, **kwargs)
[rank42]:            ^^^^^^^^^^^^^^^^^^^^^
[rank42]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank42]:     step_output = self._step_fn()
[rank42]:                   ^^^^^^^^^^^^^^^
[rank42]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank42]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank42]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank42]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank42]:     output = fn(*args, **kwargs)
[rank36]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 167, in _call_lightning_module_hook
[rank36]:     output = fn(*args, **kwargs)
[rank36]:              ^^^^^^^^^^^^^^^^^^^
[rank32]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank32]:     return forward_call(*args, **kwargs)
[rank32]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank32]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank32]:     output = func(self, *args, **kwargs)
[rank32]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank32]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 549, in forward
[rank32]:     layer_outputs = decoder_layer(
[rank32]:                     ^^^^^^^^^^^^^^
[rank32]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank42]:              ^^^^^^^^^^^^^^^^^^^
[rank36]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/module.py", line 1306, in optimizer_step
[rank36]:     optimizer.step(closure=optimizer_closure)
[rank36]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py", line 153, in step
[rank36]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank36]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank36]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py", line 238, in optimizer_step
[rank36]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank36]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank32]:     return self._call_impl(*args, **kwargs)
[rank32]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank42]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank42]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank42]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank42]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank42]:     outputs = self.forward(batch)
[rank42]:               ^^^^^^^^^^^^^^^^^^^
[rank42]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank42]:     return self.model(**batch)
[rank42]:            ^^^^^^^^^^^^^^^^^^^
[rank36]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/amp.py", line 75, in optimizer_step
[rank36]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank36]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank36]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 122, in optimizer_step
[rank36]:     return optimizer.step(closure=closure, **kwargs)
[rank36]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank36]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/optim/optimizer.py", line 516, in wrapper
[rank36]:     out = func(*args, **kwargs)
[rank36]:           ^^^^^^^^^^^^^^^^^^^^^
[rank32]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank32]:     return inner()
[rank32]:            ^^^^^^^
[rank32]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank32]:     result = forward_call(*args, **kwargs)
[rank32]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank32]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 259, in forward
[rank32]:     hidden_states = self.input_layernorm(hidden_states)
[rank32]:                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank32]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank42]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank42]:     return self._call_impl(*args, **kwargs)
[rank42]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank42]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank42]:     return inner()
[rank42]:            ^^^^^^^
[rank42]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank42]:     result = forward_call(*args, **kwargs)
[rank42]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank42]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank42]:     output = func(self, *args, **kwargs)
[rank62]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank62]:     return trainer_fn(*args, **kwargs)
[rank62]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank62]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank62]:     self._run(model, ckpt_path=ckpt_path)
[rank62]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank62]:     results = self._run_stage()
[rank62]:               ^^^^^^^^^^^^^^^^^
[rank62]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank62]:     self.fit_loop.run()
[rank36]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformer_engine/pytorch/optimizers/fused_adam.py", line 486, in step
[rank36]:     loss = closure()
[rank36]:            ^^^^^^^^^
[rank36]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 108, in _wrap_closure
[rank36]:     closure_result = closure()
[rank36]:                      ^^^^^^^^^
[rank36]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank36]:     self._result = self.closure(*args, **kwargs)
[rank36]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank36]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank21]: Traceback (most recent call last):
[rank21]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 528, in <module>
[rank21]:     main()
[rank21]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 498, in main
[rank21]:     llm.api.finetune(
[rank21]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank21]:     return train(
[rank21]:            ^^^^^^
[rank21]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank21]:     trainer.fit(model, data)
[rank21]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank21]:     call._call_and_handle_interrupt(
[rank31]: Traceback (most recent call last):
[rank31]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 528, in <module>
[rank31]:     main()
[rank31]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 498, in main
[rank31]:     llm.api.finetune(
[rank31]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank31]:     return train(
[rank31]:            ^^^^^^
[rank31]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank31]:     trainer.fit(model, data)
[rank31]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank31]:     call._call_and_handle_interrupt(
[rank32]:     return self._call_impl(*args, **kwargs)
[rank32]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank32]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank32]:     return forward_call(*args, **kwargs)
[rank32]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank32]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 223, in forward
[rank32]:     variance = hidden_states.pow(2).mean(-1, keepdim=True)
[rank32]:                ^^^^^^^^^^^^^^^^^^^^
[rank42]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank42]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank42]:     return func(*args, **kwargs)
[rank42]:            ^^^^^^^^^^^^^^^^^^^^^
[rank42]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank42]:     outputs: BaseModelOutputWithPast = self.model(
[rank42]:                                        ^^^^^^^^^^^
[rank42]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank42]:     return self._call_impl(*args, **kwargs)
[rank42]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank62]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank62]:     self.advance()
[rank62]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank62]:     self.epoch_loop.run(self._data_fetcher)
[rank62]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank62]:     self.advance(data_fetcher)
[rank62]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank62]:     super().advance(data_fetcher)
[rank36]:     return func(*args, **kwargs)
[rank36]:            ^^^^^^^^^^^^^^^^^^^^^
[rank36]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank36]:     step_output = self._step_fn()
[rank36]:                   ^^^^^^^^^^^^^^^
[rank36]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank36]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank36]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank36]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank36]:     output = fn(*args, **kwargs)
[rank32]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 640.00 MiB. GPU 0 has a total capacity of 79.19 GiB of which 399.81 MiB is free. Including non-PyTorch memory, this process has 78.79 GiB memory in use. Of the allocated memory 74.80 GiB is allocated by PyTorch, and 1.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank42]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank42]:     return forward_call(*args, **kwargs)
[rank42]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank42]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank42]:     output = func(self, *args, **kwargs)
[rank42]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank42]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 549, in forward
[rank42]:     layer_outputs = decoder_layer(
[rank42]:                     ^^^^^^^^^^^^^^
[rank42]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank62]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank62]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank62]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank62]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 190, in run
[rank62]:     self._optimizer_step(batch_idx, closure)
[rank62]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank62]:     call._call_lightning_module_hook(
[rank36]:              ^^^^^^^^^^^^^^^^^^^
[rank42]:     return self._call_impl(*args, **kwargs)
[rank42]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank62]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 167, in _call_lightning_module_hook
[rank62]:     output = fn(*args, **kwargs)
[rank62]:              ^^^^^^^^^^^^^^^^^^^
[rank36]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank36]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank36]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank36]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank36]:     outputs = self.forward(batch)
[rank36]:               ^^^^^^^^^^^^^^^^^^^
[rank36]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank36]:     return self.model(**batch)
[rank36]:            ^^^^^^^^^^^^^^^^^^^
[rank42]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank42]:     return inner()
[rank42]:            ^^^^^^^
[rank42]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank42]:     result = forward_call(*args, **kwargs)
[rank42]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank42]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 259, in forward
[rank42]:     hidden_states = self.input_layernorm(hidden_states)
[rank42]:                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank42]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank62]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/module.py", line 1306, in optimizer_step
[rank62]:     optimizer.step(closure=optimizer_closure)
[rank62]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py", line 153, in step
[rank62]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank62]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank62]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py", line 238, in optimizer_step
[rank62]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank62]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank36]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank36]:     return self._call_impl(*args, **kwargs)
[rank36]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank36]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank36]:     return inner()
[rank36]:            ^^^^^^^
[rank36]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank36]:     result = forward_call(*args, **kwargs)
[rank36]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank36]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank36]:     output = func(self, *args, **kwargs)
[rank42]:     return self._call_impl(*args, **kwargs)
[rank42]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank42]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank42]:     return forward_call(*args, **kwargs)
[rank42]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank42]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 223, in forward
[rank42]:     variance = hidden_states.pow(2).mean(-1, keepdim=True)
[rank42]:                ^^^^^^^^^^^^^^^^^^^^
[rank62]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/amp.py", line 75, in optimizer_step
[rank62]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank62]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank62]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 122, in optimizer_step
[rank62]:     return optimizer.step(closure=closure, **kwargs)
[rank62]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank62]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/optim/optimizer.py", line 516, in wrapper
[rank62]:     out = func(*args, **kwargs)
[rank62]:           ^^^^^^^^^^^^^^^^^^^^^
[rank36]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank36]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank36]:     return func(*args, **kwargs)
[rank36]:            ^^^^^^^^^^^^^^^^^^^^^
[rank36]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank36]:     outputs: BaseModelOutputWithPast = self.model(
[rank36]:                                        ^^^^^^^^^^^
[rank36]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank36]:     return self._call_impl(*args, **kwargs)
[rank36]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank21]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank21]:     return trainer_fn(*args, **kwargs)
[rank21]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank21]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank21]:     self._run(model, ckpt_path=ckpt_path)
[rank21]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank21]:     results = self._run_stage()
[rank21]:               ^^^^^^^^^^^^^^^^^
[rank21]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank21]:     self.fit_loop.run()
[rank53]: Traceback (most recent call last):
[rank53]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 528, in <module>
[rank53]:     main()
[rank53]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 498, in main
[rank53]:     llm.api.finetune(
[rank53]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank53]:     return train(
[rank53]:            ^^^^^^
[rank53]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank53]:     trainer.fit(model, data)
[rank53]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank53]:     call._call_and_handle_interrupt(
[rank35]: Traceback (most recent call last):
[rank35]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 528, in <module>
[rank35]:     main()
[rank35]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 498, in main
[rank35]:     llm.api.finetune(
[rank35]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank35]:     return train(
[rank35]:            ^^^^^^
[rank35]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank35]:     trainer.fit(model, data)
[rank35]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank35]:     call._call_and_handle_interrupt(
[rank42]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 640.00 MiB. GPU 2 has a total capacity of 79.19 GiB of which 395.81 MiB is free. Including non-PyTorch memory, this process has 78.79 GiB memory in use. Of the allocated memory 74.80 GiB is allocated by PyTorch, and 1.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank62]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformer_engine/pytorch/optimizers/fused_adam.py", line 486, in step
[rank62]:     loss = closure()
[rank62]:            ^^^^^^^^^
[rank62]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 108, in _wrap_closure
[rank62]:     closure_result = closure()
[rank62]:                      ^^^^^^^^^
[rank62]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank62]:     self._result = self.closure(*args, **kwargs)
[rank62]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank62]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank36]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank36]:     return forward_call(*args, **kwargs)
[rank36]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank36]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank36]:     output = func(self, *args, **kwargs)
[rank36]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank36]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 549, in forward
[rank36]:     layer_outputs = decoder_layer(
[rank36]:                     ^^^^^^^^^^^^^^
[rank36]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank21]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank21]:     self.advance()
[rank21]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank21]:     self.epoch_loop.run(self._data_fetcher)
[rank21]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank21]:     self.advance(data_fetcher)
[rank21]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank21]:     super().advance(data_fetcher)
[rank25]: Traceback (most recent call last):
[rank25]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 528, in <module>
[rank25]:     main()
[rank25]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 498, in main
[rank25]:     llm.api.finetune(
[rank25]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank25]:     return train(
[rank25]:            ^^^^^^
[rank25]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank25]:     trainer.fit(model, data)
[rank25]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank25]:     call._call_and_handle_interrupt(
[rank62]:     return func(*args, **kwargs)
[rank62]:            ^^^^^^^^^^^^^^^^^^^^^
[rank62]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank62]:     step_output = self._step_fn()
[rank62]:                   ^^^^^^^^^^^^^^^
[rank62]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank62]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank62]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank62]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank62]:     output = fn(*args, **kwargs)
[rank36]:     return self._call_impl(*args, **kwargs)
[rank36]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank21]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank21]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank21]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank21]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 190, in run
[rank21]:     self._optimizer_step(batch_idx, closure)
[rank21]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank21]:     call._call_lightning_module_hook(
[rank62]:              ^^^^^^^^^^^^^^^^^^^
[rank36]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank36]:     return inner()
[rank36]:            ^^^^^^^
[rank36]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank36]:     result = forward_call(*args, **kwargs)
[rank36]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank36]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 259, in forward
[rank36]:     hidden_states = self.input_layernorm(hidden_states)
[rank36]:                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank36]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank21]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 167, in _call_lightning_module_hook
[rank21]:     output = fn(*args, **kwargs)
[rank21]:              ^^^^^^^^^^^^^^^^^^^
[rank62]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank62]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank62]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank62]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank62]:     outputs = self.forward(batch)
[rank62]:               ^^^^^^^^^^^^^^^^^^^
[rank62]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank62]:     return self.model(**batch)
[rank62]:            ^^^^^^^^^^^^^^^^^^^
[rank36]:     return self._call_impl(*args, **kwargs)
[rank36]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank36]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank36]:     return forward_call(*args, **kwargs)
[rank36]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank36]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 223, in forward
[rank36]:     variance = hidden_states.pow(2).mean(-1, keepdim=True)
[rank36]:                ^^^^^^^^^^^^^^^^^^^^
[rank21]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/module.py", line 1306, in optimizer_step
[rank21]:     optimizer.step(closure=optimizer_closure)
[rank21]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py", line 153, in step
[rank21]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank21]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank21]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py", line 238, in optimizer_step
[rank21]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank21]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank62]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank62]:     return self._call_impl(*args, **kwargs)
[rank62]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank62]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank62]:     return inner()
[rank62]:            ^^^^^^^
[rank62]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank62]:     result = forward_call(*args, **kwargs)
[rank62]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank62]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank62]:     output = func(self, *args, **kwargs)
[rank36]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 640.00 MiB. GPU 0 has a total capacity of 79.19 GiB of which 399.81 MiB is free. Including non-PyTorch memory, this process has 78.79 GiB memory in use. Of the allocated memory 74.80 GiB is allocated by PyTorch, and 1.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank21]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/amp.py", line 75, in optimizer_step
[rank21]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank21]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank21]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 122, in optimizer_step
[rank21]:     return optimizer.step(closure=closure, **kwargs)
[rank21]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank21]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/optim/optimizer.py", line 516, in wrapper
[rank21]:     out = func(*args, **kwargs)
[rank21]:           ^^^^^^^^^^^^^^^^^^^^^
[rank62]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank62]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank62]:     return func(*args, **kwargs)
[rank62]:            ^^^^^^^^^^^^^^^^^^^^^
[rank62]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank62]:     outputs: BaseModelOutputWithPast = self.model(
[rank62]:                                        ^^^^^^^^^^^
[rank62]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank62]:     return self._call_impl(*args, **kwargs)
[rank62]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank21]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformer_engine/pytorch/optimizers/fused_adam.py", line 486, in step
[rank21]:     loss = closure()
[rank21]:            ^^^^^^^^^
[rank21]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 108, in _wrap_closure
[rank21]:     closure_result = closure()
[rank21]:                      ^^^^^^^^^
[rank21]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank21]:     self._result = self.closure(*args, **kwargs)
[rank21]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank21]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank53]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank53]:     return trainer_fn(*args, **kwargs)
[rank53]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank53]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank53]:     self._run(model, ckpt_path=ckpt_path)
[rank53]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank53]:     results = self._run_stage()
[rank53]:               ^^^^^^^^^^^^^^^^^
[rank53]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank53]:     self.fit_loop.run()
[rank62]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank62]:     return forward_call(*args, **kwargs)
[rank62]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank62]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank62]:     output = func(self, *args, **kwargs)
[rank62]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank62]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 549, in forward
[rank62]:     layer_outputs = decoder_layer(
[rank62]:                     ^^^^^^^^^^^^^^
[rank62]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank21]:     return func(*args, **kwargs)
[rank21]:            ^^^^^^^^^^^^^^^^^^^^^
[rank21]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank21]:     step_output = self._step_fn()
[rank21]:                   ^^^^^^^^^^^^^^^
[rank21]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank21]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank21]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank21]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank21]:     output = fn(*args, **kwargs)
[rank25]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank25]:     return trainer_fn(*args, **kwargs)
[rank25]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank25]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank25]:     self._run(model, ckpt_path=ckpt_path)
[rank25]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank25]:     results = self._run_stage()
[rank25]:               ^^^^^^^^^^^^^^^^^
[rank25]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank25]:     self.fit_loop.run()
[rank53]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank53]:     self.advance()
[rank53]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank53]:     self.epoch_loop.run(self._data_fetcher)
[rank53]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank53]:     self.advance(data_fetcher)
[rank53]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank53]:     super().advance(data_fetcher)
[rank31]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank31]:     return trainer_fn(*args, **kwargs)
[rank31]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank31]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank31]:     self._run(model, ckpt_path=ckpt_path)
[rank31]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank31]:     results = self._run_stage()
[rank31]:               ^^^^^^^^^^^^^^^^^
[rank31]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank31]:     self.fit_loop.run()
[rank2]: Traceback (most recent call last):
[rank2]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 528, in <module>
[rank2]:     main()
[rank2]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 498, in main
[rank2]:     llm.api.finetune(
[rank2]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank2]:     return train(
[rank2]:            ^^^^^^
[rank2]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank2]:     trainer.fit(model, data)
[rank2]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank2]:     call._call_and_handle_interrupt(
[rank62]:     return self._call_impl(*args, **kwargs)
[rank62]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank21]:              ^^^^^^^^^^^^^^^^^^^
[rank25]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank25]:     self.advance()
[rank25]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank25]:     self.epoch_loop.run(self._data_fetcher)
[rank25]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank25]:     self.advance(data_fetcher)
[rank25]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank25]:     super().advance(data_fetcher)
[rank53]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank53]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank53]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank53]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 190, in run
[rank53]:     self._optimizer_step(batch_idx, closure)
[rank53]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank53]:     call._call_lightning_module_hook(
[rank2]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank2]:     return trainer_fn(*args, **kwargs)
[rank2]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank2]:     self._run(model, ckpt_path=ckpt_path)
[rank2]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank2]:     results = self._run_stage()
[rank2]:               ^^^^^^^^^^^^^^^^^
[rank2]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank2]:     self.fit_loop.run()
[rank62]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank62]:     return inner()
[rank62]:            ^^^^^^^
[rank62]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank62]:     result = forward_call(*args, **kwargs)
[rank62]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank62]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 259, in forward
[rank62]:     hidden_states = self.input_layernorm(hidden_states)
[rank62]:                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank62]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank22]: Traceback (most recent call last):
[rank22]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 528, in <module>
[rank22]:     main()
[rank22]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 498, in main
[rank22]:     llm.api.finetune(
[rank22]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank22]:     return train(
[rank22]:            ^^^^^^
[rank22]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank22]:     trainer.fit(model, data)
[rank22]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank22]:     call._call_and_handle_interrupt(
[rank25]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank25]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank25]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank25]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 190, in run
[rank25]:     self._optimizer_step(batch_idx, closure)
[rank25]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank25]:     call._call_lightning_module_hook(
[rank53]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 167, in _call_lightning_module_hook
[rank53]:     output = fn(*args, **kwargs)
[rank53]:              ^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank2]:     self.advance()
[rank2]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank2]:     self.epoch_loop.run(self._data_fetcher)
[rank2]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank2]:     self.advance(data_fetcher)
[rank2]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank2]:     super().advance(data_fetcher)
[rank62]:     return self._call_impl(*args, **kwargs)
[rank62]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank62]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank62]:     return forward_call(*args, **kwargs)
[rank62]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank62]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 223, in forward
[rank62]:     variance = hidden_states.pow(2).mean(-1, keepdim=True)
[rank62]:                ^^^^^^^^^^^^^^^^^^^^
[rank22]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank22]:     return trainer_fn(*args, **kwargs)
[rank22]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank22]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank22]:     self._run(model, ckpt_path=ckpt_path)
[rank22]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank22]:     results = self._run_stage()
[rank22]:               ^^^^^^^^^^^^^^^^^
[rank22]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank22]:     self.fit_loop.run()
[rank25]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 167, in _call_lightning_module_hook
[rank25]:     output = fn(*args, **kwargs)
[rank25]:              ^^^^^^^^^^^^^^^^^^^
[rank53]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/module.py", line 1306, in optimizer_step
[rank53]:     optimizer.step(closure=optimizer_closure)
[rank53]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py", line 153, in step
[rank53]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank53]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank53]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py", line 238, in optimizer_step
[rank53]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank53]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank2]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank2]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 190, in run
[rank2]:     self._optimizer_step(batch_idx, closure)
[rank2]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank2]:     call._call_lightning_module_hook(
[rank62]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 640.00 MiB. GPU 2 has a total capacity of 79.19 GiB of which 475.81 MiB is free. Including non-PyTorch memory, this process has 78.71 GiB memory in use. Of the allocated memory 74.80 GiB is allocated by PyTorch, and 1.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank22]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank22]:     self.advance()
[rank22]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank22]:     self.epoch_loop.run(self._data_fetcher)
[rank22]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank22]:     self.advance(data_fetcher)
[rank22]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank22]:     super().advance(data_fetcher)
[rank25]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/module.py", line 1306, in optimizer_step
[rank25]:     optimizer.step(closure=optimizer_closure)
[rank25]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py", line 153, in step
[rank25]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank25]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank25]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py", line 238, in optimizer_step
[rank25]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank25]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank53]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/amp.py", line 75, in optimizer_step
[rank53]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank53]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank53]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 122, in optimizer_step
[rank53]:     return optimizer.step(closure=closure, **kwargs)
[rank53]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank53]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/optim/optimizer.py", line 516, in wrapper
[rank53]:     out = func(*args, **kwargs)
[rank53]:           ^^^^^^^^^^^^^^^^^^^^^
[rank31]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank31]:     self.advance()
[rank31]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank31]:     self.epoch_loop.run(self._data_fetcher)
[rank31]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank31]:     self.advance(data_fetcher)
[rank31]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank31]:     super().advance(data_fetcher)
[rank2]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 167, in _call_lightning_module_hook
[rank2]:     output = fn(*args, **kwargs)
[rank2]:              ^^^^^^^^^^^^^^^^^^^
[rank63]: Traceback (most recent call last):
[rank63]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 528, in <module>
[rank63]:     main()
[rank63]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 498, in main
[rank63]:     llm.api.finetune(
[rank63]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank63]:     return train(
[rank63]:            ^^^^^^
[rank63]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank63]:     trainer.fit(model, data)
[rank63]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank63]:     call._call_and_handle_interrupt(
[rank22]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank22]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank22]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank22]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 190, in run
[rank22]:     self._optimizer_step(batch_idx, closure)
[rank22]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank22]:     call._call_lightning_module_hook(
[rank25]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/amp.py", line 75, in optimizer_step
[rank25]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank25]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank25]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 122, in optimizer_step
[rank25]:     return optimizer.step(closure=closure, **kwargs)
[rank25]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank25]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/optim/optimizer.py", line 516, in wrapper
[rank25]:     out = func(*args, **kwargs)
[rank25]:           ^^^^^^^^^^^^^^^^^^^^^
[rank53]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformer_engine/pytorch/optimizers/fused_adam.py", line 486, in step
[rank53]:     loss = closure()
[rank53]:            ^^^^^^^^^
[rank53]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 108, in _wrap_closure
[rank53]:     closure_result = closure()
[rank53]:                      ^^^^^^^^^
[rank53]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank53]:     self._result = self.closure(*args, **kwargs)
[rank53]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank53]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank31]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank31]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank31]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank31]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 190, in run
[rank31]:     self._optimizer_step(batch_idx, closure)
[rank31]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank31]:     call._call_lightning_module_hook(
[rank2]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/module.py", line 1306, in optimizer_step
[rank2]:     optimizer.step(closure=optimizer_closure)
[rank2]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py", line 153, in step
[rank2]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank2]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py", line 238, in optimizer_step
[rank2]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank2]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank63]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank63]:     return trainer_fn(*args, **kwargs)
[rank63]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank63]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank63]:     self._run(model, ckpt_path=ckpt_path)
[rank63]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank63]:     results = self._run_stage()
[rank63]:               ^^^^^^^^^^^^^^^^^
[rank63]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank63]:     self.fit_loop.run()
[rank22]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 167, in _call_lightning_module_hook
[rank22]:     output = fn(*args, **kwargs)
[rank22]:              ^^^^^^^^^^^^^^^^^^^
[rank53]:     return func(*args, **kwargs)
[rank53]:            ^^^^^^^^^^^^^^^^^^^^^
[rank53]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank53]:     step_output = self._step_fn()
[rank53]:                   ^^^^^^^^^^^^^^^
[rank53]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank53]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank53]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank53]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank53]:     output = fn(*args, **kwargs)
[rank31]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 167, in _call_lightning_module_hook
[rank31]:     output = fn(*args, **kwargs)
[rank31]:              ^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/amp.py", line 75, in optimizer_step
[rank2]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank2]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 122, in optimizer_step
[rank2]:     return optimizer.step(closure=closure, **kwargs)
[rank2]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/optim/optimizer.py", line 516, in wrapper
[rank2]:     out = func(*args, **kwargs)
[rank2]:           ^^^^^^^^^^^^^^^^^^^^^
[rank63]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank63]:     self.advance()
[rank63]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank63]:     self.epoch_loop.run(self._data_fetcher)
[rank63]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank63]:     self.advance(data_fetcher)
[rank63]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank63]:     super().advance(data_fetcher)
[rank21]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank21]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank21]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank21]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank21]:     outputs = self.forward(batch)
[rank21]:               ^^^^^^^^^^^^^^^^^^^
[rank21]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank21]:     return self.model(**batch)
[rank21]:            ^^^^^^^^^^^^^^^^^^^
[rank30]: Traceback (most recent call last):
[rank30]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 528, in <module>
[rank30]:     main()
[rank30]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 498, in main
[rank30]:     llm.api.finetune(
[rank30]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank30]:     return train(
[rank30]:            ^^^^^^
[rank30]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank30]:     trainer.fit(model, data)
[rank30]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank30]:     call._call_and_handle_interrupt(
[rank35]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank35]:     return trainer_fn(*args, **kwargs)
[rank35]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank35]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank35]:     self._run(model, ckpt_path=ckpt_path)
[rank35]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank35]:     results = self._run_stage()
[rank35]:               ^^^^^^^^^^^^^^^^^
[rank35]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank35]:     self.fit_loop.run()
[rank2]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformer_engine/pytorch/optimizers/fused_adam.py", line 486, in step
[rank2]:     loss = closure()
[rank2]:            ^^^^^^^^^
[rank2]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 108, in _wrap_closure
[rank2]:     closure_result = closure()
[rank2]:                      ^^^^^^^^^
[rank2]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank2]:     self._result = self.closure(*args, **kwargs)
[rank2]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank63]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank63]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank63]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank63]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 190, in run
[rank63]:     self._optimizer_step(batch_idx, closure)
[rank63]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank63]:     call._call_lightning_module_hook(
[rank21]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank21]:     return self._call_impl(*args, **kwargs)
[rank21]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank21]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank21]:     return inner()
[rank21]:            ^^^^^^^
[rank21]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank21]:     result = forward_call(*args, **kwargs)
[rank21]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank21]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank21]:     output = func(self, *args, **kwargs)
[rank30]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank30]:     return trainer_fn(*args, **kwargs)
[rank30]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank30]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank30]:     self._run(model, ckpt_path=ckpt_path)
[rank30]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank30]:     results = self._run_stage()
[rank30]:               ^^^^^^^^^^^^^^^^^
[rank30]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank30]:     self.fit_loop.run()
[rank2]:     return func(*args, **kwargs)
[rank2]:            ^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank2]:     step_output = self._step_fn()
[rank2]:                   ^^^^^^^^^^^^^^^
[rank2]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank2]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank2]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank2]:     output = fn(*args, **kwargs)
[rank63]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 167, in _call_lightning_module_hook
[rank63]:     output = fn(*args, **kwargs)
[rank63]:              ^^^^^^^^^^^^^^^^^^^
[rank21]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank21]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank21]:     return func(*args, **kwargs)
[rank21]:            ^^^^^^^^^^^^^^^^^^^^^
[rank21]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank21]:     outputs: BaseModelOutputWithPast = self.model(
[rank21]:                                        ^^^^^^^^^^^
[rank21]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank21]:     return self._call_impl(*args, **kwargs)
[rank21]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank25]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformer_engine/pytorch/optimizers/fused_adam.py", line 486, in step
[rank25]:     loss = closure()
[rank25]:            ^^^^^^^^^
[rank25]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 108, in _wrap_closure
[rank25]:     closure_result = closure()
[rank25]:                      ^^^^^^^^^
[rank25]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank25]:     self._result = self.closure(*args, **kwargs)
[rank25]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank25]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank53]:              ^^^^^^^^^^^^^^^^^^^
[rank30]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank30]:     self.advance()
[rank30]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank30]:     self.epoch_loop.run(self._data_fetcher)
[rank30]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank30]:     self.advance(data_fetcher)
[rank30]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank30]:     super().advance(data_fetcher)
[rank2]:              ^^^^^^^^^^^^^^^^^^^
[rank63]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/module.py", line 1306, in optimizer_step
[rank63]:     optimizer.step(closure=optimizer_closure)
[rank63]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py", line 153, in step
[rank63]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank63]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank63]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py", line 238, in optimizer_step
[rank63]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank63]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank21]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank21]:     return forward_call(*args, **kwargs)
[rank21]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank21]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank21]:     output = func(self, *args, **kwargs)
[rank21]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank21]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 549, in forward
[rank21]:     layer_outputs = decoder_layer(
[rank21]:                     ^^^^^^^^^^^^^^
[rank21]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank25]:     return func(*args, **kwargs)
[rank25]:            ^^^^^^^^^^^^^^^^^^^^^
[rank25]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank25]:     step_output = self._step_fn()
[rank25]:                   ^^^^^^^^^^^^^^^
[rank25]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank25]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank25]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank25]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank25]:     output = fn(*args, **kwargs)
[rank53]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank53]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank53]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank53]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank53]:     outputs = self.forward(batch)
[rank53]:               ^^^^^^^^^^^^^^^^^^^
[rank53]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank53]:     return self.model(**batch)
[rank53]:            ^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank2]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank2]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank2]:     outputs = self.forward(batch)
[rank2]:               ^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank2]:     return self.model(**batch)
[rank2]:            ^^^^^^^^^^^^^^^^^^^
[rank63]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/amp.py", line 75, in optimizer_step
[rank63]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank63]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank63]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 122, in optimizer_step
[rank63]:     return optimizer.step(closure=closure, **kwargs)
[rank63]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank63]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/optim/optimizer.py", line 516, in wrapper
[rank63]:     out = func(*args, **kwargs)
[rank63]:           ^^^^^^^^^^^^^^^^^^^^^
[rank21]:     return self._call_impl(*args, **kwargs)
[rank21]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank25]:              ^^^^^^^^^^^^^^^^^^^
[rank53]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank53]:     return self._call_impl(*args, **kwargs)
[rank53]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank53]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank53]:     return inner()
[rank53]:            ^^^^^^^
[rank53]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank53]:     result = forward_call(*args, **kwargs)
[rank53]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank53]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank53]:     output = func(self, *args, **kwargs)
[rank35]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank35]:     self.advance()
[rank35]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank35]:     self.epoch_loop.run(self._data_fetcher)
[rank35]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank35]:     self.advance(data_fetcher)
[rank35]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank35]:     super().advance(data_fetcher)
[rank2]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank2]:     return self._call_impl(*args, **kwargs)
[rank2]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank2]:     return inner()
[rank2]:            ^^^^^^^
[rank2]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank2]:     result = forward_call(*args, **kwargs)
[rank2]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank2]:     output = func(self, *args, **kwargs)
[rank63]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformer_engine/pytorch/optimizers/fused_adam.py", line 486, in step
[rank63]:     loss = closure()
[rank63]:            ^^^^^^^^^
[rank63]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 108, in _wrap_closure
[rank63]:     closure_result = closure()
[rank63]:                      ^^^^^^^^^
[rank63]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank63]:     self._result = self.closure(*args, **kwargs)
[rank63]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank63]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank22]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/module.py", line 1306, in optimizer_step
[rank22]:     optimizer.step(closure=optimizer_closure)
[rank22]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py", line 153, in step
[rank22]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank22]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank22]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py", line 238, in optimizer_step
[rank22]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank22]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank25]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank25]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank25]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank25]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank25]:     outputs = self.forward(batch)
[rank25]:               ^^^^^^^^^^^^^^^^^^^
[rank25]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank25]:     return self.model(**batch)
[rank25]:            ^^^^^^^^^^^^^^^^^^^
[rank53]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank53]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank53]:     return func(*args, **kwargs)
[rank53]:            ^^^^^^^^^^^^^^^^^^^^^
[rank53]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank53]:     outputs: BaseModelOutputWithPast = self.model(
[rank53]:                                        ^^^^^^^^^^^
[rank53]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank53]:     return self._call_impl(*args, **kwargs)
[rank53]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank35]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank35]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank35]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank35]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 190, in run
[rank35]:     self._optimizer_step(batch_idx, closure)
[rank35]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank35]:     call._call_lightning_module_hook(
[rank2]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank2]:     return func(*args, **kwargs)
[rank2]:            ^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank2]:     outputs: BaseModelOutputWithPast = self.model(
[rank2]:                                        ^^^^^^^^^^^
[rank2]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank2]:     return self._call_impl(*args, **kwargs)
[rank2]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank63]:     return func(*args, **kwargs)
[rank63]:            ^^^^^^^^^^^^^^^^^^^^^
[rank63]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank63]:     step_output = self._step_fn()
[rank63]:                   ^^^^^^^^^^^^^^^
[rank63]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank63]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank63]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank63]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank63]:     output = fn(*args, **kwargs)
[rank22]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/amp.py", line 75, in optimizer_step
[rank22]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank22]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank22]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 122, in optimizer_step
[rank22]:     return optimizer.step(closure=closure, **kwargs)
[rank22]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank22]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/optim/optimizer.py", line 516, in wrapper
[rank22]:     out = func(*args, **kwargs)
[rank22]:           ^^^^^^^^^^^^^^^^^^^^^
[rank25]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank25]:     return self._call_impl(*args, **kwargs)
[rank25]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank25]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank25]:     return inner()
[rank25]:            ^^^^^^^
[rank25]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank25]:     result = forward_call(*args, **kwargs)
[rank25]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank25]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank25]:     output = func(self, *args, **kwargs)
[rank53]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank53]:     return forward_call(*args, **kwargs)
[rank53]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank53]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank53]:     output = func(self, *args, **kwargs)
[rank53]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank53]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 549, in forward
[rank53]:     layer_outputs = decoder_layer(
[rank53]:                     ^^^^^^^^^^^^^^
[rank53]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank30]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank30]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank30]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank30]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 190, in run
[rank30]:     self._optimizer_step(batch_idx, closure)
[rank30]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank30]:     call._call_lightning_module_hook(
[rank35]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 167, in _call_lightning_module_hook
[rank35]:     output = fn(*args, **kwargs)
[rank35]:              ^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank2]:     return forward_call(*args, **kwargs)
[rank2]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank2]:     output = func(self, *args, **kwargs)
[rank2]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 549, in forward
[rank2]:     layer_outputs = decoder_layer(
[rank2]:                     ^^^^^^^^^^^^^^
[rank2]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank63]:              ^^^^^^^^^^^^^^^^^^^
[rank22]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformer_engine/pytorch/optimizers/fused_adam.py", line 486, in step
[rank22]:     loss = closure()
[rank22]:            ^^^^^^^^^
[rank22]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 108, in _wrap_closure
[rank22]:     closure_result = closure()
[rank22]:                      ^^^^^^^^^
[rank22]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank22]:     self._result = self.closure(*args, **kwargs)
[rank22]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank22]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank25]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank25]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank25]:     return func(*args, **kwargs)
[rank25]:            ^^^^^^^^^^^^^^^^^^^^^
[rank25]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank25]:     outputs: BaseModelOutputWithPast = self.model(
[rank25]:                                        ^^^^^^^^^^^
[rank25]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank25]:     return self._call_impl(*args, **kwargs)
[rank25]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank53]:     return self._call_impl(*args, **kwargs)
[rank53]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank30]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 167, in _call_lightning_module_hook
[rank30]:     output = fn(*args, **kwargs)
[rank30]:              ^^^^^^^^^^^^^^^^^^^
[rank33]: Traceback (most recent call last):
[rank33]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 528, in <module>
[rank33]:     main()
[rank33]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 498, in main
[rank33]:     llm.api.finetune(
[rank33]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank33]:     return train(
[rank33]:            ^^^^^^
[rank33]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank33]:     trainer.fit(model, data)
[rank33]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank33]:     call._call_and_handle_interrupt(
[rank2]:     return self._call_impl(*args, **kwargs)
[rank2]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank2]:     return inner()
[rank63]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank63]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank63]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank63]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank63]:     outputs = self.forward(batch)
[rank63]:               ^^^^^^^^^^^^^^^^^^^
[rank63]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank63]:     return self.model(**batch)
[rank63]:            ^^^^^^^^^^^^^^^^^^^
[rank22]:     return func(*args, **kwargs)
[rank22]:            ^^^^^^^^^^^^^^^^^^^^^
[rank22]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank22]:     step_output = self._step_fn()
[rank22]:                   ^^^^^^^^^^^^^^^
[rank22]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank22]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank22]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank22]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank22]:     output = fn(*args, **kwargs)
[rank25]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank25]:     return forward_call(*args, **kwargs)
[rank25]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank25]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank25]:     output = func(self, *args, **kwargs)
[rank25]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank25]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 549, in forward
[rank25]:     layer_outputs = decoder_layer(
[rank25]:                     ^^^^^^^^^^^^^^
[rank25]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank53]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank53]:     return inner()
[rank53]:            ^^^^^^^
[rank53]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank53]:     result = forward_call(*args, **kwargs)
[rank53]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank53]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 259, in forward
[rank53]:     hidden_states = self.input_layernorm(hidden_states)
[rank53]:                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank53]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank31]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/module.py", line 1306, in optimizer_step
[rank31]:     optimizer.step(closure=optimizer_closure)
[rank31]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py", line 153, in step
[rank31]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank31]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank31]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py", line 238, in optimizer_step
[rank31]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank31]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank33]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank33]:     return trainer_fn(*args, **kwargs)
[rank33]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank33]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank33]:     self._run(model, ckpt_path=ckpt_path)
[rank33]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank33]:     results = self._run_stage()
[rank33]:               ^^^^^^^^^^^^^^^^^
[rank33]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank33]:     self.fit_loop.run()
[rank2]:            ^^^^^^^
[rank2]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank2]:     result = forward_call(*args, **kwargs)
[rank2]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 259, in forward
[rank2]:     hidden_states = self.input_layernorm(hidden_states)
[rank2]:                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank2]:     return self._call_impl(*args, **kwargs)
[rank2]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank63]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank63]:     return self._call_impl(*args, **kwargs)
[rank63]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank63]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank63]:     return inner()
[rank63]:            ^^^^^^^
[rank63]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank63]:     result = forward_call(*args, **kwargs)
[rank63]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank63]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank63]:     output = func(self, *args, **kwargs)
[rank22]:              ^^^^^^^^^^^^^^^^^^^
[rank25]:     return self._call_impl(*args, **kwargs)
[rank25]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank53]:     return self._call_impl(*args, **kwargs)
[rank53]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank53]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank53]:     return forward_call(*args, **kwargs)
[rank53]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank53]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 223, in forward
[rank53]:     variance = hidden_states.pow(2).mean(-1, keepdim=True)
[rank53]:                ^^^^^^^^^^^^^^^^^^^^
[rank31]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/amp.py", line 75, in optimizer_step
[rank31]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank31]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank31]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 122, in optimizer_step
[rank31]:     return optimizer.step(closure=closure, **kwargs)
[rank31]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank31]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/optim/optimizer.py", line 516, in wrapper
[rank31]:     out = func(*args, **kwargs)
[rank31]:           ^^^^^^^^^^^^^^^^^^^^^
[rank33]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank33]:     self.advance()
[rank33]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank33]:     self.epoch_loop.run(self._data_fetcher)
[rank33]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank33]:     self.advance(data_fetcher)
[rank33]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank33]:     super().advance(data_fetcher)
[rank2]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank2]:     return forward_call(*args, **kwargs)
[rank2]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 223, in forward
[rank2]:     variance = hidden_states.pow(2).mean(-1, keepdim=True)
[rank2]:                ^^^^^^^^^^^^^^^^^^^^
[rank63]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank63]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank63]:     return func(*args, **kwargs)
[rank63]:            ^^^^^^^^^^^^^^^^^^^^^
[rank63]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank63]:     outputs: BaseModelOutputWithPast = self.model(
[rank63]:                                        ^^^^^^^^^^^
[rank63]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank63]:     return self._call_impl(*args, **kwargs)
[rank63]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank21]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank21]:     return inner()
[rank21]:            ^^^^^^^
[rank21]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank21]:     result = forward_call(*args, **kwargs)
[rank21]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank21]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 259, in forward
[rank21]:     hidden_states = self.input_layernorm(hidden_states)
[rank21]:                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank21]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank25]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank25]:     return inner()
[rank25]:            ^^^^^^^
[rank25]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank25]:     result = forward_call(*args, **kwargs)
[rank25]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank25]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 259, in forward
[rank25]:     hidden_states = self.input_layernorm(hidden_states)
[rank25]:                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank25]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank53]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 640.00 MiB. GPU 1 has a total capacity of 79.19 GiB of which 367.81 MiB is free. Including non-PyTorch memory, this process has 78.82 GiB memory in use. Of the allocated memory 74.80 GiB is allocated by PyTorch, and 1.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank33]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank33]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank33]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank33]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 190, in run
[rank33]:     self._optimizer_step(batch_idx, closure)
[rank33]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank33]:     call._call_lightning_module_hook(
[rank2]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 640.00 MiB. GPU 2 has a total capacity of 79.19 GiB of which 475.81 MiB is free. Including non-PyTorch memory, this process has 78.71 GiB memory in use. Of the allocated memory 74.80 GiB is allocated by PyTorch, and 1.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank63]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank63]:     return forward_call(*args, **kwargs)
[rank63]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank63]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank63]:     output = func(self, *args, **kwargs)
[rank63]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank63]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 549, in forward
[rank63]:     layer_outputs = decoder_layer(
[rank63]:                     ^^^^^^^^^^^^^^
[rank63]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank21]:     return self._call_impl(*args, **kwargs)
[rank21]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank21]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank21]:     return forward_call(*args, **kwargs)
[rank21]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank21]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 223, in forward
[rank21]:     variance = hidden_states.pow(2).mean(-1, keepdim=True)
[rank21]:                ^^^^^^^^^^^^^^^^^^^^
[rank25]:     return self._call_impl(*args, **kwargs)
[rank25]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank25]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank25]:     return forward_call(*args, **kwargs)
[rank25]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank25]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 223, in forward
[rank25]:     variance = hidden_states.pow(2).mean(-1, keepdim=True)
[rank25]:                ^^^^^^^^^^^^^^^^^^^^
[rank52]: Traceback (most recent call last):
[rank52]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 528, in <module>
[rank52]:     main()
[rank52]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 498, in main
[rank52]:     llm.api.finetune(
[rank52]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank52]:     return train(
[rank52]:            ^^^^^^
[rank52]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank52]:     trainer.fit(model, data)
[rank52]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank52]:     call._call_and_handle_interrupt(
[rank33]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 167, in _call_lightning_module_hook
[rank33]:     output = fn(*args, **kwargs)
[rank33]:              ^^^^^^^^^^^^^^^^^^^
[rank63]:     return self._call_impl(*args, **kwargs)
[rank63]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank21]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 640.00 MiB. GPU 1 has a total capacity of 79.19 GiB of which 367.81 MiB is free. Including non-PyTorch memory, this process has 78.82 GiB memory in use. Of the allocated memory 74.80 GiB is allocated by PyTorch, and 1.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank25]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 640.00 MiB. GPU 1 has a total capacity of 79.19 GiB of which 367.81 MiB is free. Including non-PyTorch memory, this process has 78.82 GiB memory in use. Of the allocated memory 74.80 GiB is allocated by PyTorch, and 1.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank52]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank52]:     return trainer_fn(*args, **kwargs)
[rank52]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank52]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank52]:     self._run(model, ckpt_path=ckpt_path)
[rank52]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank52]:     results = self._run_stage()
[rank52]:               ^^^^^^^^^^^^^^^^^
[rank52]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank52]:     self.fit_loop.run()
[rank31]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformer_engine/pytorch/optimizers/fused_adam.py", line 486, in step
[rank31]:     loss = closure()
[rank31]:            ^^^^^^^^^
[rank31]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 108, in _wrap_closure
[rank31]:     closure_result = closure()
[rank31]:                      ^^^^^^^^^
[rank31]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank31]:     self._result = self.closure(*args, **kwargs)
[rank31]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank31]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank35]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/module.py", line 1306, in optimizer_step
[rank35]:     optimizer.step(closure=optimizer_closure)
[rank35]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py", line 153, in step
[rank35]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank35]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank35]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py", line 238, in optimizer_step
[rank35]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank35]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank63]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank63]:     return inner()
[rank63]:            ^^^^^^^
[rank63]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank63]:     result = forward_call(*args, **kwargs)
[rank63]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank63]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 259, in forward
[rank63]:     hidden_states = self.input_layernorm(hidden_states)
[rank63]:                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank63]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank22]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank22]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank22]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank22]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank22]:     outputs = self.forward(batch)
[rank22]:               ^^^^^^^^^^^^^^^^^^^
[rank22]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank22]:     return self.model(**batch)
[rank22]:            ^^^^^^^^^^^^^^^^^^^
[rank26]: Traceback (most recent call last):
[rank26]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 528, in <module>
[rank26]:     main()
[rank26]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 498, in main
[rank26]:     llm.api.finetune(
[rank26]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank26]:     return train(
[rank26]:            ^^^^^^
[rank26]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank26]:     trainer.fit(model, data)
[rank26]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank26]:     call._call_and_handle_interrupt(
[rank52]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank52]:     self.advance()
[rank52]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank52]:     self.epoch_loop.run(self._data_fetcher)
[rank52]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank52]:     self.advance(data_fetcher)
[rank52]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank52]:     super().advance(data_fetcher)
[rank31]:     return func(*args, **kwargs)
[rank31]:            ^^^^^^^^^^^^^^^^^^^^^
[rank31]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank31]:     step_output = self._step_fn()
[rank31]:                   ^^^^^^^^^^^^^^^
[rank31]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank31]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank31]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank31]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank31]:     output = fn(*args, **kwargs)
[rank35]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/amp.py", line 75, in optimizer_step
[rank35]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank35]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank35]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 122, in optimizer_step
[rank35]:     return optimizer.step(closure=closure, **kwargs)
[rank35]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank35]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/optim/optimizer.py", line 516, in wrapper
[rank35]:     out = func(*args, **kwargs)
[rank35]:           ^^^^^^^^^^^^^^^^^^^^^
[rank63]:     return self._call_impl(*args, **kwargs)
[rank63]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank63]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank63]:     return forward_call(*args, **kwargs)
[rank63]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank63]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 223, in forward
[rank63]:     variance = hidden_states.pow(2).mean(-1, keepdim=True)
[rank63]:                ^^^^^^^^^^^^^^^^^^^^
[rank22]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank22]:     return self._call_impl(*args, **kwargs)
[rank22]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank22]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank22]:     return inner()
[rank22]:            ^^^^^^^
[rank22]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank22]:     result = forward_call(*args, **kwargs)
[rank22]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank22]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank22]:     output = func(self, *args, **kwargs)
[rank52]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank52]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank52]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank52]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 190, in run
[rank52]:     self._optimizer_step(batch_idx, closure)
[rank52]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank52]:     call._call_lightning_module_hook(
[rank31]:              ^^^^^^^^^^^^^^^^^^^
[rank35]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformer_engine/pytorch/optimizers/fused_adam.py", line 486, in step
[rank35]:     loss = closure()
[rank35]:            ^^^^^^^^^
[rank35]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 108, in _wrap_closure
[rank35]:     closure_result = closure()
[rank35]:                      ^^^^^^^^^
[rank35]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank35]:     self._result = self.closure(*args, **kwargs)
[rank35]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank35]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank63]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 640.00 MiB. GPU 3 has a total capacity of 79.19 GiB of which 491.81 MiB is free. Including non-PyTorch memory, this process has 78.70 GiB memory in use. Of the allocated memory 74.80 GiB is allocated by PyTorch, and 1.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank22]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank22]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank22]:     return func(*args, **kwargs)
[rank22]:            ^^^^^^^^^^^^^^^^^^^^^
[rank22]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank22]:     outputs: BaseModelOutputWithPast = self.model(
[rank22]:                                        ^^^^^^^^^^^
[rank22]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank22]:     return self._call_impl(*args, **kwargs)
[rank22]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank52]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 167, in _call_lightning_module_hook
[rank52]:     output = fn(*args, **kwargs)
[rank52]:              ^^^^^^^^^^^^^^^^^^^
[rank29]: Traceback (most recent call last):
[rank29]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 528, in <module>
[rank29]:     main()
[rank29]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 498, in main
[rank29]:     llm.api.finetune(
[rank29]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank29]:     return train(
[rank29]:            ^^^^^^
[rank29]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank29]:     trainer.fit(model, data)
[rank29]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank29]:     call._call_and_handle_interrupt(
[rank35]:     return func(*args, **kwargs)
[rank35]:            ^^^^^^^^^^^^^^^^^^^^^
[rank35]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank35]:     step_output = self._step_fn()
[rank35]:                   ^^^^^^^^^^^^^^^
[rank35]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank35]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank35]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank35]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank35]:     output = fn(*args, **kwargs)
[rank61]: Traceback (most recent call last):
[rank61]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 528, in <module>
[rank61]:     main()
[rank61]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 498, in main
[rank61]:     llm.api.finetune(
[rank61]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank61]:     return train(
[rank61]:            ^^^^^^
[rank61]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank61]:     trainer.fit(model, data)
[rank61]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank61]:     call._call_and_handle_interrupt(
[rank22]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank22]:     return forward_call(*args, **kwargs)
[rank22]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank22]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank22]:     output = func(self, *args, **kwargs)
[rank22]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank22]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 549, in forward
[rank22]:     layer_outputs = decoder_layer(
[rank22]:                     ^^^^^^^^^^^^^^
[rank22]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank52]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/module.py", line 1306, in optimizer_step
[rank52]:     optimizer.step(closure=optimizer_closure)
[rank52]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py", line 153, in step
[rank52]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank52]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank52]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py", line 238, in optimizer_step
[rank52]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank52]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank29]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank29]:     return trainer_fn(*args, **kwargs)
[rank29]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank29]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank29]:     self._run(model, ckpt_path=ckpt_path)
[rank29]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank29]:     results = self._run_stage()
[rank29]:               ^^^^^^^^^^^^^^^^^
[rank29]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank29]:     self.fit_loop.run()
[rank35]:              ^^^^^^^^^^^^^^^^^^^
[rank61]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank61]:     return trainer_fn(*args, **kwargs)
[rank61]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank61]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank61]:     self._run(model, ckpt_path=ckpt_path)
[rank61]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank61]:     results = self._run_stage()
[rank61]:               ^^^^^^^^^^^^^^^^^
[rank61]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank61]:     self.fit_loop.run()
[rank22]:     return self._call_impl(*args, **kwargs)
[rank22]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank52]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/amp.py", line 75, in optimizer_step
[rank52]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank52]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank52]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 122, in optimizer_step
[rank52]:     return optimizer.step(closure=closure, **kwargs)
[rank52]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank52]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/optim/optimizer.py", line 516, in wrapper
[rank52]:     out = func(*args, **kwargs)
[rank52]:           ^^^^^^^^^^^^^^^^^^^^^
[rank29]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank29]:     self.advance()
[rank29]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank29]:     self.epoch_loop.run(self._data_fetcher)
[rank29]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank29]:     self.advance(data_fetcher)
[rank29]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank29]:     super().advance(data_fetcher)
[rank33]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/module.py", line 1306, in optimizer_step
[rank33]:     optimizer.step(closure=optimizer_closure)
[rank33]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py", line 153, in step
[rank33]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank33]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank33]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py", line 238, in optimizer_step
[rank33]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank33]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank22]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank22]:     return inner()
[rank22]:            ^^^^^^^
[rank22]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank22]:     result = forward_call(*args, **kwargs)
[rank22]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank22]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 259, in forward
[rank22]:     hidden_states = self.input_layernorm(hidden_states)
[rank22]:                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank22]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank26]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank26]:     return trainer_fn(*args, **kwargs)
[rank26]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank26]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank26]:     self._run(model, ckpt_path=ckpt_path)
[rank26]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank26]:     results = self._run_stage()
[rank26]:               ^^^^^^^^^^^^^^^^^
[rank26]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank26]:     self.fit_loop.run()
[rank52]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformer_engine/pytorch/optimizers/fused_adam.py", line 486, in step
[rank52]:     loss = closure()
[rank52]:            ^^^^^^^^^
[rank52]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 108, in _wrap_closure
[rank52]:     closure_result = closure()
[rank52]:                      ^^^^^^^^^
[rank52]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank52]:     self._result = self.closure(*args, **kwargs)
[rank52]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank52]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank29]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank29]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank29]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank29]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 190, in run
[rank29]:     self._optimizer_step(batch_idx, closure)
[rank29]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank29]:     call._call_lightning_module_hook(
[rank33]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/amp.py", line 75, in optimizer_step
[rank33]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank33]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank33]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 122, in optimizer_step
[rank33]:     return optimizer.step(closure=closure, **kwargs)
[rank33]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank33]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/optim/optimizer.py", line 516, in wrapper
[rank33]:     out = func(*args, **kwargs)
[rank33]:           ^^^^^^^^^^^^^^^^^^^^^
[rank58]: Traceback (most recent call last):
[rank58]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 528, in <module>
[rank58]:     main()
[rank58]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 498, in main
[rank58]:     llm.api.finetune(
[rank58]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank58]:     return train(
[rank58]:            ^^^^^^
[rank58]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank58]:     trainer.fit(model, data)
[rank58]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank58]:     call._call_and_handle_interrupt(
[rank22]:     return self._call_impl(*args, **kwargs)
[rank22]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank22]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank22]:     return forward_call(*args, **kwargs)
[rank22]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank22]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 223, in forward
[rank22]:     variance = hidden_states.pow(2).mean(-1, keepdim=True)
[rank22]:                ^^^^^^^^^^^^^^^^^^^^
[rank26]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank26]:     self.advance()
[rank26]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank26]:     self.epoch_loop.run(self._data_fetcher)
[rank26]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank26]:     self.advance(data_fetcher)
[rank26]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank26]:     super().advance(data_fetcher)
[rank52]:     return func(*args, **kwargs)
[rank52]:            ^^^^^^^^^^^^^^^^^^^^^
[rank52]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank52]:     step_output = self._step_fn()
[rank52]:                   ^^^^^^^^^^^^^^^
[rank52]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank52]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank52]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank52]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank52]:     output = fn(*args, **kwargs)
[rank29]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 167, in _call_lightning_module_hook
[rank29]:     output = fn(*args, **kwargs)
[rank29]:              ^^^^^^^^^^^^^^^^^^^
[rank33]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformer_engine/pytorch/optimizers/fused_adam.py", line 486, in step
[rank33]:     loss = closure()
[rank33]:            ^^^^^^^^^
[rank33]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 108, in _wrap_closure
[rank33]:     closure_result = closure()
[rank33]:                      ^^^^^^^^^
[rank33]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank33]:     self._result = self.closure(*args, **kwargs)
[rank33]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank33]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank0]: Traceback (most recent call last):
[rank0]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 528, in <module>
[rank0]:     main()
[rank0]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 498, in main
[rank0]:     llm.api.finetune(
[rank0]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank0]:     return train(
[rank0]:            ^^^^^^
[rank0]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank0]:     trainer.fit(model, data)
[rank0]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank0]:     call._call_and_handle_interrupt(
[rank61]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank61]:     self.advance()
[rank61]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank61]:     self.epoch_loop.run(self._data_fetcher)
[rank61]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank61]:     self.advance(data_fetcher)
[rank61]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank61]:     super().advance(data_fetcher)
[rank22]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 640.00 MiB. GPU 2 has a total capacity of 79.19 GiB of which 395.81 MiB is free. Including non-PyTorch memory, this process has 78.79 GiB memory in use. Of the allocated memory 74.80 GiB is allocated by PyTorch, and 1.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank26]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank26]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank26]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank26]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 190, in run
[rank26]:     self._optimizer_step(batch_idx, closure)
[rank26]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank26]:     call._call_lightning_module_hook(
[rank52]:              ^^^^^^^^^^^^^^^^^^^
[rank30]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/module.py", line 1306, in optimizer_step
[rank30]:     optimizer.step(closure=optimizer_closure)
[rank30]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py", line 153, in step
[rank30]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank30]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank30]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py", line 238, in optimizer_step
[rank30]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank30]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank33]:     return func(*args, **kwargs)
[rank33]:            ^^^^^^^^^^^^^^^^^^^^^
[rank33]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank33]:     step_output = self._step_fn()
[rank33]:                   ^^^^^^^^^^^^^^^
[rank33]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank33]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank33]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank33]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank33]:     output = fn(*args, **kwargs)
[rank0]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank0]:     return trainer_fn(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank0]:     self._run(model, ckpt_path=ckpt_path)
[rank0]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank0]:     results = self._run_stage()
[rank0]:               ^^^^^^^^^^^^^^^^^
[rank0]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank0]:     self.fit_loop.run()
[rank26]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 167, in _call_lightning_module_hook
[rank26]:     output = fn(*args, **kwargs)
[rank26]:              ^^^^^^^^^^^^^^^^^^^
[rank52]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank52]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank52]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank52]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank52]:     outputs = self.forward(batch)
[rank52]:               ^^^^^^^^^^^^^^^^^^^
[rank52]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank52]:     return self.model(**batch)
[rank52]:            ^^^^^^^^^^^^^^^^^^^
[rank30]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/amp.py", line 75, in optimizer_step
[rank30]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank30]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank30]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 122, in optimizer_step
[rank30]:     return optimizer.step(closure=closure, **kwargs)
[rank30]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank30]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/optim/optimizer.py", line 516, in wrapper
[rank30]:     out = func(*args, **kwargs)
[rank30]:           ^^^^^^^^^^^^^^^^^^^^^
[rank33]:              ^^^^^^^^^^^^^^^^^^^
[rank26]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/module.py", line 1306, in optimizer_step
[rank26]:     optimizer.step(closure=optimizer_closure)
[rank26]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py", line 153, in step
[rank26]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank26]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank26]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py", line 238, in optimizer_step
[rank26]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank26]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank52]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank52]:     return self._call_impl(*args, **kwargs)
[rank52]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank52]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank52]:     return inner()
[rank52]:            ^^^^^^^
[rank52]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank52]:     result = forward_call(*args, **kwargs)
[rank52]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank52]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank52]:     output = func(self, *args, **kwargs)
[rank30]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformer_engine/pytorch/optimizers/fused_adam.py", line 486, in step
[rank30]:     loss = closure()
[rank30]:            ^^^^^^^^^
[rank30]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 108, in _wrap_closure
[rank30]:     closure_result = closure()
[rank30]:                      ^^^^^^^^^
[rank30]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank30]:     self._result = self.closure(*args, **kwargs)
[rank30]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank30]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank34]: Traceback (most recent call last):
[rank34]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 528, in <module>
[rank34]:     main()
[rank34]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 498, in main
[rank34]:     llm.api.finetune(
[rank34]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank34]:     return train(
[rank34]:            ^^^^^^
[rank34]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank34]:     trainer.fit(model, data)
[rank34]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank34]:     call._call_and_handle_interrupt(
[rank58]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank58]:     return trainer_fn(*args, **kwargs)
[rank58]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank58]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank58]:     self._run(model, ckpt_path=ckpt_path)
[rank58]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank58]:     results = self._run_stage()
[rank58]:               ^^^^^^^^^^^^^^^^^
[rank58]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank58]:     self.fit_loop.run()
[rank0]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank0]:     self.advance()
[rank0]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank0]:     self.epoch_loop.run(self._data_fetcher)
[rank0]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank0]:     self.advance(data_fetcher)
[rank0]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank0]:     super().advance(data_fetcher)
[rank26]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/amp.py", line 75, in optimizer_step
[rank26]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank26]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank26]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 122, in optimizer_step
[rank26]:     return optimizer.step(closure=closure, **kwargs)
[rank26]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank26]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/optim/optimizer.py", line 516, in wrapper
[rank26]:     out = func(*args, **kwargs)
[rank26]:           ^^^^^^^^^^^^^^^^^^^^^
[rank52]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank52]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank52]:     return func(*args, **kwargs)
[rank52]:            ^^^^^^^^^^^^^^^^^^^^^
[rank52]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank52]:     outputs: BaseModelOutputWithPast = self.model(
[rank52]:                                        ^^^^^^^^^^^
[rank52]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank52]:     return self._call_impl(*args, **kwargs)
[rank52]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank30]:     return func(*args, **kwargs)
[rank30]:            ^^^^^^^^^^^^^^^^^^^^^
[rank30]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank30]:     step_output = self._step_fn()
[rank30]:                   ^^^^^^^^^^^^^^^
[rank30]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank30]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank30]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank30]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank30]:     output = fn(*args, **kwargs)
[rank34]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank34]:     return trainer_fn(*args, **kwargs)
[rank34]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank34]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank34]:     self._run(model, ckpt_path=ckpt_path)
[rank34]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank34]:     results = self._run_stage()
[rank34]:               ^^^^^^^^^^^^^^^^^
[rank34]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank34]:     self.fit_loop.run()
[rank58]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank58]:     self.advance()
[rank58]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank58]:     self.epoch_loop.run(self._data_fetcher)
[rank58]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank58]:     self.advance(data_fetcher)
[rank58]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank58]:     super().advance(data_fetcher)
[rank0]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank0]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank0]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 190, in run
[rank0]:     self._optimizer_step(batch_idx, closure)
[rank0]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank0]:     call._call_lightning_module_hook(
[rank26]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformer_engine/pytorch/optimizers/fused_adam.py", line 486, in step
[rank26]:     loss = closure()
[rank26]:            ^^^^^^^^^
[rank26]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 108, in _wrap_closure
[rank26]:     closure_result = closure()
[rank26]:                      ^^^^^^^^^
[rank26]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank26]:     self._result = self.closure(*args, **kwargs)
[rank26]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank26]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank52]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank52]:     return forward_call(*args, **kwargs)
[rank52]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank52]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank52]:     output = func(self, *args, **kwargs)
[rank52]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank52]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 549, in forward
[rank52]:     layer_outputs = decoder_layer(
[rank52]:                     ^^^^^^^^^^^^^^
[rank52]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank30]:              ^^^^^^^^^^^^^^^^^^^
[rank34]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank34]:     self.advance()
[rank34]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank34]:     self.epoch_loop.run(self._data_fetcher)
[rank34]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank34]:     self.advance(data_fetcher)
[rank34]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank34]:     super().advance(data_fetcher)
[rank58]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank58]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank58]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank58]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 190, in run
[rank58]:     self._optimizer_step(batch_idx, closure)
[rank58]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank58]:     call._call_lightning_module_hook(
[rank0]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 167, in _call_lightning_module_hook
[rank0]:     output = fn(*args, **kwargs)
[rank0]:              ^^^^^^^^^^^^^^^^^^^
[rank61]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank61]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank61]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank61]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 190, in run
[rank61]:     self._optimizer_step(batch_idx, closure)
[rank61]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank61]:     call._call_lightning_module_hook(
[rank26]:     return func(*args, **kwargs)
[rank26]:            ^^^^^^^^^^^^^^^^^^^^^
[rank26]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank26]:     step_output = self._step_fn()
[rank26]:                   ^^^^^^^^^^^^^^^
[rank26]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank26]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank26]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank26]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank26]:     output = fn(*args, **kwargs)
[rank52]:     return self._call_impl(*args, **kwargs)
[rank52]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank31]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank31]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank31]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank31]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank31]:     outputs = self.forward(batch)
[rank31]:               ^^^^^^^^^^^^^^^^^^^
[rank31]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank31]:     return self.model(**batch)
[rank31]:            ^^^^^^^^^^^^^^^^^^^
[rank34]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank34]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank34]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank34]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 190, in run
[rank34]:     self._optimizer_step(batch_idx, closure)
[rank34]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank34]:     call._call_lightning_module_hook(
[rank58]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 167, in _call_lightning_module_hook
[rank58]:     output = fn(*args, **kwargs)
[rank58]:              ^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/module.py", line 1306, in optimizer_step
[rank0]:     optimizer.step(closure=optimizer_closure)
[rank0]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py", line 153, in step
[rank0]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank0]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py", line 238, in optimizer_step
[rank0]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank61]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 167, in _call_lightning_module_hook
[rank61]:     output = fn(*args, **kwargs)
[rank61]:              ^^^^^^^^^^^^^^^^^^^
[rank26]:              ^^^^^^^^^^^^^^^^^^^
[rank52]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank52]:     return inner()
[rank52]:            ^^^^^^^
[rank52]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank52]:     result = forward_call(*args, **kwargs)
[rank52]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank52]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 259, in forward
[rank52]:     hidden_states = self.input_layernorm(hidden_states)
[rank52]:                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank52]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank31]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank31]:     return self._call_impl(*args, **kwargs)
[rank31]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank31]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank31]:     return inner()
[rank31]:            ^^^^^^^
[rank31]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank31]:     result = forward_call(*args, **kwargs)
[rank31]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank31]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank31]:     output = func(self, *args, **kwargs)
[rank34]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 167, in _call_lightning_module_hook
[rank34]:     output = fn(*args, **kwargs)
[rank34]:              ^^^^^^^^^^^^^^^^^^^
[rank58]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/module.py", line 1306, in optimizer_step
[rank58]:     optimizer.step(closure=optimizer_closure)
[rank58]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py", line 153, in step
[rank58]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank58]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank58]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py", line 238, in optimizer_step
[rank58]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank58]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/amp.py", line 75, in optimizer_step
[rank0]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 122, in optimizer_step
[rank0]:     return optimizer.step(closure=closure, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/optim/optimizer.py", line 516, in wrapper
[rank0]:     out = func(*args, **kwargs)
[rank0]:           ^^^^^^^^^^^^^^^^^^^^^
[rank61]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/module.py", line 1306, in optimizer_step
[rank61]:     optimizer.step(closure=optimizer_closure)
[rank61]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py", line 153, in step
[rank61]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank61]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank61]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py", line 238, in optimizer_step
[rank61]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank61]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank26]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank26]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank26]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank26]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank26]:     outputs = self.forward(batch)
[rank26]:               ^^^^^^^^^^^^^^^^^^^
[rank26]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank26]:     return self.model(**batch)
[rank26]:            ^^^^^^^^^^^^^^^^^^^
[rank52]:     return self._call_impl(*args, **kwargs)
[rank52]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank52]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank52]:     return forward_call(*args, **kwargs)
[rank52]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank52]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 223, in forward
[rank52]:     variance = hidden_states.pow(2).mean(-1, keepdim=True)
[rank52]:                ^^^^^^^^^^^^^^^^^^^^
[rank31]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank31]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank31]:     return func(*args, **kwargs)
[rank31]:            ^^^^^^^^^^^^^^^^^^^^^
[rank31]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank31]:     outputs: BaseModelOutputWithPast = self.model(
[rank31]:                                        ^^^^^^^^^^^
[rank31]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank31]:     return self._call_impl(*args, **kwargs)
[rank31]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank35]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank35]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank35]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank35]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank35]:     outputs = self.forward(batch)
[rank35]:               ^^^^^^^^^^^^^^^^^^^
[rank35]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank35]:     return self.model(**batch)
[rank35]:            ^^^^^^^^^^^^^^^^^^^
[rank58]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/amp.py", line 75, in optimizer_step
[rank58]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank58]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank58]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 122, in optimizer_step
[rank58]:     return optimizer.step(closure=closure, **kwargs)
[rank58]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank58]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/optim/optimizer.py", line 516, in wrapper
[rank58]:     out = func(*args, **kwargs)
[rank58]:           ^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformer_engine/pytorch/optimizers/fused_adam.py", line 486, in step
[rank0]:     loss = closure()
[rank0]:            ^^^^^^^^^
[rank0]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 108, in _wrap_closure
[rank0]:     closure_result = closure()
[rank0]:                      ^^^^^^^^^
[rank0]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank0]:     self._result = self.closure(*args, **kwargs)
[rank0]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank61]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/amp.py", line 75, in optimizer_step
[rank61]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank61]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank61]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 122, in optimizer_step
[rank61]:     return optimizer.step(closure=closure, **kwargs)
[rank61]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank61]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/optim/optimizer.py", line 516, in wrapper
[rank61]:     out = func(*args, **kwargs)
[rank61]:           ^^^^^^^^^^^^^^^^^^^^^
[rank26]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank26]:     return self._call_impl(*args, **kwargs)
[rank26]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank26]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank26]:     return inner()
[rank26]:            ^^^^^^^
[rank26]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank26]:     result = forward_call(*args, **kwargs)
[rank26]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank26]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank26]:     output = func(self, *args, **kwargs)
[rank52]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 640.00 MiB. GPU 0 has a total capacity of 79.19 GiB of which 399.81 MiB is free. Including non-PyTorch memory, this process has 78.79 GiB memory in use. Of the allocated memory 74.80 GiB is allocated by PyTorch, and 1.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank31]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank31]:     return forward_call(*args, **kwargs)
[rank31]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank31]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank31]:     output = func(self, *args, **kwargs)
[rank31]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank31]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 549, in forward
[rank31]:     layer_outputs = decoder_layer(
[rank31]:                     ^^^^^^^^^^^^^^
[rank31]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank35]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank35]:     return self._call_impl(*args, **kwargs)
[rank35]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank35]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank35]:     return inner()
[rank35]:            ^^^^^^^
[rank35]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank35]:     result = forward_call(*args, **kwargs)
[rank35]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank35]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank35]:     output = func(self, *args, **kwargs)
[rank58]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformer_engine/pytorch/optimizers/fused_adam.py", line 486, in step
[rank58]:     loss = closure()
[rank58]:            ^^^^^^^^^
[rank58]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 108, in _wrap_closure
[rank58]:     closure_result = closure()
[rank58]:                      ^^^^^^^^^
[rank58]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank58]:     self._result = self.closure(*args, **kwargs)
[rank58]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank58]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank0]:     return func(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank0]:     step_output = self._step_fn()
[rank0]:                   ^^^^^^^^^^^^^^^
[rank0]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank0]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank0]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank0]:     output = fn(*args, **kwargs)
[rank48]: Traceback (most recent call last):
[rank48]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 528, in <module>
[rank48]:     main()
[rank48]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 498, in main
[rank48]:     llm.api.finetune(
[rank48]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank48]:     return train(
[rank48]:            ^^^^^^
[rank48]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank48]:     trainer.fit(model, data)
[rank48]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank48]:     call._call_and_handle_interrupt(
[rank61]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformer_engine/pytorch/optimizers/fused_adam.py", line 486, in step
[rank61]:     loss = closure()
[rank61]:            ^^^^^^^^^
[rank61]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 108, in _wrap_closure
[rank61]:     closure_result = closure()
[rank61]:                      ^^^^^^^^^
[rank61]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank61]:     self._result = self.closure(*args, **kwargs)
[rank61]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank61]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank26]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank26]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank26]:     return func(*args, **kwargs)
[rank26]:            ^^^^^^^^^^^^^^^^^^^^^
[rank26]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank26]:     outputs: BaseModelOutputWithPast = self.model(
[rank26]:                                        ^^^^^^^^^^^
[rank26]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank26]:     return self._call_impl(*args, **kwargs)
[rank26]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank31]:     return self._call_impl(*args, **kwargs)
[rank31]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank35]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank35]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank35]:     return func(*args, **kwargs)
[rank35]:            ^^^^^^^^^^^^^^^^^^^^^
[rank35]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank35]:     outputs: BaseModelOutputWithPast = self.model(
[rank35]:                                        ^^^^^^^^^^^
[rank35]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank35]:     return self._call_impl(*args, **kwargs)
[rank35]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank58]:     return func(*args, **kwargs)
[rank58]:            ^^^^^^^^^^^^^^^^^^^^^
[rank58]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank58]:     step_output = self._step_fn()
[rank58]:                   ^^^^^^^^^^^^^^^
[rank58]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank58]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank58]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank58]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank58]:     output = fn(*args, **kwargs)
[rank0]:              ^^^^^^^^^^^^^^^^^^^
[rank61]:     return func(*args, **kwargs)
[rank61]:            ^^^^^^^^^^^^^^^^^^^^^
[rank61]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank61]:     step_output = self._step_fn()
[rank61]:                   ^^^^^^^^^^^^^^^
[rank61]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank61]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank61]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank61]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank61]:     output = fn(*args, **kwargs)
[rank26]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank26]:     return forward_call(*args, **kwargs)
[rank26]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank26]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank26]:     output = func(self, *args, **kwargs)
[rank26]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank26]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 549, in forward
[rank26]:     layer_outputs = decoder_layer(
[rank26]:                     ^^^^^^^^^^^^^^
[rank26]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank35]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank35]:     return forward_call(*args, **kwargs)
[rank35]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank35]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank35]:     output = func(self, *args, **kwargs)
[rank35]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank35]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 549, in forward
[rank35]:     layer_outputs = decoder_layer(
[rank35]:                     ^^^^^^^^^^^^^^
[rank35]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank58]:              ^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank0]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank0]:     outputs = self.forward(batch)
[rank0]:               ^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank0]:     return self.model(**batch)
[rank0]:            ^^^^^^^^^^^^^^^^^^^
[rank61]:              ^^^^^^^^^^^^^^^^^^^
[rank26]:     return self._call_impl(*args, **kwargs)
[rank26]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank35]:     return self._call_impl(*args, **kwargs)
[rank35]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank58]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank58]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank58]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank58]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank58]:     outputs = self.forward(batch)
[rank58]:               ^^^^^^^^^^^^^^^^^^^
[rank58]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank58]:     return self.model(**batch)
[rank58]:            ^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank0]:     return inner()
[rank0]:            ^^^^^^^
[rank0]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank0]:     result = forward_call(*args, **kwargs)
[rank0]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank0]:     output = func(self, *args, **kwargs)
[rank60]: Traceback (most recent call last):
[rank60]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 528, in <module>
[rank60]:     main()
[rank60]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 498, in main
[rank60]:     llm.api.finetune(
[rank60]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank60]:     return train(
[rank60]:            ^^^^^^
[rank60]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank60]:     trainer.fit(model, data)
[rank60]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank60]:     call._call_and_handle_interrupt(
[rank26]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank26]:     return inner()
[rank26]:            ^^^^^^^
[rank26]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank26]:     result = forward_call(*args, **kwargs)
[rank26]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank26]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 259, in forward
[rank26]:     hidden_states = self.input_layernorm(hidden_states)
[rank26]:                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank26]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank29]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/module.py", line 1306, in optimizer_step
[rank29]:     optimizer.step(closure=optimizer_closure)
[rank29]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py", line 153, in step
[rank29]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank29]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank29]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py", line 238, in optimizer_step
[rank29]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank29]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank33]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank33]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank33]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank33]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank33]:     outputs = self.forward(batch)
[rank33]:               ^^^^^^^^^^^^^^^^^^^
[rank33]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank33]:     return self.model(**batch)
[rank33]:            ^^^^^^^^^^^^^^^^^^^
[rank58]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank58]:     return self._call_impl(*args, **kwargs)
[rank58]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank58]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank58]:     return inner()
[rank58]:            ^^^^^^^
[rank58]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank58]:     result = forward_call(*args, **kwargs)
[rank58]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank58]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank58]:     output = func(self, *args, **kwargs)
[rank0]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank0]:     return func(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank0]:     outputs: BaseModelOutputWithPast = self.model(
[rank0]:                                        ^^^^^^^^^^^
[rank0]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank60]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank60]:     return trainer_fn(*args, **kwargs)
[rank60]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank60]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank60]:     self._run(model, ckpt_path=ckpt_path)
[rank60]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank60]:     results = self._run_stage()
[rank60]:               ^^^^^^^^^^^^^^^^^
[rank60]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank60]:     self.fit_loop.run()
[rank26]:     return self._call_impl(*args, **kwargs)
[rank26]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank26]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank26]:     return forward_call(*args, **kwargs)
[rank26]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank26]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 223, in forward
[rank26]:     variance = hidden_states.pow(2).mean(-1, keepdim=True)
[rank26]:                ^^^^^^^^^^^^^^^^^^^^
[rank29]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/amp.py", line 75, in optimizer_step
[rank29]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank29]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank29]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 122, in optimizer_step
[rank29]:     return optimizer.step(closure=closure, **kwargs)
[rank29]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank29]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/optim/optimizer.py", line 516, in wrapper
[rank29]:     out = func(*args, **kwargs)
[rank29]:           ^^^^^^^^^^^^^^^^^^^^^
[rank33]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank33]:     return self._call_impl(*args, **kwargs)
[rank33]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank33]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank33]:     return inner()
[rank33]:            ^^^^^^^
[rank33]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank33]:     result = forward_call(*args, **kwargs)
[rank33]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank33]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank33]:     output = func(self, *args, **kwargs)
[rank58]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank58]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank58]:     return func(*args, **kwargs)
[rank58]:            ^^^^^^^^^^^^^^^^^^^^^
[rank58]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank58]:     outputs: BaseModelOutputWithPast = self.model(
[rank58]:                                        ^^^^^^^^^^^
[rank58]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank58]:     return self._call_impl(*args, **kwargs)
[rank58]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank0]:     output = func(self, *args, **kwargs)
[rank0]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 549, in forward
[rank0]:     layer_outputs = decoder_layer(
[rank0]:                     ^^^^^^^^^^^^^^
[rank0]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank60]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank60]:     self.advance()
[rank60]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank60]:     self.epoch_loop.run(self._data_fetcher)
[rank60]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank60]:     self.advance(data_fetcher)
[rank60]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank60]:     super().advance(data_fetcher)
[rank26]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 640.00 MiB. GPU 2 has a total capacity of 79.19 GiB of which 395.81 MiB is free. Including non-PyTorch memory, this process has 78.79 GiB memory in use. Of the allocated memory 74.80 GiB is allocated by PyTorch, and 1.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank29]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformer_engine/pytorch/optimizers/fused_adam.py", line 486, in step
[rank29]:     loss = closure()
[rank29]:            ^^^^^^^^^
[rank29]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 108, in _wrap_closure
[rank29]:     closure_result = closure()
[rank29]:                      ^^^^^^^^^
[rank29]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank29]:     self._result = self.closure(*args, **kwargs)
[rank29]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank29]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank33]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank33]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank33]:     return func(*args, **kwargs)
[rank33]:            ^^^^^^^^^^^^^^^^^^^^^
[rank33]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank33]:     outputs: BaseModelOutputWithPast = self.model(
[rank33]:                                        ^^^^^^^^^^^
[rank33]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank33]:     return self._call_impl(*args, **kwargs)
[rank33]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank58]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank58]:     return forward_call(*args, **kwargs)
[rank58]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank58]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank58]:     output = func(self, *args, **kwargs)
[rank58]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank58]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 549, in forward
[rank58]:     layer_outputs = decoder_layer(
[rank58]:                     ^^^^^^^^^^^^^^
[rank58]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank0]:     return inner()
[rank48]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank48]:     return trainer_fn(*args, **kwargs)
[rank48]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank48]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank48]:     self._run(model, ckpt_path=ckpt_path)
[rank48]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank48]:     results = self._run_stage()
[rank48]:               ^^^^^^^^^^^^^^^^^
[rank48]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank48]:     self.fit_loop.run()
[rank60]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank60]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank60]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank60]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 190, in run
[rank60]:     self._optimizer_step(batch_idx, closure)
[rank60]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank60]:     call._call_lightning_module_hook(
[rank29]:     return func(*args, **kwargs)
[rank29]:            ^^^^^^^^^^^^^^^^^^^^^
[rank29]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank29]:     step_output = self._step_fn()
[rank29]:                   ^^^^^^^^^^^^^^^
[rank29]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank29]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank29]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank29]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank29]:     output = fn(*args, **kwargs)
[rank33]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank33]:     return forward_call(*args, **kwargs)
[rank33]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank33]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank33]:     output = func(self, *args, **kwargs)
[rank33]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank33]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 549, in forward
[rank33]:     layer_outputs = decoder_layer(
[rank33]:                     ^^^^^^^^^^^^^^
[rank33]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank58]:     return self._call_impl(*args, **kwargs)
[rank58]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:            ^^^^^^^
[rank0]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank0]:     result = forward_call(*args, **kwargs)
[rank0]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 259, in forward
[rank0]:     hidden_states = self.input_layernorm(hidden_states)
[rank0]:                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank48]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank48]:     self.advance()
[rank48]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank48]:     self.epoch_loop.run(self._data_fetcher)
[rank48]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank48]:     self.advance(data_fetcher)
[rank48]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank48]:     super().advance(data_fetcher)
[rank60]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 167, in _call_lightning_module_hook
[rank60]:     output = fn(*args, **kwargs)
[rank60]:              ^^^^^^^^^^^^^^^^^^^
[rank29]:              ^^^^^^^^^^^^^^^^^^^
[rank33]:     return self._call_impl(*args, **kwargs)
[rank33]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank58]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank58]:     return inner()
[rank58]:            ^^^^^^^
[rank58]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank58]:     result = forward_call(*args, **kwargs)
[rank58]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank58]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 259, in forward
[rank58]:     hidden_states = self.input_layernorm(hidden_states)
[rank58]:                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank58]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank0]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 223, in forward
[rank0]:     variance = hidden_states.pow(2).mean(-1, keepdim=True)
[rank0]:                ^^^^^^^^^^^^^^^^^^^^
[rank48]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank48]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank48]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank48]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 190, in run
[rank48]:     self._optimizer_step(batch_idx, closure)
[rank48]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank48]:     call._call_lightning_module_hook(
[rank61]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank61]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank61]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank61]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank61]:     outputs = self.forward(batch)
[rank61]:               ^^^^^^^^^^^^^^^^^^^
[rank61]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank61]:     return self.model(**batch)
[rank61]:            ^^^^^^^^^^^^^^^^^^^
[rank30]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank30]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank30]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank30]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank30]:     outputs = self.forward(batch)
[rank30]:               ^^^^^^^^^^^^^^^^^^^
[rank30]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank30]:     return self.model(**batch)
[rank30]:            ^^^^^^^^^^^^^^^^^^^
[rank34]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/module.py", line 1306, in optimizer_step
[rank34]:     optimizer.step(closure=optimizer_closure)
[rank34]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py", line 153, in step
[rank34]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank34]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank34]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py", line 238, in optimizer_step
[rank34]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank34]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank58]:     return self._call_impl(*args, **kwargs)
[rank58]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank58]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank58]:     return forward_call(*args, **kwargs)
[rank58]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank58]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 223, in forward
[rank58]:     variance = hidden_states.pow(2).mean(-1, keepdim=True)
[rank58]:                ^^^^^^^^^^^^^^^^^^^^
[rank0]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 640.00 MiB. GPU 0 has a total capacity of 79.19 GiB of which 479.81 MiB is free. Including non-PyTorch memory, this process has 78.71 GiB memory in use. Of the allocated memory 74.80 GiB is allocated by PyTorch, and 1.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank48]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 167, in _call_lightning_module_hook
[rank48]:     output = fn(*args, **kwargs)
[rank48]:              ^^^^^^^^^^^^^^^^^^^
[rank61]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank61]:     return self._call_impl(*args, **kwargs)
[rank61]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank61]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank61]:     return inner()
[rank61]:            ^^^^^^^
[rank61]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank61]:     result = forward_call(*args, **kwargs)
[rank61]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank61]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank61]:     output = func(self, *args, **kwargs)
[rank30]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank30]:     return self._call_impl(*args, **kwargs)
[rank30]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank30]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank30]:     return inner()
[rank30]:            ^^^^^^^
[rank30]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank30]:     result = forward_call(*args, **kwargs)
[rank30]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank30]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank30]:     output = func(self, *args, **kwargs)
[rank58]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 640.00 MiB. GPU 2 has a total capacity of 79.19 GiB of which 395.81 MiB is free. Including non-PyTorch memory, this process has 78.79 GiB memory in use. Of the allocated memory 74.80 GiB is allocated by PyTorch, and 1.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank48]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/module.py", line 1306, in optimizer_step
[rank48]:     optimizer.step(closure=optimizer_closure)
[rank48]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py", line 153, in step
[rank48]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank48]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank48]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py", line 238, in optimizer_step
[rank48]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank48]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank61]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank61]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank61]:     return func(*args, **kwargs)
[rank61]:            ^^^^^^^^^^^^^^^^^^^^^
[rank61]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank61]:     outputs: BaseModelOutputWithPast = self.model(
[rank61]:                                        ^^^^^^^^^^^
[rank61]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank61]:     return self._call_impl(*args, **kwargs)
[rank61]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank30]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank30]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank30]:     return func(*args, **kwargs)
[rank30]:            ^^^^^^^^^^^^^^^^^^^^^
[rank30]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank30]:     outputs: BaseModelOutputWithPast = self.model(
[rank30]:                                        ^^^^^^^^^^^
[rank30]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank30]:     return self._call_impl(*args, **kwargs)
[rank30]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank48]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/amp.py", line 75, in optimizer_step
[rank48]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank48]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank48]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 122, in optimizer_step
[rank48]:     return optimizer.step(closure=closure, **kwargs)
[rank48]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank48]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/optim/optimizer.py", line 516, in wrapper
[rank48]:     out = func(*args, **kwargs)
[rank48]:           ^^^^^^^^^^^^^^^^^^^^^
[rank61]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank61]:     return forward_call(*args, **kwargs)
[rank61]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank61]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank61]:     output = func(self, *args, **kwargs)
[rank61]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank61]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 549, in forward
[rank61]:     layer_outputs = decoder_layer(
[rank61]:                     ^^^^^^^^^^^^^^
[rank61]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank19]: Traceback (most recent call last):
[rank19]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 528, in <module>
[rank19]:     main()
[rank19]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 498, in main
[rank19]:     llm.api.finetune(
[rank19]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank19]:     return train(
[rank19]:            ^^^^^^
[rank19]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank19]:     trainer.fit(model, data)
[rank19]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank19]:     call._call_and_handle_interrupt(
[rank30]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank30]:     return forward_call(*args, **kwargs)
[rank30]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank30]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank30]:     output = func(self, *args, **kwargs)
[rank30]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank30]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 549, in forward
[rank30]:     layer_outputs = decoder_layer(
[rank30]:                     ^^^^^^^^^^^^^^
[rank30]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank34]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/amp.py", line 75, in optimizer_step
[rank34]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank34]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank34]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 122, in optimizer_step
[rank34]:     return optimizer.step(closure=closure, **kwargs)
[rank34]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank34]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/optim/optimizer.py", line 516, in wrapper
[rank34]:     out = func(*args, **kwargs)
[rank34]:           ^^^^^^^^^^^^^^^^^^^^^
[rank48]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformer_engine/pytorch/optimizers/fused_adam.py", line 486, in step
[rank48]:     loss = closure()
[rank48]:            ^^^^^^^^^
[rank48]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 108, in _wrap_closure
[rank48]:     closure_result = closure()
[rank48]:                      ^^^^^^^^^
[rank48]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank48]:     self._result = self.closure(*args, **kwargs)
[rank48]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank48]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank61]:     return self._call_impl(*args, **kwargs)
[rank61]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank30]:     return self._call_impl(*args, **kwargs)
[rank30]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank34]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformer_engine/pytorch/optimizers/fused_adam.py", line 486, in step
[rank34]:     loss = closure()
[rank34]:            ^^^^^^^^^
[rank34]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 108, in _wrap_closure
[rank34]:     closure_result = closure()
[rank34]:                      ^^^^^^^^^
[rank34]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank34]:     self._result = self.closure(*args, **kwargs)
[rank34]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank34]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank48]:     return func(*args, **kwargs)
[rank48]:            ^^^^^^^^^^^^^^^^^^^^^
[rank48]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank48]:     step_output = self._step_fn()
[rank48]:                   ^^^^^^^^^^^^^^^
[rank48]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank48]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank48]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank48]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank48]:     output = fn(*args, **kwargs)
[rank60]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/module.py", line 1306, in optimizer_step
[rank60]:     optimizer.step(closure=optimizer_closure)
[rank60]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py", line 153, in step
[rank60]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank60]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank60]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py", line 238, in optimizer_step
[rank60]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank60]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank31]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank31]:     return inner()
[rank31]:            ^^^^^^^
[rank31]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank31]:     result = forward_call(*args, **kwargs)
[rank31]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank31]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 259, in forward
[rank31]:     hidden_states = self.input_layernorm(hidden_states)
[rank31]:                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank31]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank34]:     return func(*args, **kwargs)
[rank34]:            ^^^^^^^^^^^^^^^^^^^^^
[rank34]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank34]:     step_output = self._step_fn()
[rank34]:                   ^^^^^^^^^^^^^^^
[rank34]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank34]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank34]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank34]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank34]:     output = fn(*args, **kwargs)
[rank48]:              ^^^^^^^^^^^^^^^^^^^
[rank60]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/amp.py", line 75, in optimizer_step
[rank60]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank60]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank60]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 122, in optimizer_step
[rank60]:     return optimizer.step(closure=closure, **kwargs)
[rank60]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank60]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/optim/optimizer.py", line 516, in wrapper
[rank60]:     out = func(*args, **kwargs)
[rank60]:           ^^^^^^^^^^^^^^^^^^^^^
[rank19]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank19]:     return trainer_fn(*args, **kwargs)
[rank19]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank19]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank19]:     self._run(model, ckpt_path=ckpt_path)
[rank19]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank19]:     results = self._run_stage()
[rank19]:               ^^^^^^^^^^^^^^^^^
[rank19]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank19]:     self.fit_loop.run()
[rank31]:     return self._call_impl(*args, **kwargs)
[rank31]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank31]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank31]:     return forward_call(*args, **kwargs)
[rank31]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank31]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 223, in forward
[rank31]:     variance = hidden_states.pow(2).mean(-1, keepdim=True)
[rank31]:                ^^^^^^^^^^^^^^^^^^^^
[rank34]:              ^^^^^^^^^^^^^^^^^^^
[rank48]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank48]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank48]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank48]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank48]:     outputs = self.forward(batch)
[rank48]:               ^^^^^^^^^^^^^^^^^^^
[rank48]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank48]:     return self.model(**batch)
[rank48]:            ^^^^^^^^^^^^^^^^^^^
[rank60]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformer_engine/pytorch/optimizers/fused_adam.py", line 486, in step
[rank60]:     loss = closure()
[rank60]:            ^^^^^^^^^
[rank60]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 108, in _wrap_closure
[rank60]:     closure_result = closure()
[rank60]:                      ^^^^^^^^^
[rank60]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank60]:     self._result = self.closure(*args, **kwargs)
[rank60]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank60]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank27]: Traceback (most recent call last):
[rank27]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 528, in <module>
[rank27]:     main()
[rank27]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 498, in main
[rank27]:     llm.api.finetune(
[rank27]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank27]:     return train(
[rank27]:            ^^^^^^
[rank27]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank27]:     trainer.fit(model, data)
[rank27]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank27]:     call._call_and_handle_interrupt(
[rank19]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank19]:     self.advance()
[rank19]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank19]:     self.epoch_loop.run(self._data_fetcher)
[rank19]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank19]:     self.advance(data_fetcher)
[rank19]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank19]:     super().advance(data_fetcher)
[rank31]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 640.00 MiB. GPU 3 has a total capacity of 79.19 GiB of which 411.81 MiB is free. Including non-PyTorch memory, this process has 78.78 GiB memory in use. Of the allocated memory 74.80 GiB is allocated by PyTorch, and 1.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank35]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank35]:     return inner()
[rank35]:            ^^^^^^^
[rank35]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank35]:     result = forward_call(*args, **kwargs)
[rank35]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank35]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 259, in forward
[rank35]:     hidden_states = self.input_layernorm(hidden_states)
[rank35]:                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank35]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank48]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank48]:     return self._call_impl(*args, **kwargs)
[rank48]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank48]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank48]:     return inner()
[rank48]:            ^^^^^^^
[rank48]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank48]:     result = forward_call(*args, **kwargs)
[rank48]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank48]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank48]:     output = func(self, *args, **kwargs)
[rank60]:     return func(*args, **kwargs)
[rank60]:            ^^^^^^^^^^^^^^^^^^^^^
[rank60]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank60]:     step_output = self._step_fn()
[rank60]:                   ^^^^^^^^^^^^^^^
[rank60]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank60]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank60]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank60]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank60]:     output = fn(*args, **kwargs)
[rank27]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank27]:     return trainer_fn(*args, **kwargs)
[rank27]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank27]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank27]:     self._run(model, ckpt_path=ckpt_path)
[rank27]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank27]:     results = self._run_stage()
[rank27]:               ^^^^^^^^^^^^^^^^^
[rank27]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank27]:     self.fit_loop.run()
[rank19]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank19]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank19]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank19]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 190, in run
[rank19]:     self._optimizer_step(batch_idx, closure)
[rank19]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank19]:     call._call_lightning_module_hook(
[rank29]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank29]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank29]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank29]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank29]:     outputs = self.forward(batch)
[rank29]:               ^^^^^^^^^^^^^^^^^^^
[rank29]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank29]:     return self.model(**batch)
[rank29]:            ^^^^^^^^^^^^^^^^^^^
[rank35]:     return self._call_impl(*args, **kwargs)
[rank35]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank35]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank35]:     return forward_call(*args, **kwargs)
[rank35]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank35]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 223, in forward
[rank35]:     variance = hidden_states.pow(2).mean(-1, keepdim=True)
[rank35]:                ^^^^^^^^^^^^^^^^^^^^
[rank48]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank48]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank48]:     return func(*args, **kwargs)
[rank48]:            ^^^^^^^^^^^^^^^^^^^^^
[rank48]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank48]:     outputs: BaseModelOutputWithPast = self.model(
[rank48]:                                        ^^^^^^^^^^^
[rank48]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank48]:     return self._call_impl(*args, **kwargs)
[rank48]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank60]:              ^^^^^^^^^^^^^^^^^^^
[rank27]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank27]:     self.advance()
[rank27]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank27]:     self.epoch_loop.run(self._data_fetcher)
[rank27]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank27]:     self.advance(data_fetcher)
[rank27]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank27]:     super().advance(data_fetcher)
[rank19]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 167, in _call_lightning_module_hook
[rank19]:     output = fn(*args, **kwargs)
[rank19]:              ^^^^^^^^^^^^^^^^^^^
[rank29]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank29]:     return self._call_impl(*args, **kwargs)
[rank29]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank29]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank29]:     return inner()
[rank29]:            ^^^^^^^
[rank29]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank29]:     result = forward_call(*args, **kwargs)
[rank29]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank29]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank29]:     output = func(self, *args, **kwargs)
[rank35]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 640.00 MiB. GPU 3 has a total capacity of 79.19 GiB of which 411.81 MiB is free. Including non-PyTorch memory, this process has 78.78 GiB memory in use. Of the allocated memory 74.80 GiB is allocated by PyTorch, and 1.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank48]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank48]:     return forward_call(*args, **kwargs)
[rank48]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank48]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank48]:     output = func(self, *args, **kwargs)
[rank48]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank48]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 549, in forward
[rank48]:     layer_outputs = decoder_layer(
[rank48]:                     ^^^^^^^^^^^^^^
[rank48]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank61]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank61]:     return inner()
[rank61]:            ^^^^^^^
[rank61]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank61]:     result = forward_call(*args, **kwargs)
[rank61]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank61]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 259, in forward
[rank61]:     hidden_states = self.input_layernorm(hidden_states)
[rank61]:                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank61]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank27]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank27]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank27]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank27]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 190, in run
[rank27]:     self._optimizer_step(batch_idx, closure)
[rank27]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank27]:     call._call_lightning_module_hook(
[rank19]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/module.py", line 1306, in optimizer_step
[rank19]:     optimizer.step(closure=optimizer_closure)
[rank19]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py", line 153, in step
[rank19]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank19]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank19]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py", line 238, in optimizer_step
[rank19]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank19]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank29]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank29]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank29]:     return func(*args, **kwargs)
[rank29]:            ^^^^^^^^^^^^^^^^^^^^^
[rank29]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank29]:     outputs: BaseModelOutputWithPast = self.model(
[rank29]:                                        ^^^^^^^^^^^
[rank29]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank29]:     return self._call_impl(*args, **kwargs)
[rank29]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank33]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank33]:     return inner()
[rank33]:            ^^^^^^^
[rank33]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank33]:     result = forward_call(*args, **kwargs)
[rank33]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank33]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 259, in forward
[rank33]:     hidden_states = self.input_layernorm(hidden_states)
[rank33]:                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank33]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank48]:     return self._call_impl(*args, **kwargs)
[rank48]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank61]:     return self._call_impl(*args, **kwargs)
[rank61]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank61]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank61]:     return forward_call(*args, **kwargs)
[rank61]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank61]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 223, in forward
[rank61]:     variance = hidden_states.pow(2).mean(-1, keepdim=True)
[rank61]:                ^^^^^^^^^^^^^^^^^^^^
[rank27]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 167, in _call_lightning_module_hook
[rank27]:     output = fn(*args, **kwargs)
[rank27]:              ^^^^^^^^^^^^^^^^^^^
[rank19]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/amp.py", line 75, in optimizer_step
[rank19]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank19]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank19]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 122, in optimizer_step
[rank19]:     return optimizer.step(closure=closure, **kwargs)
[rank19]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank19]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/optim/optimizer.py", line 516, in wrapper
[rank19]:     out = func(*args, **kwargs)
[rank19]:           ^^^^^^^^^^^^^^^^^^^^^
[rank29]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank29]:     return forward_call(*args, **kwargs)
[rank29]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank29]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank29]:     output = func(self, *args, **kwargs)
[rank29]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank29]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 549, in forward
[rank29]:     layer_outputs = decoder_layer(
[rank29]:                     ^^^^^^^^^^^^^^
[rank29]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank33]:     return self._call_impl(*args, **kwargs)
[rank33]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank33]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank33]:     return forward_call(*args, **kwargs)
[rank33]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank33]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 223, in forward
[rank33]:     variance = hidden_states.pow(2).mean(-1, keepdim=True)
[rank33]:                ^^^^^^^^^^^^^^^^^^^^
[rank48]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank48]:     return inner()
[rank48]:            ^^^^^^^
[rank48]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank48]:     result = forward_call(*args, **kwargs)
[rank48]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank48]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 259, in forward
[rank48]:     hidden_states = self.input_layernorm(hidden_states)
[rank48]:                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank48]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank61]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 640.00 MiB. GPU 1 has a total capacity of 79.19 GiB of which 447.81 MiB is free. Including non-PyTorch memory, this process has 78.74 GiB memory in use. Of the allocated memory 74.80 GiB is allocated by PyTorch, and 1.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank27]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/module.py", line 1306, in optimizer_step
[rank27]:     optimizer.step(closure=optimizer_closure)
[rank27]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py", line 153, in step
[rank27]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank27]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank27]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py", line 238, in optimizer_step
[rank27]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank27]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank19]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformer_engine/pytorch/optimizers/fused_adam.py", line 486, in step
[rank19]:     loss = closure()
[rank19]:            ^^^^^^^^^
[rank19]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 108, in _wrap_closure
[rank19]:     closure_result = closure()
[rank19]:                      ^^^^^^^^^
[rank19]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank19]:     self._result = self.closure(*args, **kwargs)
[rank19]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank19]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank29]:     return self._call_impl(*args, **kwargs)
[rank29]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank33]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 640.00 MiB. GPU 1 has a total capacity of 79.19 GiB of which 367.81 MiB is free. Including non-PyTorch memory, this process has 78.82 GiB memory in use. Of the allocated memory 74.80 GiB is allocated by PyTorch, and 1.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank48]:     return self._call_impl(*args, **kwargs)
[rank48]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank48]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank48]:     return forward_call(*args, **kwargs)
[rank48]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank48]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 223, in forward
[rank48]:     variance = hidden_states.pow(2).mean(-1, keepdim=True)
[rank48]:                ^^^^^^^^^^^^^^^^^^^^
[rank60]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank60]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank60]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank60]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank60]:     outputs = self.forward(batch)
[rank60]:               ^^^^^^^^^^^^^^^^^^^
[rank60]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank60]:     return self.model(**batch)
[rank60]:            ^^^^^^^^^^^^^^^^^^^
[rank15]: Traceback (most recent call last):
[rank15]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 528, in <module>
[rank15]:     main()
[rank15]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 498, in main
[rank15]:     llm.api.finetune(
[rank15]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank15]:     return train(
[rank15]:            ^^^^^^
[rank15]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank15]:     trainer.fit(model, data)
[rank15]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank15]:     call._call_and_handle_interrupt(
[rank27]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/amp.py", line 75, in optimizer_step
[rank27]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank27]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank27]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 122, in optimizer_step
[rank27]:     return optimizer.step(closure=closure, **kwargs)
[rank27]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank27]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/optim/optimizer.py", line 516, in wrapper
[rank27]:     out = func(*args, **kwargs)
[rank27]:           ^^^^^^^^^^^^^^^^^^^^^
[rank19]:     return func(*args, **kwargs)
[rank19]:            ^^^^^^^^^^^^^^^^^^^^^
[rank19]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank19]:     step_output = self._step_fn()
[rank19]:                   ^^^^^^^^^^^^^^^
[rank19]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank19]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank19]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank19]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank19]:     output = fn(*args, **kwargs)
[rank30]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank30]:     return inner()
[rank30]:            ^^^^^^^
[rank30]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank30]:     result = forward_call(*args, **kwargs)
[rank30]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank30]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 259, in forward
[rank30]:     hidden_states = self.input_layernorm(hidden_states)
[rank30]:                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank30]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank34]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank34]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank34]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank34]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank34]:     outputs = self.forward(batch)
[rank34]:               ^^^^^^^^^^^^^^^^^^^
[rank34]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank34]:     return self.model(**batch)
[rank34]:            ^^^^^^^^^^^^^^^^^^^
[rank48]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 640.00 MiB. GPU 0 has a total capacity of 79.19 GiB of which 399.81 MiB is free. Including non-PyTorch memory, this process has 78.79 GiB memory in use. Of the allocated memory 74.80 GiB is allocated by PyTorch, and 1.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank60]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank60]:     return self._call_impl(*args, **kwargs)
[rank60]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank60]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank60]:     return inner()
[rank60]:            ^^^^^^^
[rank60]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank60]:     result = forward_call(*args, **kwargs)
[rank60]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank60]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank60]:     output = func(self, *args, **kwargs)
[rank27]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformer_engine/pytorch/optimizers/fused_adam.py", line 486, in step
[rank27]:     loss = closure()
[rank27]:            ^^^^^^^^^
[rank27]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 108, in _wrap_closure
[rank27]:     closure_result = closure()
[rank27]:                      ^^^^^^^^^
[rank27]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank27]:     self._result = self.closure(*args, **kwargs)
[rank27]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank27]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank19]:              ^^^^^^^^^^^^^^^^^^^
[rank30]:     return self._call_impl(*args, **kwargs)
[rank30]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank30]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank30]:     return forward_call(*args, **kwargs)
[rank30]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank30]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 223, in forward
[rank30]:     variance = hidden_states.pow(2).mean(-1, keepdim=True)
[rank30]:                ^^^^^^^^^^^^^^^^^^^^
[rank34]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank34]:     return self._call_impl(*args, **kwargs)
[rank34]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank34]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank34]:     return inner()
[rank34]:            ^^^^^^^
[rank34]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank34]:     result = forward_call(*args, **kwargs)
[rank34]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank34]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank34]:     output = func(self, *args, **kwargs)
[rank60]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank60]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank60]:     return func(*args, **kwargs)
[rank60]:            ^^^^^^^^^^^^^^^^^^^^^
[rank60]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank60]:     outputs: BaseModelOutputWithPast = self.model(
[rank60]:                                        ^^^^^^^^^^^
[rank60]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank60]:     return self._call_impl(*args, **kwargs)
[rank60]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank27]:     return func(*args, **kwargs)
[rank27]:            ^^^^^^^^^^^^^^^^^^^^^
[rank27]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank27]:     step_output = self._step_fn()
[rank27]:                   ^^^^^^^^^^^^^^^
[rank27]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank27]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank27]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank27]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank27]:     output = fn(*args, **kwargs)
[rank19]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank19]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank19]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank19]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank19]:     outputs = self.forward(batch)
[rank19]:               ^^^^^^^^^^^^^^^^^^^
[rank19]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank19]:     return self.model(**batch)
[rank19]:            ^^^^^^^^^^^^^^^^^^^
[rank30]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 640.00 MiB. GPU 2 has a total capacity of 79.19 GiB of which 395.81 MiB is free. Including non-PyTorch memory, this process has 78.79 GiB memory in use. Of the allocated memory 74.80 GiB is allocated by PyTorch, and 1.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank34]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank34]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank34]:     return func(*args, **kwargs)
[rank34]:            ^^^^^^^^^^^^^^^^^^^^^
[rank34]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank34]:     outputs: BaseModelOutputWithPast = self.model(
[rank34]:                                        ^^^^^^^^^^^
[rank34]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank34]:     return self._call_impl(*args, **kwargs)
[rank34]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank60]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank60]:     return forward_call(*args, **kwargs)
[rank60]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank60]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank60]:     output = func(self, *args, **kwargs)
[rank60]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank60]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 549, in forward
[rank60]:     layer_outputs = decoder_layer(
[rank60]:                     ^^^^^^^^^^^^^^
[rank60]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank27]:              ^^^^^^^^^^^^^^^^^^^
[rank19]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank19]:     return self._call_impl(*args, **kwargs)
[rank19]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank19]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank19]:     return inner()
[rank19]:            ^^^^^^^
[rank19]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank19]:     result = forward_call(*args, **kwargs)
[rank19]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank19]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank19]:     output = func(self, *args, **kwargs)
[rank29]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank29]:     return inner()
[rank29]:            ^^^^^^^
[rank29]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank29]:     result = forward_call(*args, **kwargs)
[rank29]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank29]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 259, in forward
[rank29]:     hidden_states = self.input_layernorm(hidden_states)
[rank29]:                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank29]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank34]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank34]:     return forward_call(*args, **kwargs)
[rank34]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank34]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank34]:     output = func(self, *args, **kwargs)
[rank34]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank34]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 549, in forward
[rank34]:     layer_outputs = decoder_layer(
[rank34]:                     ^^^^^^^^^^^^^^
[rank34]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank60]:     return self._call_impl(*args, **kwargs)
[rank60]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank27]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank27]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank27]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank27]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank27]:     outputs = self.forward(batch)
[rank27]:               ^^^^^^^^^^^^^^^^^^^
[rank27]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank27]:     return self.model(**batch)
[rank27]:            ^^^^^^^^^^^^^^^^^^^
[rank19]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank19]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank19]:     return func(*args, **kwargs)
[rank19]:            ^^^^^^^^^^^^^^^^^^^^^
[rank19]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank19]:     outputs: BaseModelOutputWithPast = self.model(
[rank19]:                                        ^^^^^^^^^^^
[rank19]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank19]:     return self._call_impl(*args, **kwargs)
[rank19]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank29]:     return self._call_impl(*args, **kwargs)
[rank29]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank29]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank29]:     return forward_call(*args, **kwargs)
[rank29]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank29]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 223, in forward
[rank29]:     variance = hidden_states.pow(2).mean(-1, keepdim=True)
[rank29]:                ^^^^^^^^^^^^^^^^^^^^
[rank34]:     return self._call_impl(*args, **kwargs)
[rank34]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank60]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank60]:     return inner()
[rank60]:            ^^^^^^^
[rank60]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank60]:     result = forward_call(*args, **kwargs)
[rank60]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank60]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 259, in forward
[rank60]:     hidden_states = self.input_layernorm(hidden_states)
[rank60]:                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank60]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank27]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank27]:     return self._call_impl(*args, **kwargs)
[rank27]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank27]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank27]:     return inner()
[rank27]:            ^^^^^^^
[rank27]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank27]:     result = forward_call(*args, **kwargs)
[rank27]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank27]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank27]:     output = func(self, *args, **kwargs)
[rank19]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank19]:     return forward_call(*args, **kwargs)
[rank19]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank19]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank19]:     output = func(self, *args, **kwargs)
[rank19]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank19]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 549, in forward
[rank19]:     layer_outputs = decoder_layer(
[rank19]:                     ^^^^^^^^^^^^^^
[rank19]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank29]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 640.00 MiB. GPU 1 has a total capacity of 79.19 GiB of which 367.81 MiB is free. Including non-PyTorch memory, this process has 78.82 GiB memory in use. Of the allocated memory 74.80 GiB is allocated by PyTorch, and 1.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank34]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank34]:     return inner()
[rank34]:            ^^^^^^^
[rank34]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank34]:     result = forward_call(*args, **kwargs)
[rank34]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank34]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 259, in forward
[rank34]:     hidden_states = self.input_layernorm(hidden_states)
[rank34]:                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank34]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank60]:     return self._call_impl(*args, **kwargs)
[rank60]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank60]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank60]:     return forward_call(*args, **kwargs)
[rank60]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank60]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 223, in forward
[rank60]:     variance = hidden_states.pow(2).mean(-1, keepdim=True)
[rank60]:                ^^^^^^^^^^^^^^^^^^^^
[rank15]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank15]:     return trainer_fn(*args, **kwargs)
[rank15]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank15]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank15]:     self._run(model, ckpt_path=ckpt_path)
[rank15]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank15]:     results = self._run_stage()
[rank15]:               ^^^^^^^^^^^^^^^^^
[rank15]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank15]:     self.fit_loop.run()
[rank27]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank27]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank27]:     return func(*args, **kwargs)
[rank27]:            ^^^^^^^^^^^^^^^^^^^^^
[rank27]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank27]:     outputs: BaseModelOutputWithPast = self.model(
[rank27]:                                        ^^^^^^^^^^^
[rank27]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank27]:     return self._call_impl(*args, **kwargs)
[rank27]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank19]:     return self._call_impl(*args, **kwargs)
[rank19]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank28]: Traceback (most recent call last):
[rank28]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 528, in <module>
[rank28]:     main()
[rank28]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 498, in main
[rank28]:     llm.api.finetune(
[rank28]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank28]:     return train(
[rank28]:            ^^^^^^
[rank28]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank28]:     trainer.fit(model, data)
[rank28]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank28]:     call._call_and_handle_interrupt(
[rank34]:     return self._call_impl(*args, **kwargs)
[rank34]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank34]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank34]:     return forward_call(*args, **kwargs)
[rank34]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank34]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 223, in forward
[rank34]:     variance = hidden_states.pow(2).mean(-1, keepdim=True)
[rank34]:                ^^^^^^^^^^^^^^^^^^^^
[rank59]: Traceback (most recent call last):
[rank59]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 528, in <module>
[rank59]:     main()
[rank59]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 498, in main
[rank59]:     llm.api.finetune(
[rank59]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank59]:     return train(
[rank59]:            ^^^^^^
[rank59]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank59]:     trainer.fit(model, data)
[rank59]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank59]:     call._call_and_handle_interrupt(
[rank60]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 640.00 MiB. GPU 0 has a total capacity of 79.19 GiB of which 479.81 MiB is free. Including non-PyTorch memory, this process has 78.71 GiB memory in use. Of the allocated memory 74.80 GiB is allocated by PyTorch, and 1.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank15]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank15]:     self.advance()
[rank15]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank15]:     self.epoch_loop.run(self._data_fetcher)
[rank15]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank15]:     self.advance(data_fetcher)
[rank15]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank15]:     super().advance(data_fetcher)
[rank27]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank27]:     return forward_call(*args, **kwargs)
[rank27]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank27]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank27]:     output = func(self, *args, **kwargs)
[rank27]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank27]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 549, in forward
[rank27]:     layer_outputs = decoder_layer(
[rank27]:                     ^^^^^^^^^^^^^^
[rank27]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank19]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank19]:     return inner()
[rank19]:            ^^^^^^^
[rank19]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank19]:     result = forward_call(*args, **kwargs)
[rank19]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank19]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 259, in forward
[rank19]:     hidden_states = self.input_layernorm(hidden_states)
[rank19]:                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank19]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank28]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank28]:     return trainer_fn(*args, **kwargs)
[rank28]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank28]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank28]:     self._run(model, ckpt_path=ckpt_path)
[rank28]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank28]:     results = self._run_stage()
[rank28]:               ^^^^^^^^^^^^^^^^^
[rank28]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank28]:     self.fit_loop.run()
[rank34]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 640.00 MiB. GPU 2 has a total capacity of 79.19 GiB of which 395.81 MiB is free. Including non-PyTorch memory, this process has 78.79 GiB memory in use. Of the allocated memory 74.80 GiB is allocated by PyTorch, and 1.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank59]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank59]:     return trainer_fn(*args, **kwargs)
[rank59]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank59]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank59]:     self._run(model, ckpt_path=ckpt_path)
[rank59]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank59]:     results = self._run_stage()
[rank59]:               ^^^^^^^^^^^^^^^^^
[rank59]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank59]:     self.fit_loop.run()
[rank15]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank15]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank15]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank15]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 190, in run
[rank15]:     self._optimizer_step(batch_idx, closure)
[rank15]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank15]:     call._call_lightning_module_hook(
[rank27]:     return self._call_impl(*args, **kwargs)
[rank27]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank19]:     return self._call_impl(*args, **kwargs)
[rank19]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank19]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank19]:     return forward_call(*args, **kwargs)
[rank19]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank19]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 223, in forward
[rank19]:     variance = hidden_states.pow(2).mean(-1, keepdim=True)
[rank19]:                ^^^^^^^^^^^^^^^^^^^^
[rank28]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank28]:     self.advance()
[rank28]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank28]:     self.epoch_loop.run(self._data_fetcher)
[rank28]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank28]:     self.advance(data_fetcher)
[rank28]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank28]:     super().advance(data_fetcher)
[rank59]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank59]:     self.advance()
[rank59]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank59]:     self.epoch_loop.run(self._data_fetcher)
[rank59]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank59]:     self.advance(data_fetcher)
[rank59]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank59]:     super().advance(data_fetcher)
[rank15]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 167, in _call_lightning_module_hook
[rank15]:     output = fn(*args, **kwargs)
[rank15]:              ^^^^^^^^^^^^^^^^^^^
[rank27]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank27]:     return inner()
[rank27]:            ^^^^^^^
[rank27]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank27]:     result = forward_call(*args, **kwargs)
[rank27]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank27]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 259, in forward
[rank27]:     hidden_states = self.input_layernorm(hidden_states)
[rank27]:                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank27]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank19]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 640.00 MiB. GPU 3 has a total capacity of 79.19 GiB of which 411.81 MiB is free. Including non-PyTorch memory, this process has 78.78 GiB memory in use. Of the allocated memory 74.80 GiB is allocated by PyTorch, and 1.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank28]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank28]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank28]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank28]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 190, in run
[rank28]:     self._optimizer_step(batch_idx, closure)
[rank28]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank28]:     call._call_lightning_module_hook(
[rank59]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank59]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank59]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank59]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 190, in run
[rank59]:     self._optimizer_step(batch_idx, closure)
[rank59]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank59]:     call._call_lightning_module_hook(
[rank15]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/module.py", line 1306, in optimizer_step
[rank15]:     optimizer.step(closure=optimizer_closure)
[rank15]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py", line 153, in step
[rank15]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank15]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank15]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py", line 238, in optimizer_step
[rank15]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank15]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank27]:     return self._call_impl(*args, **kwargs)
[rank27]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank27]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank27]:     return forward_call(*args, **kwargs)
[rank27]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank27]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 223, in forward
[rank27]:     variance = hidden_states.pow(2).mean(-1, keepdim=True)
[rank27]:                ^^^^^^^^^^^^^^^^^^^^
[rank28]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 167, in _call_lightning_module_hook
[rank28]:     output = fn(*args, **kwargs)
[rank28]:              ^^^^^^^^^^^^^^^^^^^
[rank59]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 167, in _call_lightning_module_hook
[rank59]:     output = fn(*args, **kwargs)
[rank59]:              ^^^^^^^^^^^^^^^^^^^
[rank15]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/amp.py", line 75, in optimizer_step
[rank15]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank15]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank15]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 122, in optimizer_step
[rank15]:     return optimizer.step(closure=closure, **kwargs)
[rank15]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank15]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/optim/optimizer.py", line 516, in wrapper
[rank15]:     out = func(*args, **kwargs)
[rank15]:           ^^^^^^^^^^^^^^^^^^^^^
[rank27]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 640.00 MiB. GPU 3 has a total capacity of 79.19 GiB of which 411.81 MiB is free. Including non-PyTorch memory, this process has 78.78 GiB memory in use. Of the allocated memory 74.80 GiB is allocated by PyTorch, and 1.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank28]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/module.py", line 1306, in optimizer_step
[rank28]:     optimizer.step(closure=optimizer_closure)
[rank28]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py", line 153, in step
[rank28]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank28]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank28]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py", line 238, in optimizer_step
[rank28]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank28]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank59]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/module.py", line 1306, in optimizer_step
[rank59]:     optimizer.step(closure=optimizer_closure)
[rank59]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py", line 153, in step
[rank59]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank59]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank59]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py", line 238, in optimizer_step
[rank59]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank59]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank15]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformer_engine/pytorch/optimizers/fused_adam.py", line 486, in step
[rank15]:     loss = closure()
[rank15]:            ^^^^^^^^^
[rank15]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 108, in _wrap_closure
[rank15]:     closure_result = closure()
[rank15]:                      ^^^^^^^^^
[rank15]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank15]:     self._result = self.closure(*args, **kwargs)
[rank15]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank15]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank28]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/amp.py", line 75, in optimizer_step
[rank28]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank28]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank28]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 122, in optimizer_step
[rank28]:     return optimizer.step(closure=closure, **kwargs)
[rank28]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank28]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/optim/optimizer.py", line 516, in wrapper
[rank28]:     out = func(*args, **kwargs)
[rank28]:           ^^^^^^^^^^^^^^^^^^^^^
[rank59]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/amp.py", line 75, in optimizer_step
[rank59]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank59]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank59]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 122, in optimizer_step
[rank59]:     return optimizer.step(closure=closure, **kwargs)
[rank59]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank59]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/optim/optimizer.py", line 516, in wrapper
[rank59]:     out = func(*args, **kwargs)
[rank59]:           ^^^^^^^^^^^^^^^^^^^^^
[rank15]:     return func(*args, **kwargs)
[rank15]:            ^^^^^^^^^^^^^^^^^^^^^
[rank15]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank15]:     step_output = self._step_fn()
[rank15]:                   ^^^^^^^^^^^^^^^
[rank15]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank15]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank15]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank15]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank15]:     output = fn(*args, **kwargs)
[rank28]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformer_engine/pytorch/optimizers/fused_adam.py", line 486, in step
[rank28]:     loss = closure()
[rank28]:            ^^^^^^^^^
[rank28]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 108, in _wrap_closure
[rank28]:     closure_result = closure()
[rank28]:                      ^^^^^^^^^
[rank28]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank28]:     self._result = self.closure(*args, **kwargs)
[rank28]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank28]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank59]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformer_engine/pytorch/optimizers/fused_adam.py", line 486, in step
[rank59]:     loss = closure()
[rank59]:            ^^^^^^^^^
[rank59]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 108, in _wrap_closure
[rank59]:     closure_result = closure()
[rank59]:                      ^^^^^^^^^
[rank59]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank59]:     self._result = self.closure(*args, **kwargs)
[rank59]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank59]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank15]:              ^^^^^^^^^^^^^^^^^^^
[rank28]:     return func(*args, **kwargs)
[rank28]:            ^^^^^^^^^^^^^^^^^^^^^
[rank28]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank28]:     step_output = self._step_fn()
[rank28]:                   ^^^^^^^^^^^^^^^
[rank28]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank28]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank28]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank28]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank28]:     output = fn(*args, **kwargs)
[rank59]:     return func(*args, **kwargs)
[rank59]:            ^^^^^^^^^^^^^^^^^^^^^
[rank59]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank59]:     step_output = self._step_fn()
[rank59]:                   ^^^^^^^^^^^^^^^
[rank59]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank59]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank59]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank59]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank59]:     output = fn(*args, **kwargs)
[rank15]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank15]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank15]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank15]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank15]:     outputs = self.forward(batch)
[rank15]:               ^^^^^^^^^^^^^^^^^^^
[rank15]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank15]:     return self.model(**batch)
[rank15]:            ^^^^^^^^^^^^^^^^^^^
[rank28]:              ^^^^^^^^^^^^^^^^^^^
[rank59]:              ^^^^^^^^^^^^^^^^^^^
[rank15]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank15]:     return self._call_impl(*args, **kwargs)
[rank15]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank15]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank15]:     return inner()
[rank15]:            ^^^^^^^
[rank15]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank15]:     result = forward_call(*args, **kwargs)
[rank15]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank15]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank15]:     output = func(self, *args, **kwargs)
[rank28]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank28]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank28]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank28]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank28]:     outputs = self.forward(batch)
[rank28]:               ^^^^^^^^^^^^^^^^^^^
[rank28]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank28]:     return self.model(**batch)
[rank28]:            ^^^^^^^^^^^^^^^^^^^
[rank59]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank59]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank59]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank59]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank59]:     outputs = self.forward(batch)
[rank59]:               ^^^^^^^^^^^^^^^^^^^
[rank59]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank59]:     return self.model(**batch)
[rank59]:            ^^^^^^^^^^^^^^^^^^^
[rank15]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank15]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank15]:     return func(*args, **kwargs)
[rank15]:            ^^^^^^^^^^^^^^^^^^^^^
[rank15]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank15]:     outputs: BaseModelOutputWithPast = self.model(
[rank15]:                                        ^^^^^^^^^^^
[rank15]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank15]:     return self._call_impl(*args, **kwargs)
[rank15]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank28]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank28]:     return self._call_impl(*args, **kwargs)
[rank28]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank28]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank28]:     return inner()
[rank28]:            ^^^^^^^
[rank28]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank28]:     result = forward_call(*args, **kwargs)
[rank28]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank28]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank28]:     output = func(self, *args, **kwargs)
[rank59]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank59]:     return self._call_impl(*args, **kwargs)
[rank59]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank59]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank59]:     return inner()
[rank59]:            ^^^^^^^
[rank59]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank59]:     result = forward_call(*args, **kwargs)
[rank59]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank59]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank59]:     output = func(self, *args, **kwargs)
[rank15]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank15]:     return forward_call(*args, **kwargs)
[rank15]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank15]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank15]:     output = func(self, *args, **kwargs)
[rank15]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank15]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 549, in forward
[rank15]:     layer_outputs = decoder_layer(
[rank15]:                     ^^^^^^^^^^^^^^
[rank15]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank28]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank28]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank28]:     return func(*args, **kwargs)
[rank28]:            ^^^^^^^^^^^^^^^^^^^^^
[rank28]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank28]:     outputs: BaseModelOutputWithPast = self.model(
[rank28]:                                        ^^^^^^^^^^^
[rank28]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank28]:     return self._call_impl(*args, **kwargs)
[rank28]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank59]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank59]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank59]:     return func(*args, **kwargs)
[rank59]:            ^^^^^^^^^^^^^^^^^^^^^
[rank59]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank59]:     outputs: BaseModelOutputWithPast = self.model(
[rank59]:                                        ^^^^^^^^^^^
[rank59]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank59]:     return self._call_impl(*args, **kwargs)
[rank59]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank15]:     return self._call_impl(*args, **kwargs)
[rank15]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank28]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank28]:     return forward_call(*args, **kwargs)
[rank28]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank28]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank28]:     output = func(self, *args, **kwargs)
[rank28]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank28]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 549, in forward
[rank28]:     layer_outputs = decoder_layer(
[rank28]:                     ^^^^^^^^^^^^^^
[rank28]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank59]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank59]:     return forward_call(*args, **kwargs)
[rank59]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank59]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank59]:     output = func(self, *args, **kwargs)
[rank59]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank59]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 549, in forward
[rank59]:     layer_outputs = decoder_layer(
[rank59]:                     ^^^^^^^^^^^^^^
[rank59]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank13]: Traceback (most recent call last):
[rank13]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 528, in <module>
[rank13]:     main()
[rank13]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 498, in main
[rank13]:     llm.api.finetune(
[rank13]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank13]:     return train(
[rank13]:            ^^^^^^
[rank13]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank13]:     trainer.fit(model, data)
[rank13]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank13]:     call._call_and_handle_interrupt(
[rank28]:     return self._call_impl(*args, **kwargs)
[rank28]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank59]:     return self._call_impl(*args, **kwargs)
[rank59]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank13]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank13]:     return trainer_fn(*args, **kwargs)
[rank13]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank13]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank13]:     self._run(model, ckpt_path=ckpt_path)
[rank13]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank13]:     results = self._run_stage()
[rank13]:               ^^^^^^^^^^^^^^^^^
[rank13]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank13]:     self.fit_loop.run()
[rank28]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank28]:     return inner()
[rank28]:            ^^^^^^^
[rank28]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank28]:     result = forward_call(*args, **kwargs)
[rank28]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank28]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 259, in forward
[rank28]:     hidden_states = self.input_layernorm(hidden_states)
[rank28]:                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank28]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank59]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank59]:     return inner()
[rank59]:            ^^^^^^^
[rank59]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank59]:     result = forward_call(*args, **kwargs)
[rank59]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank59]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 259, in forward
[rank59]:     hidden_states = self.input_layernorm(hidden_states)
[rank59]:                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank59]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank13]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank13]:     self.advance()
[rank13]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank13]:     self.epoch_loop.run(self._data_fetcher)
[rank13]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank13]:     self.advance(data_fetcher)
[rank13]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank13]:     super().advance(data_fetcher)
[rank28]:     return self._call_impl(*args, **kwargs)
[rank28]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank28]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank28]:     return forward_call(*args, **kwargs)
[rank28]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank28]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 223, in forward
[rank28]:     variance = hidden_states.pow(2).mean(-1, keepdim=True)
[rank28]:                ^^^^^^^^^^^^^^^^^^^^
[rank59]:     return self._call_impl(*args, **kwargs)
[rank59]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank59]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank59]:     return forward_call(*args, **kwargs)
[rank59]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank59]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 223, in forward
[rank59]:     variance = hidden_states.pow(2).mean(-1, keepdim=True)
[rank59]:                ^^^^^^^^^^^^^^^^^^^^
[rank13]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank13]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank13]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank13]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 190, in run
[rank13]:     self._optimizer_step(batch_idx, closure)
[rank13]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank13]:     call._call_lightning_module_hook(
[rank28]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 640.00 MiB. GPU 0 has a total capacity of 79.19 GiB of which 399.81 MiB is free. Including non-PyTorch memory, this process has 78.79 GiB memory in use. Of the allocated memory 74.80 GiB is allocated by PyTorch, and 1.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank59]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 640.00 MiB. GPU 3 has a total capacity of 79.19 GiB of which 411.81 MiB is free. Including non-PyTorch memory, this process has 78.78 GiB memory in use. Of the allocated memory 74.80 GiB is allocated by PyTorch, and 1.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank13]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 167, in _call_lightning_module_hook
[rank13]:     output = fn(*args, **kwargs)
[rank13]:              ^^^^^^^^^^^^^^^^^^^
[rank56]: Traceback (most recent call last):
[rank56]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 528, in <module>
[rank56]:     main()
[rank56]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 498, in main
[rank56]:     llm.api.finetune(
[rank56]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank56]:     return train(
[rank56]:            ^^^^^^
[rank56]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank56]:     trainer.fit(model, data)
[rank56]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank56]:     call._call_and_handle_interrupt(
[rank15]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank15]:     return inner()
[rank15]:            ^^^^^^^
[rank15]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank15]:     result = forward_call(*args, **kwargs)
[rank15]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank15]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 259, in forward
[rank15]:     hidden_states = self.input_layernorm(hidden_states)
[rank15]:                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank15]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank56]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank56]:     return trainer_fn(*args, **kwargs)
[rank56]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank56]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank56]:     self._run(model, ckpt_path=ckpt_path)
[rank56]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank56]:     results = self._run_stage()
[rank56]:               ^^^^^^^^^^^^^^^^^
[rank56]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank56]:     self.fit_loop.run()
[rank15]:     return self._call_impl(*args, **kwargs)
[rank15]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank15]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank15]:     return forward_call(*args, **kwargs)
[rank15]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank15]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 223, in forward
[rank15]:     variance = hidden_states.pow(2).mean(-1, keepdim=True)
[rank15]:                ^^^^^^^^^^^^^^^^^^^^
[rank56]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank56]:     self.advance()
[rank56]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank56]:     self.epoch_loop.run(self._data_fetcher)
[rank56]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank56]:     self.advance(data_fetcher)
[rank56]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank56]:     super().advance(data_fetcher)
[rank15]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 640.00 MiB. GPU 3 has a total capacity of 79.19 GiB of which 411.81 MiB is free. Including non-PyTorch memory, this process has 78.78 GiB memory in use. Of the allocated memory 74.80 GiB is allocated by PyTorch, and 1.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank56]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank56]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank56]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank56]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 190, in run
[rank56]:     self._optimizer_step(batch_idx, closure)
[rank56]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank56]:     call._call_lightning_module_hook(
[rank13]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/module.py", line 1306, in optimizer_step
[rank13]:     optimizer.step(closure=optimizer_closure)
[rank13]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py", line 153, in step
[rank13]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank13]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank13]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py", line 238, in optimizer_step
[rank13]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank13]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank56]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 167, in _call_lightning_module_hook
[rank56]:     output = fn(*args, **kwargs)
[rank56]:              ^^^^^^^^^^^^^^^^^^^
[rank13]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/amp.py", line 75, in optimizer_step
[rank13]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank13]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank13]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 122, in optimizer_step
[rank13]:     return optimizer.step(closure=closure, **kwargs)
[rank13]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank13]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/optim/optimizer.py", line 516, in wrapper
[rank13]:     out = func(*args, **kwargs)
[rank13]:           ^^^^^^^^^^^^^^^^^^^^^
[rank56]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/module.py", line 1306, in optimizer_step
[rank56]:     optimizer.step(closure=optimizer_closure)
[rank56]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py", line 153, in step
[rank56]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank56]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank56]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py", line 238, in optimizer_step
[rank56]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank56]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank13]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformer_engine/pytorch/optimizers/fused_adam.py", line 486, in step
[rank13]:     loss = closure()
[rank13]:            ^^^^^^^^^
[rank13]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 108, in _wrap_closure
[rank13]:     closure_result = closure()
[rank13]:                      ^^^^^^^^^
[rank13]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank13]:     self._result = self.closure(*args, **kwargs)
[rank13]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank13]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank56]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/amp.py", line 75, in optimizer_step
[rank56]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank56]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank56]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 122, in optimizer_step
[rank56]:     return optimizer.step(closure=closure, **kwargs)
[rank56]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank56]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/optim/optimizer.py", line 516, in wrapper
[rank56]:     out = func(*args, **kwargs)
[rank56]:           ^^^^^^^^^^^^^^^^^^^^^
[rank13]:     return func(*args, **kwargs)
[rank13]:            ^^^^^^^^^^^^^^^^^^^^^
[rank13]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank13]:     step_output = self._step_fn()
[rank13]:                   ^^^^^^^^^^^^^^^
[rank13]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank13]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank13]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank13]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank13]:     output = fn(*args, **kwargs)
[rank56]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformer_engine/pytorch/optimizers/fused_adam.py", line 486, in step
[rank56]:     loss = closure()
[rank56]:            ^^^^^^^^^
[rank56]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 108, in _wrap_closure
[rank56]:     closure_result = closure()
[rank56]:                      ^^^^^^^^^
[rank56]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank56]:     self._result = self.closure(*args, **kwargs)
[rank56]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank56]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank13]:              ^^^^^^^^^^^^^^^^^^^
[rank56]:     return func(*args, **kwargs)
[rank56]:            ^^^^^^^^^^^^^^^^^^^^^
[rank56]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank56]:     step_output = self._step_fn()
[rank56]:                   ^^^^^^^^^^^^^^^
[rank56]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank56]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank56]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank56]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank56]:     output = fn(*args, **kwargs)
[rank13]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank13]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank13]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank13]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank13]:     outputs = self.forward(batch)
[rank13]:               ^^^^^^^^^^^^^^^^^^^
[rank13]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank13]:     return self.model(**batch)
[rank13]:            ^^^^^^^^^^^^^^^^^^^
[rank56]:              ^^^^^^^^^^^^^^^^^^^
[rank13]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank13]:     return self._call_impl(*args, **kwargs)
[rank13]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank13]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank13]:     return inner()
[rank13]:            ^^^^^^^
[rank13]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank13]:     result = forward_call(*args, **kwargs)
[rank13]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank13]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank13]:     output = func(self, *args, **kwargs)
[rank56]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank56]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank56]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank56]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank56]:     outputs = self.forward(batch)
[rank56]:               ^^^^^^^^^^^^^^^^^^^
[rank56]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank56]:     return self.model(**batch)
[rank56]:            ^^^^^^^^^^^^^^^^^^^
[rank13]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank13]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank13]:     return func(*args, **kwargs)
[rank13]:            ^^^^^^^^^^^^^^^^^^^^^
[rank13]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank13]:     outputs: BaseModelOutputWithPast = self.model(
[rank13]:                                        ^^^^^^^^^^^
[rank13]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank13]:     return self._call_impl(*args, **kwargs)
[rank13]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank56]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank56]:     return self._call_impl(*args, **kwargs)
[rank56]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank56]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank56]:     return inner()
[rank56]:            ^^^^^^^
[rank56]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank56]:     result = forward_call(*args, **kwargs)
[rank56]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank56]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank56]:     output = func(self, *args, **kwargs)
[rank13]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank13]:     return forward_call(*args, **kwargs)
[rank13]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank13]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank13]:     output = func(self, *args, **kwargs)
[rank13]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank13]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 549, in forward
[rank13]:     layer_outputs = decoder_layer(
[rank13]:                     ^^^^^^^^^^^^^^
[rank13]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank56]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank56]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank56]:     return func(*args, **kwargs)
[rank56]:            ^^^^^^^^^^^^^^^^^^^^^
[rank56]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank56]:     outputs: BaseModelOutputWithPast = self.model(
[rank56]:                                        ^^^^^^^^^^^
[rank56]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank56]:     return self._call_impl(*args, **kwargs)
[rank56]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank13]:     return self._call_impl(*args, **kwargs)
[rank13]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank56]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank56]:     return forward_call(*args, **kwargs)
[rank56]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank56]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank56]:     output = func(self, *args, **kwargs)
[rank56]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank56]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 549, in forward
[rank56]:     layer_outputs = decoder_layer(
[rank56]:                     ^^^^^^^^^^^^^^
[rank56]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank14]: Traceback (most recent call last):
[rank14]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 528, in <module>
[rank14]:     main()
[rank14]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 498, in main
[rank14]:     llm.api.finetune(
[rank14]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank14]:     return train(
[rank14]:            ^^^^^^
[rank14]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank14]:     trainer.fit(model, data)
[rank14]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank14]:     call._call_and_handle_interrupt(
[rank56]:     return self._call_impl(*args, **kwargs)
[rank56]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank14]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank14]:     return trainer_fn(*args, **kwargs)
[rank14]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank14]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank14]:     self._run(model, ckpt_path=ckpt_path)
[rank14]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank14]:     results = self._run_stage()
[rank14]:               ^^^^^^^^^^^^^^^^^
[rank14]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank14]:     self.fit_loop.run()
[rank56]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank56]:     return inner()
[rank56]:            ^^^^^^^
[rank56]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank56]:     result = forward_call(*args, **kwargs)
[rank56]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank56]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 259, in forward
[rank56]:     hidden_states = self.input_layernorm(hidden_states)
[rank56]:                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank56]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank14]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank14]:     self.advance()
[rank14]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank14]:     self.epoch_loop.run(self._data_fetcher)
[rank14]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank14]:     self.advance(data_fetcher)
[rank14]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank14]:     super().advance(data_fetcher)
[rank56]:     return self._call_impl(*args, **kwargs)
[rank56]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank56]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank56]:     return forward_call(*args, **kwargs)
[rank56]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank56]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 223, in forward
[rank56]:     variance = hidden_states.pow(2).mean(-1, keepdim=True)
[rank56]:                ^^^^^^^^^^^^^^^^^^^^
[rank14]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank14]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank14]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank14]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 190, in run
[rank14]:     self._optimizer_step(batch_idx, closure)
[rank14]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank14]:     call._call_lightning_module_hook(
[rank56]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 640.00 MiB. GPU 0 has a total capacity of 79.19 GiB of which 399.81 MiB is free. Including non-PyTorch memory, this process has 78.79 GiB memory in use. Of the allocated memory 74.80 GiB is allocated by PyTorch, and 1.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank14]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 167, in _call_lightning_module_hook
[rank14]:     output = fn(*args, **kwargs)
[rank14]:              ^^^^^^^^^^^^^^^^^^^
[rank13]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank13]:     return inner()
[rank13]:            ^^^^^^^
[rank13]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank13]:     result = forward_call(*args, **kwargs)
[rank13]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank13]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 259, in forward
[rank13]:     hidden_states = self.input_layernorm(hidden_states)
[rank13]:                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank13]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank13]:     return self._call_impl(*args, **kwargs)
[rank13]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank13]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank13]:     return forward_call(*args, **kwargs)
[rank13]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank13]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 223, in forward
[rank13]:     variance = hidden_states.pow(2).mean(-1, keepdim=True)
[rank13]:                ^^^^^^^^^^^^^^^^^^^^
[rank13]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 640.00 MiB. GPU 1 has a total capacity of 79.19 GiB of which 367.81 MiB is free. Including non-PyTorch memory, this process has 78.82 GiB memory in use. Of the allocated memory 74.80 GiB is allocated by PyTorch, and 1.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank14]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/module.py", line 1306, in optimizer_step
[rank14]:     optimizer.step(closure=optimizer_closure)
[rank14]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py", line 153, in step
[rank14]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank14]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank14]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py", line 238, in optimizer_step
[rank14]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank14]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank14]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/amp.py", line 75, in optimizer_step
[rank14]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank14]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank14]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 122, in optimizer_step
[rank14]:     return optimizer.step(closure=closure, **kwargs)
[rank14]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank14]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/optim/optimizer.py", line 516, in wrapper
[rank14]:     out = func(*args, **kwargs)
[rank14]:           ^^^^^^^^^^^^^^^^^^^^^
[rank14]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformer_engine/pytorch/optimizers/fused_adam.py", line 486, in step
[rank14]:     loss = closure()
[rank14]:            ^^^^^^^^^
[rank14]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 108, in _wrap_closure
[rank14]:     closure_result = closure()
[rank14]:                      ^^^^^^^^^
[rank14]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank14]:     self._result = self.closure(*args, **kwargs)
[rank14]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank14]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank14]:     return func(*args, **kwargs)
[rank14]:            ^^^^^^^^^^^^^^^^^^^^^
[rank14]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank14]:     step_output = self._step_fn()
[rank14]:                   ^^^^^^^^^^^^^^^
[rank14]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank14]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank14]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank14]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank14]:     output = fn(*args, **kwargs)
[rank14]:              ^^^^^^^^^^^^^^^^^^^
[rank14]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank14]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank14]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank14]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank14]:     outputs = self.forward(batch)
[rank14]:               ^^^^^^^^^^^^^^^^^^^
[rank14]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank14]:     return self.model(**batch)
[rank14]:            ^^^^^^^^^^^^^^^^^^^
[rank14]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank14]:     return self._call_impl(*args, **kwargs)
[rank14]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank14]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank14]:     return inner()
[rank14]:            ^^^^^^^
[rank14]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank14]:     result = forward_call(*args, **kwargs)
[rank14]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank14]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank14]:     output = func(self, *args, **kwargs)
[rank14]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank14]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank14]:     return func(*args, **kwargs)
[rank14]:            ^^^^^^^^^^^^^^^^^^^^^
[rank14]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank14]:     outputs: BaseModelOutputWithPast = self.model(
[rank14]:                                        ^^^^^^^^^^^
[rank14]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank14]:     return self._call_impl(*args, **kwargs)
[rank14]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank14]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank14]:     return forward_call(*args, **kwargs)
[rank14]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank14]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank14]:     output = func(self, *args, **kwargs)
[rank14]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank14]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 549, in forward
[rank14]:     layer_outputs = decoder_layer(
[rank14]:                     ^^^^^^^^^^^^^^
[rank14]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank14]:     return self._call_impl(*args, **kwargs)
[rank14]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank14]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank14]:     return inner()
[rank14]:            ^^^^^^^
[rank14]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank14]:     result = forward_call(*args, **kwargs)
[rank14]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank14]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 259, in forward
[rank14]:     hidden_states = self.input_layernorm(hidden_states)
[rank14]:                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank14]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank14]:     return self._call_impl(*args, **kwargs)
[rank14]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank14]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank14]:     return forward_call(*args, **kwargs)
[rank14]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank14]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 223, in forward
[rank14]:     variance = hidden_states.pow(2).mean(-1, keepdim=True)
[rank14]:                ^^^^^^^^^^^^^^^^^^^^
[rank14]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 640.00 MiB. GPU 2 has a total capacity of 79.19 GiB of which 395.81 MiB is free. Including non-PyTorch memory, this process has 78.79 GiB memory in use. Of the allocated memory 74.80 GiB is allocated by PyTorch, and 1.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank12]: Traceback (most recent call last):
[rank12]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 528, in <module>
[rank12]:     main()
[rank12]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 498, in main
[rank12]:     llm.api.finetune(
[rank12]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank12]:     return train(
[rank12]:            ^^^^^^
[rank12]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank12]:     trainer.fit(model, data)
[rank12]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank12]:     call._call_and_handle_interrupt(
[rank12]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank12]:     return trainer_fn(*args, **kwargs)
[rank12]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank12]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank12]:     self._run(model, ckpt_path=ckpt_path)
[rank12]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank12]:     results = self._run_stage()
[rank12]:               ^^^^^^^^^^^^^^^^^
[rank12]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank12]:     self.fit_loop.run()
[rank12]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank12]:     self.advance()
[rank12]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank12]:     self.epoch_loop.run(self._data_fetcher)
[rank12]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank12]:     self.advance(data_fetcher)
[rank12]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank12]:     super().advance(data_fetcher)
[rank12]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank12]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank12]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank12]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 190, in run
[rank12]:     self._optimizer_step(batch_idx, closure)
[rank12]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank12]:     call._call_lightning_module_hook(
[rank12]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 167, in _call_lightning_module_hook
[rank12]:     output = fn(*args, **kwargs)
[rank12]:              ^^^^^^^^^^^^^^^^^^^
[rank12]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/module.py", line 1306, in optimizer_step
[rank12]:     optimizer.step(closure=optimizer_closure)
[rank12]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py", line 153, in step
[rank12]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank12]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank12]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py", line 238, in optimizer_step
[rank12]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank12]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank12]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/amp.py", line 75, in optimizer_step
[rank12]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank12]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank12]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 122, in optimizer_step
[rank12]:     return optimizer.step(closure=closure, **kwargs)
[rank12]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank12]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/optim/optimizer.py", line 516, in wrapper
[rank12]:     out = func(*args, **kwargs)
[rank12]:           ^^^^^^^^^^^^^^^^^^^^^
[rank12]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformer_engine/pytorch/optimizers/fused_adam.py", line 486, in step
[rank12]:     loss = closure()
[rank12]:            ^^^^^^^^^
[rank12]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 108, in _wrap_closure
[rank12]:     closure_result = closure()
[rank12]:                      ^^^^^^^^^
[rank12]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank12]:     self._result = self.closure(*args, **kwargs)
[rank12]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank12]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank12]:     return func(*args, **kwargs)
[rank12]:            ^^^^^^^^^^^^^^^^^^^^^
[rank12]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank12]:     step_output = self._step_fn()
[rank12]:                   ^^^^^^^^^^^^^^^
[rank12]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank12]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank12]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank12]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank12]:     output = fn(*args, **kwargs)
[rank12]:              ^^^^^^^^^^^^^^^^^^^
[rank12]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank12]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank12]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank12]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank12]:     outputs = self.forward(batch)
[rank12]:               ^^^^^^^^^^^^^^^^^^^
[rank12]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank12]:     return self.model(**batch)
[rank12]:            ^^^^^^^^^^^^^^^^^^^
[rank12]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank12]:     return self._call_impl(*args, **kwargs)
[rank12]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank12]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank12]:     return inner()
[rank12]:            ^^^^^^^
[rank12]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank12]:     result = forward_call(*args, **kwargs)
[rank12]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank12]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank12]:     output = func(self, *args, **kwargs)
[rank12]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank12]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank12]:     return func(*args, **kwargs)
[rank12]:            ^^^^^^^^^^^^^^^^^^^^^
[rank12]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank12]:     outputs: BaseModelOutputWithPast = self.model(
[rank12]:                                        ^^^^^^^^^^^
[rank12]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank12]:     return self._call_impl(*args, **kwargs)
[rank12]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank12]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank12]:     return forward_call(*args, **kwargs)
[rank12]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank12]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank12]:     output = func(self, *args, **kwargs)
[rank12]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank12]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 549, in forward
[rank12]:     layer_outputs = decoder_layer(
[rank12]:                     ^^^^^^^^^^^^^^
[rank12]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank12]:     return self._call_impl(*args, **kwargs)
[rank12]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank12]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank12]:     return inner()
[rank12]:            ^^^^^^^
[rank12]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank12]:     result = forward_call(*args, **kwargs)
[rank12]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank12]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 259, in forward
[rank12]:     hidden_states = self.input_layernorm(hidden_states)
[rank12]:                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank12]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank12]:     return self._call_impl(*args, **kwargs)
[rank12]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank12]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank12]:     return forward_call(*args, **kwargs)
[rank12]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank12]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 223, in forward
[rank12]:     variance = hidden_states.pow(2).mean(-1, keepdim=True)
[rank12]:                ^^^^^^^^^^^^^^^^^^^^
[rank12]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 640.00 MiB. GPU 0 has a total capacity of 79.19 GiB of which 399.81 MiB is free. Including non-PyTorch memory, this process has 78.79 GiB memory in use. Of the allocated memory 74.80 GiB is allocated by PyTorch, and 1.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
srun: error: jzxh356: task 56: Exited with exit code 1
srun: Terminating StepId=1542690.0
srun: error: jzxh123: task 18: Exited with exit code 1
srun: error: jzxh161: tasks 46-47: Exited with exit code 1
srun: error: jzxh091: tasks 4,7: Exited with exit code 1
srun: error: jzxh139: tasks 28-29: Exited with exit code 1
srun: error: jzxh003: tasks 1-2: Exited with exit code 1
srun: error: jzxh337: tasks 54-55: Exited with exit code 1
srun: error: jzxh159: tasks 37,39: Exited with exit code 1
srun: error: jzxh336: tasks 48-49: Exited with exit code 1
srun: error: jzxh126: tasks 24-25: Exited with exit code 1
srun: error: jzxh125: tasks 21,23: Exited with exit code 1
srun: error: jzxh160: tasks 42-43: Exited with exit code 1
srun: error: jzxh092: tasks 9-10: Exited with exit code 1
srun: error: jzxh122: tasks 12-13: Exited with exit code 1
srun: error: jzxh140: tasks 32-33: Exited with exit code 1
srun: error: jzxh357: tasks 60-61: Exited with exit code 1
slurmstepd: error: *** STEP 1542690.0 ON jzxh003 CANCELLED AT 2025-11-09T13:31:25 ***
srun: error: jzxh159: task 36: Exited with exit code 1
srun: error: jzxh092: task 8: Exited with exit code 1
srun: error: jzxh126: task 27: Exited with exit code 1
srun: error: jzxh140: task 34: Exited with exit code 1
srun: error: jzxh336: task 51: Exited with exit code 1
srun: error: jzxh122: task 15: Exited with exit code 1
srun: error: jzxh357: task 63: Exited with exit code 1
srun: error: jzxh160: task 40: Exited with exit code 1
srun: error: jzxh125: task 20: Exited with exit code 1
srun: error: jzxh091: tasks 5-6: Exited with exit code 1
srun: error: jzxh003: tasks 0,3: Exited with exit code 1
srun: error: jzxh139: tasks 30-31: Exited with exit code 1
srun: error: jzxh337: tasks 52-53: Exited with exit code 1
srun: error: jzxh161: tasks 44-45: Exited with exit code 1
srun: error: jzxh159: task 38: Exited with exit code 1
srun: error: jzxh336: task 50: Exited with exit code 1
srun: error: jzxh123: tasks 16-17,19: Exited with exit code 1
srun: error: jzxh356: tasks 57-59: Exited with exit code 1
srun: error: jzxh125: task 22: Exited with exit code 1
srun: error: jzxh126: task 26: Exited with exit code 1
srun: error: jzxh092: task 11: Exited with exit code 1
srun: error: jzxh160: task 41: Exited with exit code 1
srun: error: jzxh122: task 14: Exited with exit code 1
srun: error: jzxh140: task 35: Exited with exit code 1
srun: error: jzxh357: task 62: Exited with exit code 1

real	1m28.851s
user	0m0.021s
sys	0m0.059s
+ date
