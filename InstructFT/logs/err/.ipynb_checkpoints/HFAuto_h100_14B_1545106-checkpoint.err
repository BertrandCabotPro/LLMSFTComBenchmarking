Loading nemo/2.4.0
  Loading requirement: gcc/11.4.1 cuda/12.8.0 nccl/2.27.3-1-cuda
    cudnn/9.10.2.21-12-cuda openmpi/4.1.6-cuda intel-oneapi-mkl/2024.1
    magma/2.9.0-cuda sox/14.4.2 ffmpeg/6.1.1-cuda hdf5/1.12.0-mpi-cuda
    libjpeg-turbo/2.1.3
+ srun python -u nemo_TPFSDP2.py --model Qwen/Qwen2.5-14B-Instruct --use-te-optimizer --strategy fsdp2 --devices 4 --num-nodes 16 --tp-size 4 --dp-size 16 --batch-size 2
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
[NeMo W 2025-11-09 17:36:40 nemo_logging:405] /lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lhotse/recipes/iwslt22_ta.py:323: SyntaxWarning: invalid escape sequence '\s'
      text = re.sub("\s+", " ", text)
    
[NeMo W 2025-11-09 17:36:40 nemo_logging:405] /lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lhotse/recipes/iwslt22_ta.py:324: SyntaxWarning: invalid escape sequence '\s'
      text = re.sub("\s+\.\s+", ".", text)
    
[NeMo W 2025-11-09 17:36:40 nemo_logging:405] 
    
    ************************************************************************************************************************
    ************************************************************************************************************************
    *****  Automodel on NVIDIA/NeMo is deprecated. Please, use https://github.com/NVIDIA-NeMo/Automodel repo instead.  *****
    ************************************************************************************************************************
    ************************************************************************************************************************
    
[NeMo W 2025-11-09 17:36:40 nemo_logging:405] Waiting for 2 seconds before this message disappears.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
[NeMo W 2025-11-09 17:37:08 nemo_logging:405] /lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/jieba/__init__.py:44: SyntaxWarning: invalid escape sequence '\.'
      re_han_default = re.compile("([\u4E00-\u9FD5a-zA-Z0-9+#&\._%\-]+)", re.U)
    
[NeMo W 2025-11-09 17:37:08 nemo_logging:405] /lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/jieba/__init__.py:46: SyntaxWarning: invalid escape sequence '\s'
      re_skip_default = re.compile("(\r\n|\s)", re.U)
    
[NeMo W 2025-11-09 17:37:08 nemo_logging:405] /lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/jieba/finalseg/__init__.py:78: SyntaxWarning: invalid escape sequence '\.'
      re_skip = re.compile("([a-zA-Z0-9]+(?:\.\d+)?%?)")
    
[NeMo W 2025-11-09 17:37:12 nemo_logging:405] /lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/pydub/utils.py:300: SyntaxWarning: invalid escape sequence '\('
      m = re.match('([su]([0-9]{1,2})p?) \(([0-9]{1,2}) bit\)$', token)
    
[NeMo W 2025-11-09 17:37:12 nemo_logging:405] /lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/pydub/utils.py:301: SyntaxWarning: invalid escape sequence '\('
      m2 = re.match('([su]([0-9]{1,2})p?)( \(default\))?$', token)
    
[NeMo W 2025-11-09 17:37:12 nemo_logging:405] /lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/pydub/utils.py:310: SyntaxWarning: invalid escape sequence '\('
      elif re.match('(flt)p?( \(default\))?$', token):
    
[NeMo W 2025-11-09 17:37:12 nemo_logging:405] /lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/pydub/utils.py:314: SyntaxWarning: invalid escape sequence '\('
      elif re.match('(dbl)p?( \(default\))?$', token):
    
[NeMo W 2025-11-09 17:37:16 nemo_logging:405] Dependency for linear CE loss is not available.                     Please refer to https://github.com/apple/ml-cross-entropy.
Using bfloat16 Automatic Mixed Precision (AMP)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
[NeMo W 2025-11-09 17:37:17 nemo_logging:405] "update_logger_directory" is True. Overwriting tensorboard logger "save_dir" to /tmp/tmpnnk78agx
You are using a CUDA device ('NVIDIA H100 80GB HBM3') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 64 processes
----------------------------------------------------------------------------------------------------

Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 116.55it/s]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 143.85it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 141.55it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 144.62it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 140.29it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 136.11it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 139.63it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 142.70it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 140.66it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 140.64it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 141.48it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 136.66it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 139.46it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 141.00it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 139.37it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 139.57it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 140.68it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 140.13it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 139.42it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 138.52it/s]
LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 141.43it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 139.14it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 141.59it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 138.59it/s]
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 143.39it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 138.19it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 139.79it/s]
LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 127.19it/s]
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 128.09it/s]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 128.95it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 128.37it/s]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 155.33it/s]
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 128.29it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 128.04it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 127.61it/s]
LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 127.58it/s]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 127.22it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 125.82it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 128.71it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 126.56it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 132.91it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 131.51it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 127.42it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 126.44it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 130.61it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 127.02it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 130.87it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 127.74it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 128.02it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 128.61it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 127.96it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 125.93it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 126.50it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 127.35it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 123.43it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 125.50it/s]
LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 122.35it/s]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 122.83it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 122.92it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 122.61it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 125.52it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 124.62it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 125.89it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards: 100%|| 8/8 [00:00<00:00, 124.35it/s]
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
[rank32]: Traceback (most recent call last):
[rank32]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 525, in <module>
[rank32]:     main()
[rank32]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 495, in main
[rank32]:     llm.api.finetune(
[rank32]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank32]:     return train(
[rank32]:            ^^^^^^
[rank32]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank32]:     trainer.fit(model, data)
[rank32]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank32]:     call._call_and_handle_interrupt(
[rank32]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank32]:     return trainer_fn(*args, **kwargs)
[rank32]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank32]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank32]:     self._run(model, ckpt_path=ckpt_path)
[rank32]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank32]:     results = self._run_stage()
[rank32]:               ^^^^^^^^^^^^^^^^^
[rank32]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank32]:     self.fit_loop.run()
[rank32]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank32]:     self.advance()
[rank32]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank32]:     self.epoch_loop.run(self._data_fetcher)
[rank32]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank32]:     self.advance(data_fetcher)
[rank32]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank32]:     super().advance(data_fetcher)
[rank32]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank32]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank32]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank32]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 183, in run
[rank32]:     closure()
[rank32]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank32]:     self._result = self.closure(*args, **kwargs)
[rank32]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank32]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank32]:     return func(*args, **kwargs)
[rank32]:            ^^^^^^^^^^^^^^^^^^^^^
[rank32]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank32]:     step_output = self._step_fn()
[rank32]:                   ^^^^^^^^^^^^^^^
[rank32]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank32]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank32]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank32]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank32]:     output = fn(*args, **kwargs)
[rank32]:              ^^^^^^^^^^^^^^^^^^^
[rank32]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank32]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank32]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank32]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank32]:     outputs = self.forward(batch)
[rank32]:               ^^^^^^^^^^^^^^^^^^^
[rank32]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank32]:     return self.model(**batch)
[rank32]:            ^^^^^^^^^^^^^^^^^^^
[rank29]: Traceback (most recent call last):
[rank29]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 525, in <module>
[rank29]:     main()
[rank29]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 495, in main
[rank29]:     llm.api.finetune(
[rank29]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank29]:     return train(
[rank29]:            ^^^^^^
[rank29]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank29]:     trainer.fit(model, data)
[rank29]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank29]:     call._call_and_handle_interrupt(
[rank32]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank32]:     return self._call_impl(*args, **kwargs)
[rank32]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank32]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank32]:     return inner()
[rank32]:            ^^^^^^^
[rank32]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank32]:     result = forward_call(*args, **kwargs)
[rank32]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank32]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank32]:     output = func(self, *args, **kwargs)
[rank29]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank29]:     return trainer_fn(*args, **kwargs)
[rank29]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank29]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank29]:     self._run(model, ckpt_path=ckpt_path)
[rank29]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank29]:     results = self._run_stage()
[rank29]:               ^^^^^^^^^^^^^^^^^
[rank29]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank29]:     self.fit_loop.run()
[rank32]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank32]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank32]:     return func(*args, **kwargs)
[rank32]:            ^^^^^^^^^^^^^^^^^^^^^
[rank32]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank32]:     outputs: BaseModelOutputWithPast = self.model(
[rank32]:                                        ^^^^^^^^^^^
[rank32]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank32]:     return self._call_impl(*args, **kwargs)
[rank32]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank29]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank29]:     self.advance()
[rank29]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank29]:     self.epoch_loop.run(self._data_fetcher)
[rank29]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank29]:     self.advance(data_fetcher)
[rank29]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank29]:     super().advance(data_fetcher)
[rank32]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank32]:     return forward_call(*args, **kwargs)
[rank32]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank29]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank29]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank29]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank29]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 183, in run
[rank29]:     closure()
[rank29]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank29]:     self._result = self.closure(*args, **kwargs)
[rank29]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank32]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank32]:     output = func(self, *args, **kwargs)
[rank32]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank32]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 519, in forward
[rank32]:     causal_mask = self._update_causal_mask(
[rank32]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank32]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 591, in _update_causal_mask
[rank32]:     raise ValueError(
[rank29]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank29]:     return func(*args, **kwargs)
[rank29]:            ^^^^^^^^^^^^^^^^^^^^^
[rank32]: ValueError: You are attempting to perform batched generation with padding_side='right' this may lead to unexpected behaviour for Flash Attention version of Qwen2. Make sure to  call `tokenizer.padding_side  = 'left'` before tokenizing the input. 
[rank29]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank29]:     step_output = self._step_fn()
[rank29]:                   ^^^^^^^^^^^^^^^
[rank29]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank29]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank29]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank29]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank29]:     output = fn(*args, **kwargs)
[rank29]:              ^^^^^^^^^^^^^^^^^^^
[rank33]: Traceback (most recent call last):
[rank33]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 525, in <module>
[rank33]:     main()
[rank33]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 495, in main
[rank33]:     llm.api.finetune(
[rank33]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank33]:     return train(
[rank33]:            ^^^^^^
[rank33]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank33]:     trainer.fit(model, data)
[rank33]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank33]:     call._call_and_handle_interrupt(
[rank29]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank29]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank29]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank29]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank29]:     outputs = self.forward(batch)
[rank29]:               ^^^^^^^^^^^^^^^^^^^
[rank29]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank29]:     return self.model(**batch)
[rank29]:            ^^^^^^^^^^^^^^^^^^^
[rank33]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank33]:     return trainer_fn(*args, **kwargs)
[rank33]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank33]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank33]:     self._run(model, ckpt_path=ckpt_path)
[rank33]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank33]:     results = self._run_stage()
[rank33]:               ^^^^^^^^^^^^^^^^^
[rank33]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank33]:     self.fit_loop.run()
[rank29]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank29]:     return self._call_impl(*args, **kwargs)
[rank29]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank29]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank29]:     return inner()
[rank29]:            ^^^^^^^
[rank29]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank29]:     result = forward_call(*args, **kwargs)
[rank29]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank29]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank29]:     output = func(self, *args, **kwargs)
[rank33]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank33]:     self.advance()
[rank33]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank33]:     self.epoch_loop.run(self._data_fetcher)
[rank33]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank33]:     self.advance(data_fetcher)
[rank33]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank33]:     super().advance(data_fetcher)
[rank29]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank29]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank29]:     return func(*args, **kwargs)
[rank29]:            ^^^^^^^^^^^^^^^^^^^^^
[rank29]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank29]:     outputs: BaseModelOutputWithPast = self.model(
[rank29]:                                        ^^^^^^^^^^^
[rank29]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank29]:     return self._call_impl(*args, **kwargs)
[rank29]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank33]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank33]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank33]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank33]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 183, in run
[rank33]:     closure()
[rank33]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank33]:     self._result = self.closure(*args, **kwargs)
[rank33]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank29]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank29]:     return forward_call(*args, **kwargs)
[rank29]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank33]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank33]:     return func(*args, **kwargs)
[rank33]:            ^^^^^^^^^^^^^^^^^^^^^
[rank29]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank29]:     output = func(self, *args, **kwargs)
[rank29]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank29]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 519, in forward
[rank29]:     causal_mask = self._update_causal_mask(
[rank29]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank29]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 591, in _update_causal_mask
[rank29]:     raise ValueError(
[rank33]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank33]:     step_output = self._step_fn()
[rank33]:                   ^^^^^^^^^^^^^^^
[rank33]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank33]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank33]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank33]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank33]:     output = fn(*args, **kwargs)
[rank33]:              ^^^^^^^^^^^^^^^^^^^
[rank29]: ValueError: You are attempting to perform batched generation with padding_side='right' this may lead to unexpected behaviour for Flash Attention version of Qwen2. Make sure to  call `tokenizer.padding_side  = 'left'` before tokenizing the input. 
[rank33]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank33]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank33]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank33]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank33]:     outputs = self.forward(batch)
[rank33]:               ^^^^^^^^^^^^^^^^^^^
[rank33]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank33]:     return self.model(**batch)
[rank33]:            ^^^^^^^^^^^^^^^^^^^
[rank33]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank33]:     return self._call_impl(*args, **kwargs)
[rank33]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank33]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank33]:     return inner()
[rank33]:            ^^^^^^^
[rank33]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank33]:     result = forward_call(*args, **kwargs)
[rank33]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank33]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank33]:     output = func(self, *args, **kwargs)
[rank33]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank33]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank33]:     return func(*args, **kwargs)
[rank33]:            ^^^^^^^^^^^^^^^^^^^^^
[rank33]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank33]:     outputs: BaseModelOutputWithPast = self.model(
[rank33]:                                        ^^^^^^^^^^^
[rank33]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank33]:     return self._call_impl(*args, **kwargs)
[rank33]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank33]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank33]:     return forward_call(*args, **kwargs)
[rank33]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank33]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank33]:     output = func(self, *args, **kwargs)
[rank33]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank33]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 519, in forward
[rank33]:     causal_mask = self._update_causal_mask(
[rank33]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank33]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 591, in _update_causal_mask
[rank33]:     raise ValueError(
[rank33]: ValueError: You are attempting to perform batched generation with padding_side='right' this may lead to unexpected behaviour for Flash Attention version of Qwen2. Make sure to  call `tokenizer.padding_side  = 'left'` before tokenizing the input. 
[rank34]: Traceback (most recent call last):
[rank34]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 525, in <module>
[rank34]:     main()
[rank34]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 495, in main
[rank34]:     llm.api.finetune(
[rank34]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank34]:     return train(
[rank34]:            ^^^^^^
[rank34]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank34]:     trainer.fit(model, data)
[rank34]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank34]:     call._call_and_handle_interrupt(
[rank34]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank34]:     return trainer_fn(*args, **kwargs)
[rank34]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank34]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank34]:     self._run(model, ckpt_path=ckpt_path)
[rank34]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank34]:     results = self._run_stage()
[rank34]:               ^^^^^^^^^^^^^^^^^
[rank34]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank34]:     self.fit_loop.run()
[rank34]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank34]:     self.advance()
[rank34]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank34]:     self.epoch_loop.run(self._data_fetcher)
[rank34]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank34]:     self.advance(data_fetcher)
[rank34]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank34]:     super().advance(data_fetcher)
[rank34]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank34]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank34]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank34]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 183, in run
[rank34]:     closure()
[rank34]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank34]:     self._result = self.closure(*args, **kwargs)
[rank34]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank34]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank34]:     return func(*args, **kwargs)
[rank34]:            ^^^^^^^^^^^^^^^^^^^^^
[rank34]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank34]:     step_output = self._step_fn()
[rank34]:                   ^^^^^^^^^^^^^^^
[rank34]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank34]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank34]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank34]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank34]:     output = fn(*args, **kwargs)
[rank34]:              ^^^^^^^^^^^^^^^^^^^
[rank34]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank34]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank34]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank34]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank34]:     outputs = self.forward(batch)
[rank34]:               ^^^^^^^^^^^^^^^^^^^
[rank34]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank34]:     return self.model(**batch)
[rank34]:            ^^^^^^^^^^^^^^^^^^^
[rank34]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank34]:     return self._call_impl(*args, **kwargs)
[rank34]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank34]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank34]:     return inner()
[rank34]:            ^^^^^^^
[rank34]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank34]:     result = forward_call(*args, **kwargs)
[rank34]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank34]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank34]:     output = func(self, *args, **kwargs)
[rank34]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank34]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank34]:     return func(*args, **kwargs)
[rank34]:            ^^^^^^^^^^^^^^^^^^^^^
[rank34]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank34]:     outputs: BaseModelOutputWithPast = self.model(
[rank34]:                                        ^^^^^^^^^^^
[rank34]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank34]:     return self._call_impl(*args, **kwargs)
[rank34]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank34]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank34]:     return forward_call(*args, **kwargs)
[rank34]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank34]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank34]:     output = func(self, *args, **kwargs)
[rank34]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank34]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 519, in forward
[rank34]:     causal_mask = self._update_causal_mask(
[rank34]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank34]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 591, in _update_causal_mask
[rank34]:     raise ValueError(
[rank34]: ValueError: You are attempting to perform batched generation with padding_side='right' this may lead to unexpected behaviour for Flash Attention version of Qwen2. Make sure to  call `tokenizer.padding_side  = 'left'` before tokenizing the input. 
[rank35]: Traceback (most recent call last):
[rank35]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 525, in <module>
[rank35]:     main()
[rank35]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 495, in main
[rank35]:     llm.api.finetune(
[rank35]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank35]:     return train(
[rank35]:            ^^^^^^
[rank35]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank35]:     trainer.fit(model, data)
[rank35]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank35]:     call._call_and_handle_interrupt(
[rank35]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank35]:     return trainer_fn(*args, **kwargs)
[rank35]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank35]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank35]:     self._run(model, ckpt_path=ckpt_path)
[rank35]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank35]:     results = self._run_stage()
[rank35]:               ^^^^^^^^^^^^^^^^^
[rank35]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank35]:     self.fit_loop.run()
[rank35]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank35]:     self.advance()
[rank35]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank35]:     self.epoch_loop.run(self._data_fetcher)
[rank35]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank35]:     self.advance(data_fetcher)
[rank35]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank35]:     super().advance(data_fetcher)
[rank35]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank35]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank35]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank35]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 183, in run
[rank35]:     closure()
[rank35]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank35]:     self._result = self.closure(*args, **kwargs)
[rank35]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank35]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank35]:     return func(*args, **kwargs)
[rank35]:            ^^^^^^^^^^^^^^^^^^^^^
[rank35]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank35]:     step_output = self._step_fn()
[rank35]:                   ^^^^^^^^^^^^^^^
[rank35]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank35]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank35]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank35]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank35]:     output = fn(*args, **kwargs)
[rank35]:              ^^^^^^^^^^^^^^^^^^^
[rank35]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank35]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank35]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank35]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank35]:     outputs = self.forward(batch)
[rank35]:               ^^^^^^^^^^^^^^^^^^^
[rank35]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank35]:     return self.model(**batch)
[rank35]:            ^^^^^^^^^^^^^^^^^^^
[rank35]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank35]:     return self._call_impl(*args, **kwargs)
[rank35]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank35]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank35]:     return inner()
[rank35]:            ^^^^^^^
[rank35]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank35]:     result = forward_call(*args, **kwargs)
[rank35]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank35]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank35]:     output = func(self, *args, **kwargs)
[rank35]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank35]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank35]:     return func(*args, **kwargs)
[rank35]:            ^^^^^^^^^^^^^^^^^^^^^
[rank35]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank35]:     outputs: BaseModelOutputWithPast = self.model(
[rank35]:                                        ^^^^^^^^^^^
[rank35]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank35]:     return self._call_impl(*args, **kwargs)
[rank35]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank35]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank35]:     return forward_call(*args, **kwargs)
[rank35]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank35]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank35]:     output = func(self, *args, **kwargs)
[rank35]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank35]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 519, in forward
[rank35]:     causal_mask = self._update_causal_mask(
[rank35]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank35]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 591, in _update_causal_mask
[rank35]:     raise ValueError(
[rank35]: ValueError: You are attempting to perform batched generation with padding_side='right' this may lead to unexpected behaviour for Flash Attention version of Qwen2. Make sure to  call `tokenizer.padding_side  = 'left'` before tokenizing the input. 
[rank31]: Traceback (most recent call last):
[rank31]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 525, in <module>
[rank31]:     main()
[rank31]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 495, in main
[rank31]:     llm.api.finetune(
[rank31]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank31]:     return train(
[rank31]:            ^^^^^^
[rank31]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank31]:     trainer.fit(model, data)
[rank31]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank31]:     call._call_and_handle_interrupt(
[rank31]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank31]:     return trainer_fn(*args, **kwargs)
[rank31]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank31]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank31]:     self._run(model, ckpt_path=ckpt_path)
[rank31]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank31]:     results = self._run_stage()
[rank31]:               ^^^^^^^^^^^^^^^^^
[rank31]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank31]:     self.fit_loop.run()
[rank31]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank31]:     self.advance()
[rank31]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank31]:     self.epoch_loop.run(self._data_fetcher)
[rank31]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank31]:     self.advance(data_fetcher)
[rank31]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank31]:     super().advance(data_fetcher)
[rank31]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank31]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank31]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank31]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 183, in run
[rank31]:     closure()
[rank31]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank31]:     self._result = self.closure(*args, **kwargs)
[rank31]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank31]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank31]:     return func(*args, **kwargs)
[rank31]:            ^^^^^^^^^^^^^^^^^^^^^
[rank31]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank31]:     step_output = self._step_fn()
[rank31]:                   ^^^^^^^^^^^^^^^
[rank31]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank31]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank31]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank31]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank31]:     output = fn(*args, **kwargs)
[rank31]:              ^^^^^^^^^^^^^^^^^^^
[rank31]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank31]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank31]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank31]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank31]:     outputs = self.forward(batch)
[rank31]:               ^^^^^^^^^^^^^^^^^^^
[rank31]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank31]:     return self.model(**batch)
[rank31]:            ^^^^^^^^^^^^^^^^^^^
[rank31]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank31]:     return self._call_impl(*args, **kwargs)
[rank31]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank31]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank31]:     return inner()
[rank31]:            ^^^^^^^
[rank31]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank31]:     result = forward_call(*args, **kwargs)
[rank31]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank31]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank31]:     output = func(self, *args, **kwargs)
[rank31]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank31]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank31]:     return func(*args, **kwargs)
[rank31]:            ^^^^^^^^^^^^^^^^^^^^^
[rank31]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank31]:     outputs: BaseModelOutputWithPast = self.model(
[rank31]:                                        ^^^^^^^^^^^
[rank31]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank31]:     return self._call_impl(*args, **kwargs)
[rank31]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank31]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank31]:     return forward_call(*args, **kwargs)
[rank31]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank31]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank31]:     output = func(self, *args, **kwargs)
[rank31]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank31]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 519, in forward
[rank31]:     causal_mask = self._update_causal_mask(
[rank31]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank31]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 591, in _update_causal_mask
[rank31]:     raise ValueError(
[rank31]: ValueError: You are attempting to perform batched generation with padding_side='right' this may lead to unexpected behaviour for Flash Attention version of Qwen2. Make sure to  call `tokenizer.padding_side  = 'left'` before tokenizing the input. 
[rank30]: Traceback (most recent call last):
[rank30]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 525, in <module>
[rank30]:     main()
[rank30]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 495, in main
[rank30]:     llm.api.finetune(
[rank30]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank30]:     return train(
[rank30]:            ^^^^^^
[rank30]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank30]:     trainer.fit(model, data)
[rank30]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank30]:     call._call_and_handle_interrupt(
[rank30]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank30]:     return trainer_fn(*args, **kwargs)
[rank30]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank30]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank30]:     self._run(model, ckpt_path=ckpt_path)
[rank30]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank30]:     results = self._run_stage()
[rank30]:               ^^^^^^^^^^^^^^^^^
[rank30]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank30]:     self.fit_loop.run()
[rank30]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank30]:     self.advance()
[rank30]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank30]:     self.epoch_loop.run(self._data_fetcher)
[rank30]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank30]:     self.advance(data_fetcher)
[rank30]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank30]:     super().advance(data_fetcher)
[rank30]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank30]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank30]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank30]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 183, in run
[rank30]:     closure()
[rank30]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank30]:     self._result = self.closure(*args, **kwargs)
[rank30]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank30]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank30]:     return func(*args, **kwargs)
[rank30]:            ^^^^^^^^^^^^^^^^^^^^^
[rank30]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank30]:     step_output = self._step_fn()
[rank30]:                   ^^^^^^^^^^^^^^^
[rank30]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank30]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank30]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank30]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank30]:     output = fn(*args, **kwargs)
[rank30]:              ^^^^^^^^^^^^^^^^^^^
[rank30]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank30]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank30]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank30]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank30]:     outputs = self.forward(batch)
[rank30]:               ^^^^^^^^^^^^^^^^^^^
[rank30]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank30]:     return self.model(**batch)
[rank30]:            ^^^^^^^^^^^^^^^^^^^
[rank30]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank30]:     return self._call_impl(*args, **kwargs)
[rank30]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank30]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank30]:     return inner()
[rank30]:            ^^^^^^^
[rank30]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank30]:     result = forward_call(*args, **kwargs)
[rank30]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank30]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank30]:     output = func(self, *args, **kwargs)
[rank30]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank30]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank30]:     return func(*args, **kwargs)
[rank30]:            ^^^^^^^^^^^^^^^^^^^^^
[rank30]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank30]:     outputs: BaseModelOutputWithPast = self.model(
[rank30]:                                        ^^^^^^^^^^^
[rank30]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank30]:     return self._call_impl(*args, **kwargs)
[rank30]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank30]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank30]:     return forward_call(*args, **kwargs)
[rank30]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank30]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank30]:     output = func(self, *args, **kwargs)
[rank30]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank30]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 519, in forward
[rank30]:     causal_mask = self._update_causal_mask(
[rank30]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank30]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 591, in _update_causal_mask
[rank30]:     raise ValueError(
[rank30]: ValueError: You are attempting to perform batched generation with padding_side='right' this may lead to unexpected behaviour for Flash Attention version of Qwen2. Make sure to  call `tokenizer.padding_side  = 'left'` before tokenizing the input. 
[rank39]: Traceback (most recent call last):
[rank39]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 525, in <module>
[rank39]:     main()
[rank39]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 495, in main
[rank39]:     llm.api.finetune(
[rank39]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank39]:     return train(
[rank39]:            ^^^^^^
[rank39]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank39]:     trainer.fit(model, data)
[rank39]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank39]:     call._call_and_handle_interrupt(
[rank39]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank39]:     return trainer_fn(*args, **kwargs)
[rank39]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank39]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank39]:     self._run(model, ckpt_path=ckpt_path)
[rank39]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank39]:     results = self._run_stage()
[rank39]:               ^^^^^^^^^^^^^^^^^
[rank39]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank39]:     self.fit_loop.run()
[rank39]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank39]:     self.advance()
[rank39]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank39]:     self.epoch_loop.run(self._data_fetcher)
[rank39]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank39]:     self.advance(data_fetcher)
[rank39]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank39]:     super().advance(data_fetcher)
[rank39]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank39]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank39]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank39]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 183, in run
[rank39]:     closure()
[rank39]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank39]:     self._result = self.closure(*args, **kwargs)
[rank39]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank39]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank39]:     return func(*args, **kwargs)
[rank39]:            ^^^^^^^^^^^^^^^^^^^^^
[rank39]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank39]:     step_output = self._step_fn()
[rank39]:                   ^^^^^^^^^^^^^^^
[rank39]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank39]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank39]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank39]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank39]:     output = fn(*args, **kwargs)
[rank39]:              ^^^^^^^^^^^^^^^^^^^
[rank39]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank39]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank39]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank39]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank39]:     outputs = self.forward(batch)
[rank39]:               ^^^^^^^^^^^^^^^^^^^
[rank39]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank39]:     return self.model(**batch)
[rank39]:            ^^^^^^^^^^^^^^^^^^^
[rank39]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank39]:     return self._call_impl(*args, **kwargs)
[rank39]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank39]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank39]:     return inner()
[rank39]:            ^^^^^^^
[rank39]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank39]:     result = forward_call(*args, **kwargs)
[rank39]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank39]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank39]:     output = func(self, *args, **kwargs)
[rank39]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank39]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank39]:     return func(*args, **kwargs)
[rank39]:            ^^^^^^^^^^^^^^^^^^^^^
[rank39]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank39]:     outputs: BaseModelOutputWithPast = self.model(
[rank39]:                                        ^^^^^^^^^^^
[rank39]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank39]:     return self._call_impl(*args, **kwargs)
[rank39]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank39]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank39]:     return forward_call(*args, **kwargs)
[rank39]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank39]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank39]:     output = func(self, *args, **kwargs)
[rank39]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank39]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 519, in forward
[rank39]:     causal_mask = self._update_causal_mask(
[rank39]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank39]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 591, in _update_causal_mask
[rank39]:     raise ValueError(
[rank39]: ValueError: You are attempting to perform batched generation with padding_side='right' this may lead to unexpected behaviour for Flash Attention version of Qwen2. Make sure to  call `tokenizer.padding_side  = 'left'` before tokenizing the input. 
[rank38]: Traceback (most recent call last):
[rank38]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 525, in <module>
[rank38]:     main()
[rank38]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 495, in main
[rank38]:     llm.api.finetune(
[rank38]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank38]:     return train(
[rank38]:            ^^^^^^
[rank38]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank38]:     trainer.fit(model, data)
[rank38]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank38]:     call._call_and_handle_interrupt(
[rank38]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank38]:     return trainer_fn(*args, **kwargs)
[rank38]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank38]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank38]:     self._run(model, ckpt_path=ckpt_path)
[rank38]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank38]:     results = self._run_stage()
[rank38]:               ^^^^^^^^^^^^^^^^^
[rank38]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank38]:     self.fit_loop.run()
[rank38]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank38]:     self.advance()
[rank38]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank38]:     self.epoch_loop.run(self._data_fetcher)
[rank38]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank38]:     self.advance(data_fetcher)
[rank38]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank38]:     super().advance(data_fetcher)
[rank38]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank38]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank38]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank38]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 183, in run
[rank38]:     closure()
[rank38]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank38]:     self._result = self.closure(*args, **kwargs)
[rank38]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank38]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank38]:     return func(*args, **kwargs)
[rank38]:            ^^^^^^^^^^^^^^^^^^^^^
[rank38]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank38]:     step_output = self._step_fn()
[rank38]:                   ^^^^^^^^^^^^^^^
[rank38]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank38]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank38]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank38]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank38]:     output = fn(*args, **kwargs)
[rank38]:              ^^^^^^^^^^^^^^^^^^^
[rank38]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank38]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank38]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank38]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank38]:     outputs = self.forward(batch)
[rank38]:               ^^^^^^^^^^^^^^^^^^^
[rank38]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank38]:     return self.model(**batch)
[rank38]:            ^^^^^^^^^^^^^^^^^^^
[rank38]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank38]:     return self._call_impl(*args, **kwargs)
[rank38]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank38]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank38]:     return inner()
[rank38]:            ^^^^^^^
[rank38]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank38]:     result = forward_call(*args, **kwargs)
[rank38]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank38]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank38]:     output = func(self, *args, **kwargs)
[rank38]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank38]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank38]:     return func(*args, **kwargs)
[rank38]:            ^^^^^^^^^^^^^^^^^^^^^
[rank38]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank38]:     outputs: BaseModelOutputWithPast = self.model(
[rank38]:                                        ^^^^^^^^^^^
[rank38]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank38]:     return self._call_impl(*args, **kwargs)
[rank38]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank38]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank38]:     return forward_call(*args, **kwargs)
[rank38]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank38]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank38]:     output = func(self, *args, **kwargs)
[rank38]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank38]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 519, in forward
[rank38]:     causal_mask = self._update_causal_mask(
[rank38]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank38]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 591, in _update_causal_mask
[rank38]:     raise ValueError(
[rank38]: ValueError: You are attempting to perform batched generation with padding_side='right' this may lead to unexpected behaviour for Flash Attention version of Qwen2. Make sure to  call `tokenizer.padding_side  = 'left'` before tokenizing the input. 
[rank7]: Traceback (most recent call last):
[rank7]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 525, in <module>
[rank7]:     main()
[rank7]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 495, in main
[rank7]:     llm.api.finetune(
[rank7]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank7]:     return train(
[rank7]:            ^^^^^^
[rank7]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank7]:     trainer.fit(model, data)
[rank7]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank7]:     call._call_and_handle_interrupt(
[rank7]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank7]:     return trainer_fn(*args, **kwargs)
[rank7]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank7]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank7]:     self._run(model, ckpt_path=ckpt_path)
[rank7]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank7]:     results = self._run_stage()
[rank7]:               ^^^^^^^^^^^^^^^^^
[rank7]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank7]:     self.fit_loop.run()
[rank7]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank7]:     self.advance()
[rank7]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank7]:     self.epoch_loop.run(self._data_fetcher)
[rank7]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank7]:     self.advance(data_fetcher)
[rank7]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank7]:     super().advance(data_fetcher)
[rank7]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank7]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank7]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank7]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 183, in run
[rank7]:     closure()
[rank7]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank7]:     self._result = self.closure(*args, **kwargs)
[rank7]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank7]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank7]:     return func(*args, **kwargs)
[rank7]:            ^^^^^^^^^^^^^^^^^^^^^
[rank7]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank7]:     step_output = self._step_fn()
[rank7]:                   ^^^^^^^^^^^^^^^
[rank7]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank7]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank7]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank7]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank7]:     output = fn(*args, **kwargs)
[rank7]:              ^^^^^^^^^^^^^^^^^^^
[rank7]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank7]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank7]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank7]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank7]:     outputs = self.forward(batch)
[rank7]:               ^^^^^^^^^^^^^^^^^^^
[rank7]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank7]:     return self.model(**batch)
[rank7]:            ^^^^^^^^^^^^^^^^^^^
[rank7]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank7]:     return self._call_impl(*args, **kwargs)
[rank7]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank7]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank7]:     return inner()
[rank7]:            ^^^^^^^
[rank7]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank7]:     result = forward_call(*args, **kwargs)
[rank7]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank7]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank7]:     output = func(self, *args, **kwargs)
[rank7]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank7]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank7]:     return func(*args, **kwargs)
[rank7]:            ^^^^^^^^^^^^^^^^^^^^^
[rank7]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank7]:     outputs: BaseModelOutputWithPast = self.model(
[rank7]:                                        ^^^^^^^^^^^
[rank7]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank7]:     return self._call_impl(*args, **kwargs)
[rank7]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank7]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank7]:     return forward_call(*args, **kwargs)
[rank7]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank7]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank7]:     output = func(self, *args, **kwargs)
[rank7]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank7]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 519, in forward
[rank7]:     causal_mask = self._update_causal_mask(
[rank7]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank7]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 591, in _update_causal_mask
[rank7]:     raise ValueError(
[rank7]: ValueError: You are attempting to perform batched generation with padding_side='right' this may lead to unexpected behaviour for Flash Attention version of Qwen2. Make sure to  call `tokenizer.padding_side  = 'left'` before tokenizing the input. 
[rank28]: Traceback (most recent call last):
[rank28]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 525, in <module>
[rank28]:     main()
[rank28]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 495, in main
[rank28]:     llm.api.finetune(
[rank28]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank28]:     return train(
[rank28]:            ^^^^^^
[rank28]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank28]:     trainer.fit(model, data)
[rank28]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank28]:     call._call_and_handle_interrupt(
[rank28]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank28]:     return trainer_fn(*args, **kwargs)
[rank28]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank28]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank28]:     self._run(model, ckpt_path=ckpt_path)
[rank28]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank28]:     results = self._run_stage()
[rank28]:               ^^^^^^^^^^^^^^^^^
[rank28]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank28]:     self.fit_loop.run()
[rank28]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank28]:     self.advance()
[rank28]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank28]:     self.epoch_loop.run(self._data_fetcher)
[rank28]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank28]:     self.advance(data_fetcher)
[rank28]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank28]:     super().advance(data_fetcher)
[rank28]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank28]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank28]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank28]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 183, in run
[rank28]:     closure()
[rank28]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank28]:     self._result = self.closure(*args, **kwargs)
[rank28]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank4]: Traceback (most recent call last):
[rank4]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 525, in <module>
[rank4]:     main()
[rank4]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 495, in main
[rank4]:     llm.api.finetune(
[rank4]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank4]:     return train(
[rank4]:            ^^^^^^
[rank4]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank4]:     trainer.fit(model, data)
[rank4]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank4]:     call._call_and_handle_interrupt(
[rank28]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank28]:     return func(*args, **kwargs)
[rank28]:            ^^^^^^^^^^^^^^^^^^^^^
[rank28]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank28]:     step_output = self._step_fn()
[rank28]:                   ^^^^^^^^^^^^^^^
[rank28]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank28]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank28]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank28]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank28]:     output = fn(*args, **kwargs)
[rank28]:              ^^^^^^^^^^^^^^^^^^^
[rank28]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank28]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank28]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank28]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank28]:     outputs = self.forward(batch)
[rank28]:               ^^^^^^^^^^^^^^^^^^^
[rank28]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank28]:     return self.model(**batch)
[rank28]:            ^^^^^^^^^^^^^^^^^^^
[rank28]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank28]:     return self._call_impl(*args, **kwargs)
[rank28]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank28]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank28]:     return inner()
[rank28]:            ^^^^^^^
[rank28]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank28]:     result = forward_call(*args, **kwargs)
[rank28]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank28]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank28]:     output = func(self, *args, **kwargs)
[rank28]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank28]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank28]:     return func(*args, **kwargs)
[rank28]:            ^^^^^^^^^^^^^^^^^^^^^
[rank28]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank28]:     outputs: BaseModelOutputWithPast = self.model(
[rank28]:                                        ^^^^^^^^^^^
[rank28]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank28]:     return self._call_impl(*args, **kwargs)
[rank28]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank28]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank28]:     return forward_call(*args, **kwargs)
[rank28]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank4]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank4]:     return trainer_fn(*args, **kwargs)
[rank4]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank4]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank4]:     self._run(model, ckpt_path=ckpt_path)
[rank4]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank4]:     results = self._run_stage()
[rank4]:               ^^^^^^^^^^^^^^^^^
[rank4]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank4]:     self.fit_loop.run()
[rank28]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank28]:     output = func(self, *args, **kwargs)
[rank28]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank28]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 519, in forward
[rank28]:     causal_mask = self._update_causal_mask(
[rank28]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank28]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 591, in _update_causal_mask
[rank28]:     raise ValueError(
[rank4]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank4]:     self.advance()
[rank4]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank4]:     self.epoch_loop.run(self._data_fetcher)
[rank4]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank4]:     self.advance(data_fetcher)
[rank4]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank4]:     super().advance(data_fetcher)
[rank28]: ValueError: You are attempting to perform batched generation with padding_side='right' this may lead to unexpected behaviour for Flash Attention version of Qwen2. Make sure to  call `tokenizer.padding_side  = 'left'` before tokenizing the input. 
[rank4]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank4]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank4]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank4]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 183, in run
[rank4]:     closure()
[rank4]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank4]:     self._result = self.closure(*args, **kwargs)
[rank4]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank4]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank4]:     return func(*args, **kwargs)
[rank4]:            ^^^^^^^^^^^^^^^^^^^^^
[rank4]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank4]:     step_output = self._step_fn()
[rank4]:                   ^^^^^^^^^^^^^^^
[rank4]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank4]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank4]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank4]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank4]:     output = fn(*args, **kwargs)
[rank4]:              ^^^^^^^^^^^^^^^^^^^
[rank4]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank4]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank4]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank4]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank4]:     outputs = self.forward(batch)
[rank4]:               ^^^^^^^^^^^^^^^^^^^
[rank4]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank4]:     return self.model(**batch)
[rank4]:            ^^^^^^^^^^^^^^^^^^^
[rank4]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank4]:     return self._call_impl(*args, **kwargs)
[rank4]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank4]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank4]:     return inner()
[rank4]:            ^^^^^^^
[rank4]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank4]:     result = forward_call(*args, **kwargs)
[rank4]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank4]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank4]:     output = func(self, *args, **kwargs)
[rank4]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank4]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank4]:     return func(*args, **kwargs)
[rank4]:            ^^^^^^^^^^^^^^^^^^^^^
[rank4]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank4]:     outputs: BaseModelOutputWithPast = self.model(
[rank4]:                                        ^^^^^^^^^^^
[rank4]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank4]:     return self._call_impl(*args, **kwargs)
[rank4]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank4]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank4]:     return forward_call(*args, **kwargs)
[rank4]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank5]: Traceback (most recent call last):
[rank5]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 525, in <module>
[rank5]:     main()
[rank5]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 495, in main
[rank5]:     llm.api.finetune(
[rank5]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank5]:     return train(
[rank5]:            ^^^^^^
[rank5]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank5]:     trainer.fit(model, data)
[rank5]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank5]:     call._call_and_handle_interrupt(
[rank5]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank5]:     return trainer_fn(*args, **kwargs)
[rank5]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank5]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank5]:     self._run(model, ckpt_path=ckpt_path)
[rank5]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank5]:     results = self._run_stage()
[rank5]:               ^^^^^^^^^^^^^^^^^
[rank5]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank5]:     self.fit_loop.run()
[rank5]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank5]:     self.advance()
[rank5]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank5]:     self.epoch_loop.run(self._data_fetcher)
[rank5]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank5]:     self.advance(data_fetcher)
[rank5]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank5]:     super().advance(data_fetcher)
[rank5]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank5]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank5]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank5]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 183, in run
[rank5]:     closure()
[rank5]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank5]:     self._result = self.closure(*args, **kwargs)
[rank5]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank5]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank5]:     return func(*args, **kwargs)
[rank5]:            ^^^^^^^^^^^^^^^^^^^^^
[rank4]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank4]:     output = func(self, *args, **kwargs)
[rank4]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank4]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 519, in forward
[rank4]:     causal_mask = self._update_causal_mask(
[rank4]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank4]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 591, in _update_causal_mask
[rank4]:     raise ValueError(
[rank4]: ValueError: You are attempting to perform batched generation with padding_side='right' this may lead to unexpected behaviour for Flash Attention version of Qwen2. Make sure to  call `tokenizer.padding_side  = 'left'` before tokenizing the input. 
[rank5]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank5]:     step_output = self._step_fn()
[rank5]:                   ^^^^^^^^^^^^^^^
[rank5]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank5]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank5]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank5]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank5]:     output = fn(*args, **kwargs)
[rank5]:              ^^^^^^^^^^^^^^^^^^^
[rank5]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank5]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank5]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank5]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank5]:     outputs = self.forward(batch)
[rank5]:               ^^^^^^^^^^^^^^^^^^^
[rank5]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank5]:     return self.model(**batch)
[rank5]:            ^^^^^^^^^^^^^^^^^^^
[rank5]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank5]:     return self._call_impl(*args, **kwargs)
[rank5]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank5]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank5]:     return inner()
[rank5]:            ^^^^^^^
[rank5]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank5]:     result = forward_call(*args, **kwargs)
[rank5]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank5]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank5]:     output = func(self, *args, **kwargs)
[rank5]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank5]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank5]:     return func(*args, **kwargs)
[rank5]:            ^^^^^^^^^^^^^^^^^^^^^
[rank5]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank5]:     outputs: BaseModelOutputWithPast = self.model(
[rank5]:                                        ^^^^^^^^^^^
[rank5]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank5]:     return self._call_impl(*args, **kwargs)
[rank5]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank5]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank5]:     return forward_call(*args, **kwargs)
[rank5]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank5]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank5]:     output = func(self, *args, **kwargs)
[rank5]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank5]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 519, in forward
[rank5]:     causal_mask = self._update_causal_mask(
[rank5]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank5]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 591, in _update_causal_mask
[rank5]:     raise ValueError(
[rank5]: ValueError: You are attempting to perform batched generation with padding_side='right' this may lead to unexpected behaviour for Flash Attention version of Qwen2. Make sure to  call `tokenizer.padding_side  = 'left'` before tokenizing the input. 
[rank6]: Traceback (most recent call last):
[rank6]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 525, in <module>
[rank6]:     main()
[rank6]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 495, in main
[rank6]:     llm.api.finetune(
[rank6]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank6]:     return train(
[rank6]:            ^^^^^^
[rank6]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank6]:     trainer.fit(model, data)
[rank6]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank6]:     call._call_and_handle_interrupt(
[rank6]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank6]:     return trainer_fn(*args, **kwargs)
[rank6]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank6]:     self._run(model, ckpt_path=ckpt_path)
[rank6]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank6]:     results = self._run_stage()
[rank6]:               ^^^^^^^^^^^^^^^^^
[rank6]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank6]:     self.fit_loop.run()
[rank6]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank6]:     self.advance()
[rank6]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank6]:     self.epoch_loop.run(self._data_fetcher)
[rank6]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank6]:     self.advance(data_fetcher)
[rank6]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank6]:     super().advance(data_fetcher)
[rank6]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank6]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank6]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 183, in run
[rank6]:     closure()
[rank6]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank6]:     self._result = self.closure(*args, **kwargs)
[rank6]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank6]:     return func(*args, **kwargs)
[rank6]:            ^^^^^^^^^^^^^^^^^^^^^
[rank6]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank6]:     step_output = self._step_fn()
[rank6]:                   ^^^^^^^^^^^^^^^
[rank6]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank6]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank6]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank6]:     output = fn(*args, **kwargs)
[rank6]:              ^^^^^^^^^^^^^^^^^^^
[rank6]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank6]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank6]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank6]:     outputs = self.forward(batch)
[rank6]:               ^^^^^^^^^^^^^^^^^^^
[rank6]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank6]:     return self.model(**batch)
[rank6]:            ^^^^^^^^^^^^^^^^^^^
[rank6]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank6]:     return self._call_impl(*args, **kwargs)
[rank6]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank6]:     return inner()
[rank6]:            ^^^^^^^
[rank6]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank6]:     result = forward_call(*args, **kwargs)
[rank6]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank6]:     output = func(self, *args, **kwargs)
[rank6]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank6]:     return func(*args, **kwargs)
[rank6]:            ^^^^^^^^^^^^^^^^^^^^^
[rank6]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank6]:     outputs: BaseModelOutputWithPast = self.model(
[rank6]:                                        ^^^^^^^^^^^
[rank6]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank6]:     return self._call_impl(*args, **kwargs)
[rank6]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank6]:     return forward_call(*args, **kwargs)
[rank6]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank6]:     output = func(self, *args, **kwargs)
[rank6]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 519, in forward
[rank6]:     causal_mask = self._update_causal_mask(
[rank6]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 591, in _update_causal_mask
[rank6]:     raise ValueError(
[rank6]: ValueError: You are attempting to perform batched generation with padding_side='right' this may lead to unexpected behaviour for Flash Attention version of Qwen2. Make sure to  call `tokenizer.padding_side  = 'left'` before tokenizing the input. 
[rank37]: Traceback (most recent call last):
[rank37]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 525, in <module>
[rank37]:     main()
[rank37]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 495, in main
[rank37]:     llm.api.finetune(
[rank37]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank37]:     return train(
[rank37]:            ^^^^^^
[rank37]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank37]:     trainer.fit(model, data)
[rank37]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank37]:     call._call_and_handle_interrupt(
[rank37]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank37]:     return trainer_fn(*args, **kwargs)
[rank37]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank37]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank37]:     self._run(model, ckpt_path=ckpt_path)
[rank37]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank37]:     results = self._run_stage()
[rank37]:               ^^^^^^^^^^^^^^^^^
[rank37]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank37]:     self.fit_loop.run()
[rank37]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank37]:     self.advance()
[rank37]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank37]:     self.epoch_loop.run(self._data_fetcher)
[rank37]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank37]:     self.advance(data_fetcher)
[rank37]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank37]:     super().advance(data_fetcher)
[rank37]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank37]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank37]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank37]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 183, in run
[rank37]:     closure()
[rank37]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank37]:     self._result = self.closure(*args, **kwargs)
[rank37]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank37]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank37]:     return func(*args, **kwargs)
[rank37]:            ^^^^^^^^^^^^^^^^^^^^^
[rank37]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank37]:     step_output = self._step_fn()
[rank37]:                   ^^^^^^^^^^^^^^^
[rank37]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank37]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank37]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank37]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank37]:     output = fn(*args, **kwargs)
[rank37]:              ^^^^^^^^^^^^^^^^^^^
[rank37]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank37]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank37]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank37]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank37]:     outputs = self.forward(batch)
[rank37]:               ^^^^^^^^^^^^^^^^^^^
[rank37]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank37]:     return self.model(**batch)
[rank37]:            ^^^^^^^^^^^^^^^^^^^
[rank37]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank37]:     return self._call_impl(*args, **kwargs)
[rank37]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank37]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank37]:     return inner()
[rank37]:            ^^^^^^^
[rank37]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank37]:     result = forward_call(*args, **kwargs)
[rank37]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank37]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank37]:     output = func(self, *args, **kwargs)
[rank37]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank37]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank37]:     return func(*args, **kwargs)
[rank37]:            ^^^^^^^^^^^^^^^^^^^^^
[rank37]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank37]:     outputs: BaseModelOutputWithPast = self.model(
[rank37]:                                        ^^^^^^^^^^^
[rank37]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank37]:     return self._call_impl(*args, **kwargs)
[rank37]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank37]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank37]:     return forward_call(*args, **kwargs)
[rank37]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank37]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank37]:     output = func(self, *args, **kwargs)
[rank37]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank37]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 519, in forward
[rank37]:     causal_mask = self._update_causal_mask(
[rank37]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank37]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 591, in _update_causal_mask
[rank37]:     raise ValueError(
[rank37]: ValueError: You are attempting to perform batched generation with padding_side='right' this may lead to unexpected behaviour for Flash Attention version of Qwen2. Make sure to  call `tokenizer.padding_side  = 'left'` before tokenizing the input. 
[rank36]: Traceback (most recent call last):
[rank36]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 525, in <module>
[rank36]:     main()
[rank36]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 495, in main
[rank36]:     llm.api.finetune(
[rank36]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank36]:     return train(
[rank36]:            ^^^^^^
[rank36]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank36]:     trainer.fit(model, data)
[rank36]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank36]:     call._call_and_handle_interrupt(
[rank36]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank36]:     return trainer_fn(*args, **kwargs)
[rank36]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank36]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank36]:     self._run(model, ckpt_path=ckpt_path)
[rank36]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank36]:     results = self._run_stage()
[rank36]:               ^^^^^^^^^^^^^^^^^
[rank36]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank36]:     self.fit_loop.run()
[rank36]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank36]:     self.advance()
[rank36]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank36]:     self.epoch_loop.run(self._data_fetcher)
[rank36]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank36]:     self.advance(data_fetcher)
[rank36]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank36]:     super().advance(data_fetcher)
[rank36]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank36]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank36]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank36]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 183, in run
[rank36]:     closure()
[rank36]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank36]:     self._result = self.closure(*args, **kwargs)
[rank36]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank36]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank36]:     return func(*args, **kwargs)
[rank36]:            ^^^^^^^^^^^^^^^^^^^^^
[rank36]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank36]:     step_output = self._step_fn()
[rank36]:                   ^^^^^^^^^^^^^^^
[rank36]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank36]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank36]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank36]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank36]:     output = fn(*args, **kwargs)
[rank36]:              ^^^^^^^^^^^^^^^^^^^
[rank36]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank36]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank36]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank36]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank36]:     outputs = self.forward(batch)
[rank36]:               ^^^^^^^^^^^^^^^^^^^
[rank36]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank36]:     return self.model(**batch)
[rank36]:            ^^^^^^^^^^^^^^^^^^^
[rank36]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank36]:     return self._call_impl(*args, **kwargs)
[rank36]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank36]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank36]:     return inner()
[rank36]:            ^^^^^^^
[rank36]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank36]:     result = forward_call(*args, **kwargs)
[rank36]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank36]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank36]:     output = func(self, *args, **kwargs)
[rank36]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank36]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank36]:     return func(*args, **kwargs)
[rank36]:            ^^^^^^^^^^^^^^^^^^^^^
[rank36]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank36]:     outputs: BaseModelOutputWithPast = self.model(
[rank36]:                                        ^^^^^^^^^^^
[rank36]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank36]:     return self._call_impl(*args, **kwargs)
[rank36]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank36]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank36]:     return forward_call(*args, **kwargs)
[rank36]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank36]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank36]:     output = func(self, *args, **kwargs)
[rank36]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank36]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 519, in forward
[rank36]:     causal_mask = self._update_causal_mask(
[rank36]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank36]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 591, in _update_causal_mask
[rank36]:     raise ValueError(
[rank36]: ValueError: You are attempting to perform batched generation with padding_side='right' this may lead to unexpected behaviour for Flash Attention version of Qwen2. Make sure to  call `tokenizer.padding_side  = 'left'` before tokenizing the input. 
[rank57]: Traceback (most recent call last):
[rank57]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 525, in <module>
[rank57]:     main()
[rank57]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 495, in main
[rank57]:     llm.api.finetune(
[rank57]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank57]:     return train(
[rank57]:            ^^^^^^
[rank57]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank57]:     trainer.fit(model, data)
[rank57]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank57]:     call._call_and_handle_interrupt(
[rank57]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank57]:     return trainer_fn(*args, **kwargs)
[rank57]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank57]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank57]:     self._run(model, ckpt_path=ckpt_path)
[rank57]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank57]:     results = self._run_stage()
[rank57]:               ^^^^^^^^^^^^^^^^^
[rank57]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank57]:     self.fit_loop.run()
[rank57]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank57]:     self.advance()
[rank57]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank57]:     self.epoch_loop.run(self._data_fetcher)
[rank57]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank57]:     self.advance(data_fetcher)
[rank57]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank57]:     super().advance(data_fetcher)
[rank57]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank57]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank57]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank57]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 183, in run
[rank57]:     closure()
[rank57]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank57]:     self._result = self.closure(*args, **kwargs)
[rank57]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank57]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank57]:     return func(*args, **kwargs)
[rank57]:            ^^^^^^^^^^^^^^^^^^^^^
[rank57]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank57]:     step_output = self._step_fn()
[rank57]:                   ^^^^^^^^^^^^^^^
[rank57]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank57]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank57]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank57]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank57]:     output = fn(*args, **kwargs)
[rank57]:              ^^^^^^^^^^^^^^^^^^^
[rank57]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank57]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank57]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank57]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank57]:     outputs = self.forward(batch)
[rank57]:               ^^^^^^^^^^^^^^^^^^^
[rank57]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank57]:     return self.model(**batch)
[rank57]:            ^^^^^^^^^^^^^^^^^^^
[rank57]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank57]:     return self._call_impl(*args, **kwargs)
[rank57]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank57]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank57]:     return inner()
[rank57]:            ^^^^^^^
[rank57]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank57]:     result = forward_call(*args, **kwargs)
[rank57]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank57]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank57]:     output = func(self, *args, **kwargs)
[rank57]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank57]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank57]:     return func(*args, **kwargs)
[rank57]:            ^^^^^^^^^^^^^^^^^^^^^
[rank57]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank57]:     outputs: BaseModelOutputWithPast = self.model(
[rank57]:                                        ^^^^^^^^^^^
[rank57]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank57]:     return self._call_impl(*args, **kwargs)
[rank57]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank57]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank57]:     return forward_call(*args, **kwargs)
[rank57]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank57]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank57]:     output = func(self, *args, **kwargs)
[rank57]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank57]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 519, in forward
[rank57]:     causal_mask = self._update_causal_mask(
[rank57]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank57]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 591, in _update_causal_mask
[rank57]:     raise ValueError(
[rank57]: ValueError: You are attempting to perform batched generation with padding_side='right' this may lead to unexpected behaviour for Flash Attention version of Qwen2. Make sure to  call `tokenizer.padding_side  = 'left'` before tokenizing the input. 
[rank59]: Traceback (most recent call last):
[rank59]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 525, in <module>
[rank59]:     main()
[rank59]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 495, in main
[rank59]:     llm.api.finetune(
[rank59]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank59]:     return train(
[rank59]:            ^^^^^^
[rank59]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank59]:     trainer.fit(model, data)
[rank59]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank59]:     call._call_and_handle_interrupt(
[rank59]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank59]:     return trainer_fn(*args, **kwargs)
[rank59]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank59]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank59]:     self._run(model, ckpt_path=ckpt_path)
[rank59]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank59]:     results = self._run_stage()
[rank59]:               ^^^^^^^^^^^^^^^^^
[rank59]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank59]:     self.fit_loop.run()
[rank59]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank59]:     self.advance()
[rank59]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank59]:     self.epoch_loop.run(self._data_fetcher)
[rank59]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank59]:     self.advance(data_fetcher)
[rank59]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank59]:     super().advance(data_fetcher)
[rank59]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank59]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank59]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank59]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 183, in run
[rank59]:     closure()
[rank59]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank59]:     self._result = self.closure(*args, **kwargs)
[rank59]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank59]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank59]:     return func(*args, **kwargs)
[rank59]:            ^^^^^^^^^^^^^^^^^^^^^
[rank59]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank59]:     step_output = self._step_fn()
[rank59]:                   ^^^^^^^^^^^^^^^
[rank59]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank59]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank59]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank59]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank59]:     output = fn(*args, **kwargs)
[rank59]:              ^^^^^^^^^^^^^^^^^^^
[rank59]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank59]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank59]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank59]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank59]:     outputs = self.forward(batch)
[rank59]:               ^^^^^^^^^^^^^^^^^^^
[rank59]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank59]:     return self.model(**batch)
[rank59]:            ^^^^^^^^^^^^^^^^^^^
[rank59]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank59]:     return self._call_impl(*args, **kwargs)
[rank59]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank59]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank59]:     return inner()
[rank59]:            ^^^^^^^
[rank59]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank59]:     result = forward_call(*args, **kwargs)
[rank59]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank59]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank59]:     output = func(self, *args, **kwargs)
[rank59]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank59]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank59]:     return func(*args, **kwargs)
[rank59]:            ^^^^^^^^^^^^^^^^^^^^^
[rank59]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank59]:     outputs: BaseModelOutputWithPast = self.model(
[rank59]:                                        ^^^^^^^^^^^
[rank59]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank59]:     return self._call_impl(*args, **kwargs)
[rank59]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank59]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank59]:     return forward_call(*args, **kwargs)
[rank59]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank59]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank59]:     output = func(self, *args, **kwargs)
[rank59]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank59]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 519, in forward
[rank59]:     causal_mask = self._update_causal_mask(
[rank59]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank59]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 591, in _update_causal_mask
[rank59]:     raise ValueError(
[rank59]: ValueError: You are attempting to perform batched generation with padding_side='right' this may lead to unexpected behaviour for Flash Attention version of Qwen2. Make sure to  call `tokenizer.padding_side  = 'left'` before tokenizing the input. 
[rank3]: Traceback (most recent call last):
[rank3]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 525, in <module>
[rank3]:     main()
[rank3]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 495, in main
[rank3]:     llm.api.finetune(
[rank3]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank3]:     return train(
[rank3]:            ^^^^^^
[rank3]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank3]:     trainer.fit(model, data)
[rank3]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank3]:     call._call_and_handle_interrupt(
[rank3]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank3]:     return trainer_fn(*args, **kwargs)
[rank3]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank3]:     self._run(model, ckpt_path=ckpt_path)
[rank3]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank3]:     results = self._run_stage()
[rank3]:               ^^^^^^^^^^^^^^^^^
[rank3]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank3]:     self.fit_loop.run()
[rank3]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank3]:     self.advance()
[rank3]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank3]:     self.epoch_loop.run(self._data_fetcher)
[rank3]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank3]:     self.advance(data_fetcher)
[rank3]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank3]:     super().advance(data_fetcher)
[rank3]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank3]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank3]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 183, in run
[rank3]:     closure()
[rank3]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank3]:     self._result = self.closure(*args, **kwargs)
[rank3]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank3]:     return func(*args, **kwargs)
[rank3]:            ^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank3]:     step_output = self._step_fn()
[rank3]:                   ^^^^^^^^^^^^^^^
[rank3]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank3]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank3]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank3]:     output = fn(*args, **kwargs)
[rank3]:              ^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank3]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank3]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank3]:     outputs = self.forward(batch)
[rank3]:               ^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank3]:     return self.model(**batch)
[rank3]:            ^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank3]:     return self._call_impl(*args, **kwargs)
[rank3]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank3]:     return inner()
[rank3]:            ^^^^^^^
[rank3]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank3]:     result = forward_call(*args, **kwargs)
[rank3]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank3]:     output = func(self, *args, **kwargs)
[rank3]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank3]:     return func(*args, **kwargs)
[rank3]:            ^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank3]:     outputs: BaseModelOutputWithPast = self.model(
[rank3]:                                        ^^^^^^^^^^^
[rank3]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank3]:     return self._call_impl(*args, **kwargs)
[rank3]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank3]:     return forward_call(*args, **kwargs)
[rank3]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]: Traceback (most recent call last):
[rank1]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 525, in <module>
[rank1]:     main()
[rank1]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 495, in main
[rank1]:     llm.api.finetune(
[rank1]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank1]:     return train(
[rank1]:            ^^^^^^
[rank1]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank1]:     trainer.fit(model, data)
[rank1]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank1]:     call._call_and_handle_interrupt(
[rank1]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank1]:     return trainer_fn(*args, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank1]:     self._run(model, ckpt_path=ckpt_path)
[rank1]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank1]:     results = self._run_stage()
[rank1]:               ^^^^^^^^^^^^^^^^^
[rank1]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank1]:     self.fit_loop.run()
[rank1]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank1]:     self.advance()
[rank1]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank1]:     self.epoch_loop.run(self._data_fetcher)
[rank1]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank1]:     self.advance(data_fetcher)
[rank1]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank1]:     super().advance(data_fetcher)
[rank1]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank1]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank1]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 183, in run
[rank1]:     closure()
[rank1]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank1]:     self._result = self.closure(*args, **kwargs)
[rank1]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank1]:     return func(*args, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank3]:     output = func(self, *args, **kwargs)
[rank3]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 519, in forward
[rank3]:     causal_mask = self._update_causal_mask(
[rank3]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 591, in _update_causal_mask
[rank3]:     raise ValueError(
[rank3]: ValueError: You are attempting to perform batched generation with padding_side='right' this may lead to unexpected behaviour for Flash Attention version of Qwen2. Make sure to  call `tokenizer.padding_side  = 'left'` before tokenizing the input. 
[rank1]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank1]:     step_output = self._step_fn()
[rank1]:                   ^^^^^^^^^^^^^^^
[rank1]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank1]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank1]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank1]:     output = fn(*args, **kwargs)
[rank1]:              ^^^^^^^^^^^^^^^^^^^
[rank54]: Traceback (most recent call last):
[rank54]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 525, in <module>
[rank54]:     main()
[rank54]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 495, in main
[rank54]:     llm.api.finetune(
[rank54]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank54]:     return train(
[rank54]:            ^^^^^^
[rank54]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank54]:     trainer.fit(model, data)
[rank54]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank54]:     call._call_and_handle_interrupt(
[rank1]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank1]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank1]:     outputs = self.forward(batch)
[rank1]:               ^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank1]:     return self.model(**batch)
[rank1]:            ^^^^^^^^^^^^^^^^^^^
[rank54]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank54]:     return trainer_fn(*args, **kwargs)
[rank54]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank54]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank54]:     self._run(model, ckpt_path=ckpt_path)
[rank54]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank54]:     results = self._run_stage()
[rank54]:               ^^^^^^^^^^^^^^^^^
[rank54]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank54]:     self.fit_loop.run()
[rank1]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank1]:     return inner()
[rank1]:            ^^^^^^^
[rank1]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank1]:     result = forward_call(*args, **kwargs)
[rank1]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank1]:     output = func(self, *args, **kwargs)
[rank54]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank54]:     self.advance()
[rank54]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank54]:     self.epoch_loop.run(self._data_fetcher)
[rank54]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank54]:     self.advance(data_fetcher)
[rank54]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank54]:     super().advance(data_fetcher)
[rank1]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank1]:     return func(*args, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank1]:     outputs: BaseModelOutputWithPast = self.model(
[rank1]:                                        ^^^^^^^^^^^
[rank1]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank54]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank54]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank54]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank54]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 183, in run
[rank54]:     closure()
[rank54]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank54]:     self._result = self.closure(*args, **kwargs)
[rank54]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank1]:     return forward_call(*args, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank54]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank54]:     return func(*args, **kwargs)
[rank54]:            ^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank1]:     output = func(self, *args, **kwargs)
[rank1]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 519, in forward
[rank1]:     causal_mask = self._update_causal_mask(
[rank1]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 591, in _update_causal_mask
[rank1]:     raise ValueError(
[rank54]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank54]:     step_output = self._step_fn()
[rank54]:                   ^^^^^^^^^^^^^^^
[rank54]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank54]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank54]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank54]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank54]:     output = fn(*args, **kwargs)
[rank54]:              ^^^^^^^^^^^^^^^^^^^
[rank1]: ValueError: You are attempting to perform batched generation with padding_side='right' this may lead to unexpected behaviour for Flash Attention version of Qwen2. Make sure to  call `tokenizer.padding_side  = 'left'` before tokenizing the input. 
[rank54]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank54]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank54]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank54]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank54]:     outputs = self.forward(batch)
[rank54]:               ^^^^^^^^^^^^^^^^^^^
[rank54]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank54]:     return self.model(**batch)
[rank54]:            ^^^^^^^^^^^^^^^^^^^
[rank58]: Traceback (most recent call last):
[rank58]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 525, in <module>
[rank58]:     main()
[rank58]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 495, in main
[rank58]:     llm.api.finetune(
[rank58]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank58]:     return train(
[rank58]:            ^^^^^^
[rank58]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank58]:     trainer.fit(model, data)
[rank58]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank58]:     call._call_and_handle_interrupt(
[rank54]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank54]:     return self._call_impl(*args, **kwargs)
[rank54]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank54]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank54]:     return inner()
[rank54]:            ^^^^^^^
[rank54]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank54]:     result = forward_call(*args, **kwargs)
[rank54]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank54]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank54]:     output = func(self, *args, **kwargs)
[rank58]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank58]:     return trainer_fn(*args, **kwargs)
[rank58]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank58]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank58]:     self._run(model, ckpt_path=ckpt_path)
[rank58]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank58]:     results = self._run_stage()
[rank58]:               ^^^^^^^^^^^^^^^^^
[rank58]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank58]:     self.fit_loop.run()
[rank54]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank54]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank54]:     return func(*args, **kwargs)
[rank54]:            ^^^^^^^^^^^^^^^^^^^^^
[rank54]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank54]:     outputs: BaseModelOutputWithPast = self.model(
[rank54]:                                        ^^^^^^^^^^^
[rank54]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank54]:     return self._call_impl(*args, **kwargs)
[rank54]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank58]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank58]:     self.advance()
[rank58]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank58]:     self.epoch_loop.run(self._data_fetcher)
[rank58]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank58]:     self.advance(data_fetcher)
[rank58]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank58]:     super().advance(data_fetcher)
[rank54]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank54]:     return forward_call(*args, **kwargs)
[rank54]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank58]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank58]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank58]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank58]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 183, in run
[rank58]:     closure()
[rank58]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank58]:     self._result = self.closure(*args, **kwargs)
[rank58]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank54]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank54]:     output = func(self, *args, **kwargs)
[rank54]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank54]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 519, in forward
[rank54]:     causal_mask = self._update_causal_mask(
[rank54]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank54]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 591, in _update_causal_mask
[rank54]:     raise ValueError(
[rank54]: ValueError: You are attempting to perform batched generation with padding_side='right' this may lead to unexpected behaviour for Flash Attention version of Qwen2. Make sure to  call `tokenizer.padding_side  = 'left'` before tokenizing the input. 
[rank58]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank58]:     return func(*args, **kwargs)
[rank58]:            ^^^^^^^^^^^^^^^^^^^^^
[rank58]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank58]:     step_output = self._step_fn()
[rank58]:                   ^^^^^^^^^^^^^^^
[rank58]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank58]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank58]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank58]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank58]:     output = fn(*args, **kwargs)
[rank58]:              ^^^^^^^^^^^^^^^^^^^
[rank58]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank58]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank58]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank58]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank58]:     outputs = self.forward(batch)
[rank58]:               ^^^^^^^^^^^^^^^^^^^
[rank58]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank58]:     return self.model(**batch)
[rank58]:            ^^^^^^^^^^^^^^^^^^^
[rank58]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank58]:     return self._call_impl(*args, **kwargs)
[rank58]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank58]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank58]:     return inner()
[rank58]:            ^^^^^^^
[rank58]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank58]:     result = forward_call(*args, **kwargs)
[rank58]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank58]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank58]:     output = func(self, *args, **kwargs)
[rank58]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank58]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank58]:     return func(*args, **kwargs)
[rank58]:            ^^^^^^^^^^^^^^^^^^^^^
[rank58]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank58]:     outputs: BaseModelOutputWithPast = self.model(
[rank58]:                                        ^^^^^^^^^^^
[rank58]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank58]:     return self._call_impl(*args, **kwargs)
[rank58]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank58]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank58]:     return forward_call(*args, **kwargs)
[rank58]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank58]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank58]:     output = func(self, *args, **kwargs)
[rank58]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank58]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 519, in forward
[rank58]:     causal_mask = self._update_causal_mask(
[rank58]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank58]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 591, in _update_causal_mask
[rank58]:     raise ValueError(
[rank58]: ValueError: You are attempting to perform batched generation with padding_side='right' this may lead to unexpected behaviour for Flash Attention version of Qwen2. Make sure to  call `tokenizer.padding_side  = 'left'` before tokenizing the input. 
[rank53]: Traceback (most recent call last):
[rank53]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 525, in <module>
[rank53]:     main()
[rank53]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 495, in main
[rank53]:     llm.api.finetune(
[rank53]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank53]:     return train(
[rank53]:            ^^^^^^
[rank53]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank53]:     trainer.fit(model, data)
[rank53]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank53]:     call._call_and_handle_interrupt(
[rank53]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank53]:     return trainer_fn(*args, **kwargs)
[rank53]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank53]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank53]:     self._run(model, ckpt_path=ckpt_path)
[rank53]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank53]:     results = self._run_stage()
[rank53]:               ^^^^^^^^^^^^^^^^^
[rank53]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank53]:     self.fit_loop.run()
[rank53]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank53]:     self.advance()
[rank53]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank53]:     self.epoch_loop.run(self._data_fetcher)
[rank53]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank53]:     self.advance(data_fetcher)
[rank53]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank53]:     super().advance(data_fetcher)
[rank53]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank53]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank53]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank53]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 183, in run
[rank53]:     closure()
[rank53]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank53]:     self._result = self.closure(*args, **kwargs)
[rank53]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank53]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank53]:     return func(*args, **kwargs)
[rank53]:            ^^^^^^^^^^^^^^^^^^^^^
[rank53]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank53]:     step_output = self._step_fn()
[rank53]:                   ^^^^^^^^^^^^^^^
[rank53]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank53]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank53]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank53]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank53]:     output = fn(*args, **kwargs)
[rank53]:              ^^^^^^^^^^^^^^^^^^^
[rank53]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank53]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank53]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank53]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank53]:     outputs = self.forward(batch)
[rank53]:               ^^^^^^^^^^^^^^^^^^^
[rank53]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank53]:     return self.model(**batch)
[rank53]:            ^^^^^^^^^^^^^^^^^^^
[rank53]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank53]:     return self._call_impl(*args, **kwargs)
[rank53]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank53]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank53]:     return inner()
[rank53]:            ^^^^^^^
[rank53]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank53]:     result = forward_call(*args, **kwargs)
[rank53]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank53]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank53]:     output = func(self, *args, **kwargs)
[rank53]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank53]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank53]:     return func(*args, **kwargs)
[rank53]:            ^^^^^^^^^^^^^^^^^^^^^
[rank53]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank53]:     outputs: BaseModelOutputWithPast = self.model(
[rank53]:                                        ^^^^^^^^^^^
[rank53]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank53]:     return self._call_impl(*args, **kwargs)
[rank53]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank53]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank53]:     return forward_call(*args, **kwargs)
[rank53]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank53]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank53]:     output = func(self, *args, **kwargs)
[rank53]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank53]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 519, in forward
[rank53]:     causal_mask = self._update_causal_mask(
[rank53]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank53]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 591, in _update_causal_mask
[rank53]:     raise ValueError(
[rank53]: ValueError: You are attempting to perform batched generation with padding_side='right' this may lead to unexpected behaviour for Flash Attention version of Qwen2. Make sure to  call `tokenizer.padding_side  = 'left'` before tokenizing the input. 
[rank56]: Traceback (most recent call last):
[rank56]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 525, in <module>
[rank56]:     main()
[rank56]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 495, in main
[rank56]:     llm.api.finetune(
[rank56]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank56]:     return train(
[rank56]:            ^^^^^^
[rank56]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank56]:     trainer.fit(model, data)
[rank56]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank56]:     call._call_and_handle_interrupt(
[rank56]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank56]:     return trainer_fn(*args, **kwargs)
[rank56]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank56]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank56]:     self._run(model, ckpt_path=ckpt_path)
[rank56]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank56]:     results = self._run_stage()
[rank56]:               ^^^^^^^^^^^^^^^^^
[rank56]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank56]:     self.fit_loop.run()
[rank56]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank56]:     self.advance()
[rank56]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank56]:     self.epoch_loop.run(self._data_fetcher)
[rank56]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank56]:     self.advance(data_fetcher)
[rank56]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank56]:     super().advance(data_fetcher)
[rank56]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank56]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank56]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank56]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 183, in run
[rank56]:     closure()
[rank56]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank56]:     self._result = self.closure(*args, **kwargs)
[rank56]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank56]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank56]:     return func(*args, **kwargs)
[rank56]:            ^^^^^^^^^^^^^^^^^^^^^
[rank56]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank56]:     step_output = self._step_fn()
[rank56]:                   ^^^^^^^^^^^^^^^
[rank56]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank56]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank56]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank56]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank56]:     output = fn(*args, **kwargs)
[rank56]:              ^^^^^^^^^^^^^^^^^^^
[rank56]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank56]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank56]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank56]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank56]:     outputs = self.forward(batch)
[rank56]:               ^^^^^^^^^^^^^^^^^^^
[rank56]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank56]:     return self.model(**batch)
[rank56]:            ^^^^^^^^^^^^^^^^^^^
[rank56]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank56]:     return self._call_impl(*args, **kwargs)
[rank56]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank56]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank56]:     return inner()
[rank56]:            ^^^^^^^
[rank56]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank56]:     result = forward_call(*args, **kwargs)
[rank56]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank56]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank56]:     output = func(self, *args, **kwargs)
[rank56]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank56]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank56]:     return func(*args, **kwargs)
[rank56]:            ^^^^^^^^^^^^^^^^^^^^^
[rank56]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank56]:     outputs: BaseModelOutputWithPast = self.model(
[rank56]:                                        ^^^^^^^^^^^
[rank56]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank56]:     return self._call_impl(*args, **kwargs)
[rank56]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank52]: Traceback (most recent call last):
[rank52]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 525, in <module>
[rank52]:     main()
[rank52]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 495, in main
[rank52]:     llm.api.finetune(
[rank52]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank52]:     return train(
[rank52]:            ^^^^^^
[rank52]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank52]:     trainer.fit(model, data)
[rank52]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank52]:     call._call_and_handle_interrupt(
[rank56]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank56]:     return forward_call(*args, **kwargs)
[rank56]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank52]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank52]:     return trainer_fn(*args, **kwargs)
[rank52]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank52]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank52]:     self._run(model, ckpt_path=ckpt_path)
[rank52]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank52]:     results = self._run_stage()
[rank52]:               ^^^^^^^^^^^^^^^^^
[rank52]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank52]:     self.fit_loop.run()
[rank56]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank56]:     output = func(self, *args, **kwargs)
[rank56]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank56]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 519, in forward
[rank56]:     causal_mask = self._update_causal_mask(
[rank56]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank56]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 591, in _update_causal_mask
[rank56]:     raise ValueError(
[rank56]: ValueError: You are attempting to perform batched generation with padding_side='right' this may lead to unexpected behaviour for Flash Attention version of Qwen2. Make sure to  call `tokenizer.padding_side  = 'left'` before tokenizing the input. 
[rank52]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank52]:     self.advance()
[rank52]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank52]:     self.epoch_loop.run(self._data_fetcher)
[rank52]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank52]:     self.advance(data_fetcher)
[rank52]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank52]:     super().advance(data_fetcher)
[rank52]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank52]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank52]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank52]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 183, in run
[rank52]:     closure()
[rank52]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank52]:     self._result = self.closure(*args, **kwargs)
[rank52]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank52]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank52]:     return func(*args, **kwargs)
[rank52]:            ^^^^^^^^^^^^^^^^^^^^^
[rank52]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank52]:     step_output = self._step_fn()
[rank52]:                   ^^^^^^^^^^^^^^^
[rank52]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank52]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank52]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank52]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank52]:     output = fn(*args, **kwargs)
[rank52]:              ^^^^^^^^^^^^^^^^^^^
[rank52]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank52]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank52]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank52]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank52]:     outputs = self.forward(batch)
[rank52]:               ^^^^^^^^^^^^^^^^^^^
[rank52]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank52]:     return self.model(**batch)
[rank52]:            ^^^^^^^^^^^^^^^^^^^
[rank52]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank52]:     return self._call_impl(*args, **kwargs)
[rank52]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank52]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank52]:     return inner()
[rank52]:            ^^^^^^^
[rank52]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank52]:     result = forward_call(*args, **kwargs)
[rank52]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank52]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank52]:     output = func(self, *args, **kwargs)
[rank52]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank52]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank52]:     return func(*args, **kwargs)
[rank52]:            ^^^^^^^^^^^^^^^^^^^^^
[rank52]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank52]:     outputs: BaseModelOutputWithPast = self.model(
[rank52]:                                        ^^^^^^^^^^^
[rank52]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank52]:     return self._call_impl(*args, **kwargs)
[rank52]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]: Traceback (most recent call last):
[rank2]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 525, in <module>
[rank2]:     main()
[rank2]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 495, in main
[rank2]:     llm.api.finetune(
[rank2]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank2]:     return train(
[rank2]:            ^^^^^^
[rank2]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank2]:     trainer.fit(model, data)
[rank2]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank2]:     call._call_and_handle_interrupt(
[rank52]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank52]:     return forward_call(*args, **kwargs)
[rank52]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank2]:     return trainer_fn(*args, **kwargs)
[rank2]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank2]:     self._run(model, ckpt_path=ckpt_path)
[rank2]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank2]:     results = self._run_stage()
[rank2]:               ^^^^^^^^^^^^^^^^^
[rank2]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank2]:     self.fit_loop.run()
[rank52]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank52]:     output = func(self, *args, **kwargs)
[rank52]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank52]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 519, in forward
[rank52]:     causal_mask = self._update_causal_mask(
[rank52]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank52]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 591, in _update_causal_mask
[rank52]:     raise ValueError(
[rank2]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank2]:     self.advance()
[rank2]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank2]:     self.epoch_loop.run(self._data_fetcher)
[rank2]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank2]:     self.advance(data_fetcher)
[rank2]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank2]:     super().advance(data_fetcher)
[rank52]: ValueError: You are attempting to perform batched generation with padding_side='right' this may lead to unexpected behaviour for Flash Attention version of Qwen2. Make sure to  call `tokenizer.padding_side  = 'left'` before tokenizing the input. 
[rank2]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank2]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank2]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 183, in run
[rank2]:     closure()
[rank2]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank2]:     self._result = self.closure(*args, **kwargs)
[rank2]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank2]:     return func(*args, **kwargs)
[rank2]:            ^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank2]:     step_output = self._step_fn()
[rank2]:                   ^^^^^^^^^^^^^^^
[rank2]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank2]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank2]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank2]:     output = fn(*args, **kwargs)
[rank2]:              ^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank2]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank2]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank2]:     outputs = self.forward(batch)
[rank2]:               ^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank2]:     return self.model(**batch)
[rank2]:            ^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank2]:     return self._call_impl(*args, **kwargs)
[rank2]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank2]:     return inner()
[rank2]:            ^^^^^^^
[rank2]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank2]:     result = forward_call(*args, **kwargs)
[rank2]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank2]:     output = func(self, *args, **kwargs)
[rank2]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank2]:     return func(*args, **kwargs)
[rank2]:            ^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank2]:     outputs: BaseModelOutputWithPast = self.model(
[rank2]:                                        ^^^^^^^^^^^
[rank2]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank2]:     return self._call_impl(*args, **kwargs)
[rank2]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank2]:     return forward_call(*args, **kwargs)
[rank2]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank2]:     output = func(self, *args, **kwargs)
[rank2]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 519, in forward
[rank2]:     causal_mask = self._update_causal_mask(
[rank2]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 591, in _update_causal_mask
[rank2]:     raise ValueError(
[rank2]: ValueError: You are attempting to perform batched generation with padding_side='right' this may lead to unexpected behaviour for Flash Attention version of Qwen2. Make sure to  call `tokenizer.padding_side  = 'left'` before tokenizing the input. 
[rank16]: Traceback (most recent call last):
[rank16]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 525, in <module>
[rank16]:     main()
[rank16]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 495, in main
[rank16]:     llm.api.finetune(
[rank16]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank16]:     return train(
[rank16]:            ^^^^^^
[rank16]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank16]:     trainer.fit(model, data)
[rank16]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank16]:     call._call_and_handle_interrupt(
[rank16]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank16]:     return trainer_fn(*args, **kwargs)
[rank16]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank16]:     self._run(model, ckpt_path=ckpt_path)
[rank16]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank16]:     results = self._run_stage()
[rank16]:               ^^^^^^^^^^^^^^^^^
[rank16]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank16]:     self.fit_loop.run()
[rank16]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank16]:     self.advance()
[rank16]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank16]:     self.epoch_loop.run(self._data_fetcher)
[rank16]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank16]:     self.advance(data_fetcher)
[rank16]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank16]:     super().advance(data_fetcher)
[rank16]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank16]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank16]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 183, in run
[rank16]:     closure()
[rank16]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank16]:     self._result = self.closure(*args, **kwargs)
[rank16]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank16]:     return func(*args, **kwargs)
[rank16]:            ^^^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank16]:     step_output = self._step_fn()
[rank16]:                   ^^^^^^^^^^^^^^^
[rank16]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank16]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank16]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank16]:     output = fn(*args, **kwargs)
[rank16]:              ^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank16]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank16]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank16]:     outputs = self.forward(batch)
[rank16]:               ^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank16]:     return self.model(**batch)
[rank16]:            ^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank16]:     return self._call_impl(*args, **kwargs)
[rank16]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank16]:     return inner()
[rank16]:            ^^^^^^^
[rank16]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank16]:     result = forward_call(*args, **kwargs)
[rank16]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank16]:     output = func(self, *args, **kwargs)
[rank16]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank16]:     return func(*args, **kwargs)
[rank16]:            ^^^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank16]:     outputs: BaseModelOutputWithPast = self.model(
[rank16]:                                        ^^^^^^^^^^^
[rank16]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank16]:     return self._call_impl(*args, **kwargs)
[rank16]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank16]:     return forward_call(*args, **kwargs)
[rank16]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank16]:     output = func(self, *args, **kwargs)
[rank16]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 519, in forward
[rank16]:     causal_mask = self._update_causal_mask(
[rank16]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 591, in _update_causal_mask
[rank16]:     raise ValueError(
[rank16]: ValueError: You are attempting to perform batched generation with padding_side='right' this may lead to unexpected behaviour for Flash Attention version of Qwen2. Make sure to  call `tokenizer.padding_side  = 'left'` before tokenizing the input. 
[rank18]: Traceback (most recent call last):
[rank18]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 525, in <module>
[rank18]:     main()
[rank18]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 495, in main
[rank18]:     llm.api.finetune(
[rank18]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank18]:     return train(
[rank18]:            ^^^^^^
[rank18]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank18]:     trainer.fit(model, data)
[rank18]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank18]:     call._call_and_handle_interrupt(
[rank18]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank18]:     return trainer_fn(*args, **kwargs)
[rank18]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank18]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank18]:     self._run(model, ckpt_path=ckpt_path)
[rank18]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank18]:     results = self._run_stage()
[rank18]:               ^^^^^^^^^^^^^^^^^
[rank18]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank18]:     self.fit_loop.run()
[rank18]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank18]:     self.advance()
[rank18]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank18]:     self.epoch_loop.run(self._data_fetcher)
[rank18]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank18]:     self.advance(data_fetcher)
[rank18]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank18]:     super().advance(data_fetcher)
[rank18]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank18]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank18]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank18]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 183, in run
[rank18]:     closure()
[rank18]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank18]:     self._result = self.closure(*args, **kwargs)
[rank18]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank18]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank18]:     return func(*args, **kwargs)
[rank18]:            ^^^^^^^^^^^^^^^^^^^^^
[rank18]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank18]:     step_output = self._step_fn()
[rank18]:                   ^^^^^^^^^^^^^^^
[rank18]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank18]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank18]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank18]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank18]:     output = fn(*args, **kwargs)
[rank18]:              ^^^^^^^^^^^^^^^^^^^
[rank18]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank18]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank18]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank18]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank18]:     outputs = self.forward(batch)
[rank18]:               ^^^^^^^^^^^^^^^^^^^
[rank18]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank18]:     return self.model(**batch)
[rank18]:            ^^^^^^^^^^^^^^^^^^^
[rank18]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank18]:     return self._call_impl(*args, **kwargs)
[rank18]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank18]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank18]:     return inner()
[rank18]:            ^^^^^^^
[rank18]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank18]:     result = forward_call(*args, **kwargs)
[rank18]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank18]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank18]:     output = func(self, *args, **kwargs)
[rank18]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank18]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank18]:     return func(*args, **kwargs)
[rank18]:            ^^^^^^^^^^^^^^^^^^^^^
[rank18]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank18]:     outputs: BaseModelOutputWithPast = self.model(
[rank18]:                                        ^^^^^^^^^^^
[rank18]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank18]:     return self._call_impl(*args, **kwargs)
[rank18]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank18]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank18]:     return forward_call(*args, **kwargs)
[rank18]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank18]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank18]:     output = func(self, *args, **kwargs)
[rank18]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank18]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 519, in forward
[rank18]:     causal_mask = self._update_causal_mask(
[rank18]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank18]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 591, in _update_causal_mask
[rank18]:     raise ValueError(
[rank18]: ValueError: You are attempting to perform batched generation with padding_side='right' this may lead to unexpected behaviour for Flash Attention version of Qwen2. Make sure to  call `tokenizer.padding_side  = 'left'` before tokenizing the input. 
[rank8]: Traceback (most recent call last):
[rank8]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 525, in <module>
[rank8]:     main()
[rank8]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 495, in main
[rank8]:     llm.api.finetune(
[rank8]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank8]:     return train(
[rank8]:            ^^^^^^
[rank8]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank8]:     trainer.fit(model, data)
[rank8]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank8]:     call._call_and_handle_interrupt(
[rank8]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank8]:     return trainer_fn(*args, **kwargs)
[rank8]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank8]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank8]:     self._run(model, ckpt_path=ckpt_path)
[rank8]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank8]:     results = self._run_stage()
[rank8]:               ^^^^^^^^^^^^^^^^^
[rank8]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank8]:     self.fit_loop.run()
[rank8]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank8]:     self.advance()
[rank8]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank8]:     self.epoch_loop.run(self._data_fetcher)
[rank8]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank8]:     self.advance(data_fetcher)
[rank8]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank8]:     super().advance(data_fetcher)
[rank8]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank8]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank8]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank8]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 183, in run
[rank8]:     closure()
[rank8]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank8]:     self._result = self.closure(*args, **kwargs)
[rank8]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank8]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank8]:     return func(*args, **kwargs)
[rank8]:            ^^^^^^^^^^^^^^^^^^^^^
[rank8]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank8]:     step_output = self._step_fn()
[rank8]:                   ^^^^^^^^^^^^^^^
[rank8]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank8]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank8]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank8]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank8]:     output = fn(*args, **kwargs)
[rank8]:              ^^^^^^^^^^^^^^^^^^^
[rank8]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank8]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank8]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank8]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank8]:     outputs = self.forward(batch)
[rank8]:               ^^^^^^^^^^^^^^^^^^^
[rank8]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank8]:     return self.model(**batch)
[rank8]:            ^^^^^^^^^^^^^^^^^^^
[rank8]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank8]:     return self._call_impl(*args, **kwargs)
[rank8]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank8]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank8]:     return inner()
[rank8]:            ^^^^^^^
[rank8]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank8]:     result = forward_call(*args, **kwargs)
[rank8]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank8]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank8]:     output = func(self, *args, **kwargs)
[rank8]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank8]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank8]:     return func(*args, **kwargs)
[rank8]:            ^^^^^^^^^^^^^^^^^^^^^
[rank8]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank8]:     outputs: BaseModelOutputWithPast = self.model(
[rank8]:                                        ^^^^^^^^^^^
[rank8]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank8]:     return self._call_impl(*args, **kwargs)
[rank8]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank8]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank8]:     return forward_call(*args, **kwargs)
[rank8]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank8]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank8]:     output = func(self, *args, **kwargs)
[rank8]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank8]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 519, in forward
[rank8]:     causal_mask = self._update_causal_mask(
[rank8]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank8]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 591, in _update_causal_mask
[rank8]:     raise ValueError(
[rank8]: ValueError: You are attempting to perform batched generation with padding_side='right' this may lead to unexpected behaviour for Flash Attention version of Qwen2. Make sure to  call `tokenizer.padding_side  = 'left'` before tokenizing the input. 
[rank55]: Traceback (most recent call last):
[rank55]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 525, in <module>
[rank55]:     main()
[rank55]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 495, in main
[rank55]:     llm.api.finetune(
[rank55]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank55]:     return train(
[rank55]:            ^^^^^^
[rank55]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank55]:     trainer.fit(model, data)
[rank55]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank55]:     call._call_and_handle_interrupt(
[rank11]: Traceback (most recent call last):
[rank11]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 525, in <module>
[rank11]:     main()
[rank11]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 495, in main
[rank11]:     llm.api.finetune(
[rank11]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank11]:     return train(
[rank11]:            ^^^^^^
[rank11]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank11]:     trainer.fit(model, data)
[rank11]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank11]:     call._call_and_handle_interrupt(
[rank55]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank55]:     return trainer_fn(*args, **kwargs)
[rank55]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank55]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank55]:     self._run(model, ckpt_path=ckpt_path)
[rank55]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank55]:     results = self._run_stage()
[rank55]:               ^^^^^^^^^^^^^^^^^
[rank55]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank55]:     self.fit_loop.run()
[rank11]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank11]:     return trainer_fn(*args, **kwargs)
[rank11]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank11]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank11]:     self._run(model, ckpt_path=ckpt_path)
[rank11]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank11]:     results = self._run_stage()
[rank11]:               ^^^^^^^^^^^^^^^^^
[rank11]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank11]:     self.fit_loop.run()
[rank55]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank55]:     self.advance()
[rank55]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank55]:     self.epoch_loop.run(self._data_fetcher)
[rank55]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank55]:     self.advance(data_fetcher)
[rank55]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank55]:     super().advance(data_fetcher)
[rank11]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank11]:     self.advance()
[rank11]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank11]:     self.epoch_loop.run(self._data_fetcher)
[rank11]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank11]:     self.advance(data_fetcher)
[rank11]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank11]:     super().advance(data_fetcher)
[rank55]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank55]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank55]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank55]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 183, in run
[rank55]:     closure()
[rank55]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank55]:     self._result = self.closure(*args, **kwargs)
[rank55]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank11]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank11]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank11]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank11]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 183, in run
[rank11]:     closure()
[rank11]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank11]:     self._result = self.closure(*args, **kwargs)
[rank11]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank55]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank55]:     return func(*args, **kwargs)
[rank55]:            ^^^^^^^^^^^^^^^^^^^^^
[rank11]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank11]:     return func(*args, **kwargs)
[rank11]:            ^^^^^^^^^^^^^^^^^^^^^
[rank55]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank55]:     step_output = self._step_fn()
[rank55]:                   ^^^^^^^^^^^^^^^
[rank55]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank55]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank55]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank55]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank55]:     output = fn(*args, **kwargs)
[rank55]:              ^^^^^^^^^^^^^^^^^^^
[rank11]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank11]:     step_output = self._step_fn()
[rank11]:                   ^^^^^^^^^^^^^^^
[rank11]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank11]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank11]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank11]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank11]:     output = fn(*args, **kwargs)
[rank11]:              ^^^^^^^^^^^^^^^^^^^
[rank55]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank55]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank55]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank55]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank55]:     outputs = self.forward(batch)
[rank55]:               ^^^^^^^^^^^^^^^^^^^
[rank55]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank55]:     return self.model(**batch)
[rank55]:            ^^^^^^^^^^^^^^^^^^^
[rank11]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank11]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank11]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank11]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank11]:     outputs = self.forward(batch)
[rank11]:               ^^^^^^^^^^^^^^^^^^^
[rank11]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank11]:     return self.model(**batch)
[rank11]:            ^^^^^^^^^^^^^^^^^^^
[rank55]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank55]:     return self._call_impl(*args, **kwargs)
[rank55]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank55]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank55]:     return inner()
[rank55]:            ^^^^^^^
[rank55]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank55]:     result = forward_call(*args, **kwargs)
[rank55]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank55]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank55]:     output = func(self, *args, **kwargs)
[rank11]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank11]:     return self._call_impl(*args, **kwargs)
[rank11]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank11]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank11]:     return inner()
[rank11]:            ^^^^^^^
[rank11]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank11]:     result = forward_call(*args, **kwargs)
[rank11]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank11]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank11]:     output = func(self, *args, **kwargs)
[rank55]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank55]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank55]:     return func(*args, **kwargs)
[rank55]:            ^^^^^^^^^^^^^^^^^^^^^
[rank55]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank55]:     outputs: BaseModelOutputWithPast = self.model(
[rank55]:                                        ^^^^^^^^^^^
[rank55]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank55]:     return self._call_impl(*args, **kwargs)
[rank55]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank11]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank11]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank11]:     return func(*args, **kwargs)
[rank11]:            ^^^^^^^^^^^^^^^^^^^^^
[rank11]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank11]:     outputs: BaseModelOutputWithPast = self.model(
[rank11]:                                        ^^^^^^^^^^^
[rank11]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank11]:     return self._call_impl(*args, **kwargs)
[rank11]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank55]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank55]:     return forward_call(*args, **kwargs)
[rank55]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank11]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank11]:     return forward_call(*args, **kwargs)
[rank11]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank55]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank55]:     output = func(self, *args, **kwargs)
[rank55]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank55]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 519, in forward
[rank55]:     causal_mask = self._update_causal_mask(
[rank55]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank55]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 591, in _update_causal_mask
[rank55]:     raise ValueError(
[rank11]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank11]:     output = func(self, *args, **kwargs)
[rank11]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank11]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 519, in forward
[rank11]:     causal_mask = self._update_causal_mask(
[rank11]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank11]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 591, in _update_causal_mask
[rank11]:     raise ValueError(
[rank55]: ValueError: You are attempting to perform batched generation with padding_side='right' this may lead to unexpected behaviour for Flash Attention version of Qwen2. Make sure to  call `tokenizer.padding_side  = 'left'` before tokenizing the input. 
[rank11]: ValueError: You are attempting to perform batched generation with padding_side='right' this may lead to unexpected behaviour for Flash Attention version of Qwen2. Make sure to  call `tokenizer.padding_side  = 'left'` before tokenizing the input. 
[rank27]: Traceback (most recent call last):
[rank27]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 525, in <module>
[rank27]:     main()
[rank27]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 495, in main
[rank27]:     llm.api.finetune(
[rank27]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank27]:     return train(
[rank27]:            ^^^^^^
[rank27]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank27]:     trainer.fit(model, data)
[rank27]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank27]:     call._call_and_handle_interrupt(
[rank27]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank27]:     return trainer_fn(*args, **kwargs)
[rank27]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank27]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank27]:     self._run(model, ckpt_path=ckpt_path)
[rank27]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank27]:     results = self._run_stage()
[rank27]:               ^^^^^^^^^^^^^^^^^
[rank27]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank27]:     self.fit_loop.run()
[rank9]: Traceback (most recent call last):
[rank9]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 525, in <module>
[rank9]:     main()
[rank9]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 495, in main
[rank9]:     llm.api.finetune(
[rank9]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank9]:     return train(
[rank9]:            ^^^^^^
[rank9]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank9]:     trainer.fit(model, data)
[rank9]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank9]:     call._call_and_handle_interrupt(
[rank27]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank27]:     self.advance()
[rank27]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank27]:     self.epoch_loop.run(self._data_fetcher)
[rank27]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank27]:     self.advance(data_fetcher)
[rank27]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank27]:     super().advance(data_fetcher)
[rank27]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank27]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank27]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank27]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 183, in run
[rank27]:     closure()
[rank27]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank27]:     self._result = self.closure(*args, **kwargs)
[rank27]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank27]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank27]:     return func(*args, **kwargs)
[rank27]:            ^^^^^^^^^^^^^^^^^^^^^
[rank27]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank27]:     step_output = self._step_fn()
[rank27]:                   ^^^^^^^^^^^^^^^
[rank27]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank27]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank27]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank27]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank27]:     output = fn(*args, **kwargs)
[rank27]:              ^^^^^^^^^^^^^^^^^^^
[rank9]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank9]:     return trainer_fn(*args, **kwargs)
[rank9]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank9]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank9]:     self._run(model, ckpt_path=ckpt_path)
[rank9]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank9]:     results = self._run_stage()
[rank9]:               ^^^^^^^^^^^^^^^^^
[rank9]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank9]:     self.fit_loop.run()
[rank27]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank27]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank27]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank27]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank27]:     outputs = self.forward(batch)
[rank27]:               ^^^^^^^^^^^^^^^^^^^
[rank27]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank27]:     return self.model(**batch)
[rank27]:            ^^^^^^^^^^^^^^^^^^^
[rank9]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank9]:     self.advance()
[rank9]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank9]:     self.epoch_loop.run(self._data_fetcher)
[rank9]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank9]:     self.advance(data_fetcher)
[rank9]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank9]:     super().advance(data_fetcher)
[rank27]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank27]:     return self._call_impl(*args, **kwargs)
[rank27]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank27]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank27]:     return inner()
[rank27]:            ^^^^^^^
[rank27]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank27]:     result = forward_call(*args, **kwargs)
[rank27]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank27]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank27]:     output = func(self, *args, **kwargs)
[rank9]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank9]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank9]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank9]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 183, in run
[rank9]:     closure()
[rank9]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank9]:     self._result = self.closure(*args, **kwargs)
[rank9]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank27]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank27]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank27]:     return func(*args, **kwargs)
[rank27]:            ^^^^^^^^^^^^^^^^^^^^^
[rank27]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank27]:     outputs: BaseModelOutputWithPast = self.model(
[rank27]:                                        ^^^^^^^^^^^
[rank27]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank27]:     return self._call_impl(*args, **kwargs)
[rank27]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank9]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank9]:     return func(*args, **kwargs)
[rank9]:            ^^^^^^^^^^^^^^^^^^^^^
[rank27]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank27]:     return forward_call(*args, **kwargs)
[rank27]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank9]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank9]:     step_output = self._step_fn()
[rank9]:                   ^^^^^^^^^^^^^^^
[rank9]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank9]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank9]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank9]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank9]:     output = fn(*args, **kwargs)
[rank9]:              ^^^^^^^^^^^^^^^^^^^
[rank27]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank27]:     output = func(self, *args, **kwargs)
[rank27]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank27]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 519, in forward
[rank27]:     causal_mask = self._update_causal_mask(
[rank27]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank27]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 591, in _update_causal_mask
[rank27]:     raise ValueError(
[rank9]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank9]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank9]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank9]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank9]:     outputs = self.forward(batch)
[rank9]:               ^^^^^^^^^^^^^^^^^^^
[rank9]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank9]:     return self.model(**batch)
[rank9]:            ^^^^^^^^^^^^^^^^^^^
[rank27]: ValueError: You are attempting to perform batched generation with padding_side='right' this may lead to unexpected behaviour for Flash Attention version of Qwen2. Make sure to  call `tokenizer.padding_side  = 'left'` before tokenizing the input. 
[rank9]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank9]:     return self._call_impl(*args, **kwargs)
[rank9]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank9]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank9]:     return inner()
[rank9]:            ^^^^^^^
[rank9]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank9]:     result = forward_call(*args, **kwargs)
[rank9]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank9]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank9]:     output = func(self, *args, **kwargs)
[rank26]: Traceback (most recent call last):
[rank26]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 525, in <module>
[rank26]:     main()
[rank26]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 495, in main
[rank26]:     llm.api.finetune(
[rank26]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank26]:     return train(
[rank26]:            ^^^^^^
[rank26]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank26]:     trainer.fit(model, data)
[rank26]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank26]:     call._call_and_handle_interrupt(
[rank9]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank9]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank9]:     return func(*args, **kwargs)
[rank9]:            ^^^^^^^^^^^^^^^^^^^^^
[rank9]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank9]:     outputs: BaseModelOutputWithPast = self.model(
[rank9]:                                        ^^^^^^^^^^^
[rank9]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank9]:     return self._call_impl(*args, **kwargs)
[rank9]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank26]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank26]:     return trainer_fn(*args, **kwargs)
[rank26]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank26]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank26]:     self._run(model, ckpt_path=ckpt_path)
[rank26]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank26]:     results = self._run_stage()
[rank26]:               ^^^^^^^^^^^^^^^^^
[rank26]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank26]:     self.fit_loop.run()
[rank9]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank9]:     return forward_call(*args, **kwargs)
[rank9]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank26]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank26]:     self.advance()
[rank26]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank26]:     self.epoch_loop.run(self._data_fetcher)
[rank26]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank26]:     self.advance(data_fetcher)
[rank26]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank26]:     super().advance(data_fetcher)
[rank9]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank9]:     output = func(self, *args, **kwargs)
[rank9]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank9]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 519, in forward
[rank9]:     causal_mask = self._update_causal_mask(
[rank9]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank9]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 591, in _update_causal_mask
[rank9]:     raise ValueError(
[rank26]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank26]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank26]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank26]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 183, in run
[rank26]:     closure()
[rank26]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank26]:     self._result = self.closure(*args, **kwargs)
[rank26]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank9]: ValueError: You are attempting to perform batched generation with padding_side='right' this may lead to unexpected behaviour for Flash Attention version of Qwen2. Make sure to  call `tokenizer.padding_side  = 'left'` before tokenizing the input. 
[rank26]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank26]:     return func(*args, **kwargs)
[rank26]:            ^^^^^^^^^^^^^^^^^^^^^
[rank26]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank26]:     step_output = self._step_fn()
[rank26]:                   ^^^^^^^^^^^^^^^
[rank26]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank26]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank26]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank26]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank26]:     output = fn(*args, **kwargs)
[rank26]:              ^^^^^^^^^^^^^^^^^^^
[rank26]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank26]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank26]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank26]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank26]:     outputs = self.forward(batch)
[rank26]:               ^^^^^^^^^^^^^^^^^^^
[rank26]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank26]:     return self.model(**batch)
[rank26]:            ^^^^^^^^^^^^^^^^^^^
[rank26]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank26]:     return self._call_impl(*args, **kwargs)
[rank26]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank26]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank26]:     return inner()
[rank26]:            ^^^^^^^
[rank26]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank26]:     result = forward_call(*args, **kwargs)
[rank26]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank26]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank26]:     output = func(self, *args, **kwargs)
[rank26]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank26]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank26]:     return func(*args, **kwargs)
[rank26]:            ^^^^^^^^^^^^^^^^^^^^^
[rank26]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank26]:     outputs: BaseModelOutputWithPast = self.model(
[rank26]:                                        ^^^^^^^^^^^
[rank26]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank26]:     return self._call_impl(*args, **kwargs)
[rank26]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank26]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank26]:     return forward_call(*args, **kwargs)
[rank26]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank26]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank26]:     output = func(self, *args, **kwargs)
[rank26]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank26]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 519, in forward
[rank26]:     causal_mask = self._update_causal_mask(
[rank26]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank26]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 591, in _update_causal_mask
[rank26]:     raise ValueError(
[rank26]: ValueError: You are attempting to perform batched generation with padding_side='right' this may lead to unexpected behaviour for Flash Attention version of Qwen2. Make sure to  call `tokenizer.padding_side  = 'left'` before tokenizing the input. 
[rank10]: Traceback (most recent call last):
[rank10]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 525, in <module>
[rank10]:     main()
[rank10]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 495, in main
[rank10]:     llm.api.finetune(
[rank10]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank10]:     return train(
[rank10]:            ^^^^^^
[rank10]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank10]:     trainer.fit(model, data)
[rank10]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank10]:     call._call_and_handle_interrupt(
[rank10]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank10]:     return trainer_fn(*args, **kwargs)
[rank10]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank10]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank10]:     self._run(model, ckpt_path=ckpt_path)
[rank10]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank10]:     results = self._run_stage()
[rank10]:               ^^^^^^^^^^^^^^^^^
[rank10]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank10]:     self.fit_loop.run()
[rank10]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank10]:     self.advance()
[rank10]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank10]:     self.epoch_loop.run(self._data_fetcher)
[rank10]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank10]:     self.advance(data_fetcher)
[rank10]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank10]:     super().advance(data_fetcher)
[rank10]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank10]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank10]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank10]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 183, in run
[rank10]:     closure()
[rank10]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank10]:     self._result = self.closure(*args, **kwargs)
[rank10]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank10]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank10]:     return func(*args, **kwargs)
[rank10]:            ^^^^^^^^^^^^^^^^^^^^^
[rank0]: Traceback (most recent call last):
[rank0]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 525, in <module>
[rank0]:     main()
[rank0]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 495, in main
[rank0]:     llm.api.finetune(
[rank0]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank0]:     return train(
[rank0]:            ^^^^^^
[rank0]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank0]:     trainer.fit(model, data)
[rank0]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank0]:     call._call_and_handle_interrupt(
[rank10]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank10]:     step_output = self._step_fn()
[rank10]:                   ^^^^^^^^^^^^^^^
[rank10]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank10]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank10]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank10]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank10]:     output = fn(*args, **kwargs)
[rank10]:              ^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank0]:     return trainer_fn(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank0]:     self._run(model, ckpt_path=ckpt_path)
[rank0]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank0]:     results = self._run_stage()
[rank0]:               ^^^^^^^^^^^^^^^^^
[rank0]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank0]:     self.fit_loop.run()
[rank10]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank10]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank10]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank10]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank10]:     outputs = self.forward(batch)
[rank10]:               ^^^^^^^^^^^^^^^^^^^
[rank10]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank10]:     return self.model(**batch)
[rank10]:            ^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank0]:     self.advance()
[rank0]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank0]:     self.epoch_loop.run(self._data_fetcher)
[rank0]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank0]:     self.advance(data_fetcher)
[rank0]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank0]:     super().advance(data_fetcher)
[rank0]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank0]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank0]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 183, in run
[rank0]:     closure()
[rank0]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank0]:     self._result = self.closure(*args, **kwargs)
[rank0]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank0]:     return func(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^
[rank10]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank10]:     return self._call_impl(*args, **kwargs)
[rank10]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank10]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank10]:     return inner()
[rank10]:            ^^^^^^^
[rank10]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank10]:     result = forward_call(*args, **kwargs)
[rank10]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank10]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank10]:     output = func(self, *args, **kwargs)
[rank0]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank0]:     step_output = self._step_fn()
[rank0]:                   ^^^^^^^^^^^^^^^
[rank0]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank0]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank0]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank0]:     output = fn(*args, **kwargs)
[rank0]:              ^^^^^^^^^^^^^^^^^^^
[rank10]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank10]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank10]:     return func(*args, **kwargs)
[rank10]:            ^^^^^^^^^^^^^^^^^^^^^
[rank10]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank10]:     outputs: BaseModelOutputWithPast = self.model(
[rank10]:                                        ^^^^^^^^^^^
[rank10]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank10]:     return self._call_impl(*args, **kwargs)
[rank10]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank0]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank0]:     outputs = self.forward(batch)
[rank0]:               ^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank0]:     return self.model(**batch)
[rank0]:            ^^^^^^^^^^^^^^^^^^^
[rank10]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank10]:     return forward_call(*args, **kwargs)
[rank10]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank0]:     return inner()
[rank0]:            ^^^^^^^
[rank0]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank0]:     result = forward_call(*args, **kwargs)
[rank0]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank0]:     output = func(self, *args, **kwargs)
[rank10]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank10]:     output = func(self, *args, **kwargs)
[rank10]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank10]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 519, in forward
[rank10]:     causal_mask = self._update_causal_mask(
[rank10]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank10]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 591, in _update_causal_mask
[rank10]:     raise ValueError(
[rank0]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank0]:     return func(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank0]:     outputs: BaseModelOutputWithPast = self.model(
[rank0]:                                        ^^^^^^^^^^^
[rank0]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank10]: ValueError: You are attempting to perform batched generation with padding_side='right' this may lead to unexpected behaviour for Flash Attention version of Qwen2. Make sure to  call `tokenizer.padding_side  = 'left'` before tokenizing the input. 
[rank0]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank0]:     output = func(self, *args, **kwargs)
[rank0]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 519, in forward
[rank0]:     causal_mask = self._update_causal_mask(
[rank0]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 591, in _update_causal_mask
[rank0]:     raise ValueError(
[rank0]: ValueError: You are attempting to perform batched generation with padding_side='right' this may lead to unexpected behaviour for Flash Attention version of Qwen2. Make sure to  call `tokenizer.padding_side  = 'left'` before tokenizing the input. 
[rank25]: Traceback (most recent call last):
[rank25]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 525, in <module>
[rank25]:     main()
[rank25]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 495, in main
[rank25]:     llm.api.finetune(
[rank25]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank25]:     return train(
[rank25]:            ^^^^^^
[rank25]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank25]:     trainer.fit(model, data)
[rank25]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank25]:     call._call_and_handle_interrupt(
[rank25]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank25]:     return trainer_fn(*args, **kwargs)
[rank25]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank25]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank25]:     self._run(model, ckpt_path=ckpt_path)
[rank25]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank25]:     results = self._run_stage()
[rank25]:               ^^^^^^^^^^^^^^^^^
[rank25]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank25]:     self.fit_loop.run()
[rank25]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank25]:     self.advance()
[rank25]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank25]:     self.epoch_loop.run(self._data_fetcher)
[rank25]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank25]:     self.advance(data_fetcher)
[rank25]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank25]:     super().advance(data_fetcher)
[rank25]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank25]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank25]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank25]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 183, in run
[rank25]:     closure()
[rank25]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank25]:     self._result = self.closure(*args, **kwargs)
[rank25]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank25]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank25]:     return func(*args, **kwargs)
[rank25]:            ^^^^^^^^^^^^^^^^^^^^^
[rank25]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank25]:     step_output = self._step_fn()
[rank25]:                   ^^^^^^^^^^^^^^^
[rank25]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank25]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank25]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank25]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank25]:     output = fn(*args, **kwargs)
[rank25]:              ^^^^^^^^^^^^^^^^^^^
[rank25]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank25]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank25]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank25]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank25]:     outputs = self.forward(batch)
[rank25]:               ^^^^^^^^^^^^^^^^^^^
[rank25]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank25]:     return self.model(**batch)
[rank25]:            ^^^^^^^^^^^^^^^^^^^
[rank25]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank25]:     return self._call_impl(*args, **kwargs)
[rank25]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank25]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank25]:     return inner()
[rank25]:            ^^^^^^^
[rank25]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank25]:     result = forward_call(*args, **kwargs)
[rank25]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank25]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank25]:     output = func(self, *args, **kwargs)
[rank25]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank25]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank25]:     return func(*args, **kwargs)
[rank25]:            ^^^^^^^^^^^^^^^^^^^^^
[rank25]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank25]:     outputs: BaseModelOutputWithPast = self.model(
[rank25]:                                        ^^^^^^^^^^^
[rank25]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank25]:     return self._call_impl(*args, **kwargs)
[rank25]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank25]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank25]:     return forward_call(*args, **kwargs)
[rank25]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank25]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank25]:     output = func(self, *args, **kwargs)
[rank25]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank25]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 519, in forward
[rank25]:     causal_mask = self._update_causal_mask(
[rank25]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank25]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 591, in _update_causal_mask
[rank25]:     raise ValueError(
[rank25]: ValueError: You are attempting to perform batched generation with padding_side='right' this may lead to unexpected behaviour for Flash Attention version of Qwen2. Make sure to  call `tokenizer.padding_side  = 'left'` before tokenizing the input. 
[rank19]: Traceback (most recent call last):
[rank19]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 525, in <module>
[rank19]:     main()
[rank19]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 495, in main
[rank19]:     llm.api.finetune(
[rank19]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank19]:     return train(
[rank19]:            ^^^^^^
[rank19]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank19]:     trainer.fit(model, data)
[rank19]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank19]:     call._call_and_handle_interrupt(
[rank19]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank19]:     return trainer_fn(*args, **kwargs)
[rank19]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank19]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank19]:     self._run(model, ckpt_path=ckpt_path)
[rank19]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank19]:     results = self._run_stage()
[rank19]:               ^^^^^^^^^^^^^^^^^
[rank19]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank19]:     self.fit_loop.run()
[rank19]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank19]:     self.advance()
[rank19]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank19]:     self.epoch_loop.run(self._data_fetcher)
[rank19]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank19]:     self.advance(data_fetcher)
[rank19]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank19]:     super().advance(data_fetcher)
[rank19]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank19]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank19]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank19]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 183, in run
[rank19]:     closure()
[rank19]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank19]:     self._result = self.closure(*args, **kwargs)
[rank19]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank24]: Traceback (most recent call last):
[rank24]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 525, in <module>
[rank24]:     main()
[rank24]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 495, in main
[rank24]:     llm.api.finetune(
[rank24]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank24]:     return train(
[rank24]:            ^^^^^^
[rank24]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank24]:     trainer.fit(model, data)
[rank24]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank24]:     call._call_and_handle_interrupt(
[rank24]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank24]:     return trainer_fn(*args, **kwargs)
[rank24]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank24]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank24]:     self._run(model, ckpt_path=ckpt_path)
[rank24]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank24]:     results = self._run_stage()
[rank24]:               ^^^^^^^^^^^^^^^^^
[rank24]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank24]:     self.fit_loop.run()
[rank19]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank19]:     return func(*args, **kwargs)
[rank19]:            ^^^^^^^^^^^^^^^^^^^^^
[rank24]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank24]:     self.advance()
[rank24]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank24]:     self.epoch_loop.run(self._data_fetcher)
[rank24]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank24]:     self.advance(data_fetcher)
[rank24]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank24]:     super().advance(data_fetcher)
[rank19]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank19]:     step_output = self._step_fn()
[rank19]:                   ^^^^^^^^^^^^^^^
[rank19]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank19]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank19]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank19]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank19]:     output = fn(*args, **kwargs)
[rank19]:              ^^^^^^^^^^^^^^^^^^^
[rank24]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank24]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank24]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank24]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 183, in run
[rank24]:     closure()
[rank24]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank24]:     self._result = self.closure(*args, **kwargs)
[rank24]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank19]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank19]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank19]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank19]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank19]:     outputs = self.forward(batch)
[rank19]:               ^^^^^^^^^^^^^^^^^^^
[rank19]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank19]:     return self.model(**batch)
[rank19]:            ^^^^^^^^^^^^^^^^^^^
[rank19]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank19]:     return self._call_impl(*args, **kwargs)
[rank19]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank19]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank19]:     return inner()
[rank19]:            ^^^^^^^
[rank19]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank19]:     result = forward_call(*args, **kwargs)
[rank19]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank19]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank19]:     output = func(self, *args, **kwargs)
[rank19]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank19]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank19]:     return func(*args, **kwargs)
[rank19]:            ^^^^^^^^^^^^^^^^^^^^^
[rank19]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank19]:     outputs: BaseModelOutputWithPast = self.model(
[rank19]:                                        ^^^^^^^^^^^
[rank19]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank19]:     return self._call_impl(*args, **kwargs)
[rank19]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank24]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank24]:     return func(*args, **kwargs)
[rank24]:            ^^^^^^^^^^^^^^^^^^^^^
[rank19]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank19]:     return forward_call(*args, **kwargs)
[rank19]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank24]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank24]:     step_output = self._step_fn()
[rank24]:                   ^^^^^^^^^^^^^^^
[rank24]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank24]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank24]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank24]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank24]:     output = fn(*args, **kwargs)
[rank24]:              ^^^^^^^^^^^^^^^^^^^
[rank19]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank19]:     output = func(self, *args, **kwargs)
[rank19]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank19]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 519, in forward
[rank19]:     causal_mask = self._update_causal_mask(
[rank19]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank19]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 591, in _update_causal_mask
[rank19]:     raise ValueError(
[rank24]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank24]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank24]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank24]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank24]:     outputs = self.forward(batch)
[rank24]:               ^^^^^^^^^^^^^^^^^^^
[rank24]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank24]:     return self.model(**batch)
[rank24]:            ^^^^^^^^^^^^^^^^^^^
[rank19]: ValueError: You are attempting to perform batched generation with padding_side='right' this may lead to unexpected behaviour for Flash Attention version of Qwen2. Make sure to  call `tokenizer.padding_side  = 'left'` before tokenizing the input. 
[rank24]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank24]:     return self._call_impl(*args, **kwargs)
[rank24]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank24]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank24]:     return inner()
[rank24]:            ^^^^^^^
[rank24]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank24]:     result = forward_call(*args, **kwargs)
[rank24]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank24]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank24]:     output = func(self, *args, **kwargs)
[rank24]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank24]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank24]:     return func(*args, **kwargs)
[rank24]:            ^^^^^^^^^^^^^^^^^^^^^
[rank24]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank24]:     outputs: BaseModelOutputWithPast = self.model(
[rank24]:                                        ^^^^^^^^^^^
[rank24]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank24]:     return self._call_impl(*args, **kwargs)
[rank24]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank24]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank24]:     return forward_call(*args, **kwargs)
[rank24]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank24]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank24]:     output = func(self, *args, **kwargs)
[rank24]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank24]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 519, in forward
[rank24]:     causal_mask = self._update_causal_mask(
[rank24]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank24]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 591, in _update_causal_mask
[rank24]:     raise ValueError(
[rank24]: ValueError: You are attempting to perform batched generation with padding_side='right' this may lead to unexpected behaviour for Flash Attention version of Qwen2. Make sure to  call `tokenizer.padding_side  = 'left'` before tokenizing the input. 
[rank17]: Traceback (most recent call last):
[rank17]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 525, in <module>
[rank17]:     main()
[rank17]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 495, in main
[rank17]:     llm.api.finetune(
[rank17]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank17]:     return train(
[rank17]:            ^^^^^^
[rank17]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank17]:     trainer.fit(model, data)
[rank17]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank17]:     call._call_and_handle_interrupt(
[rank17]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank17]:     return trainer_fn(*args, **kwargs)
[rank17]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank17]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank17]:     self._run(model, ckpt_path=ckpt_path)
[rank17]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank17]:     results = self._run_stage()
[rank17]:               ^^^^^^^^^^^^^^^^^
[rank17]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank17]:     self.fit_loop.run()
[rank17]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank17]:     self.advance()
[rank17]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank17]:     self.epoch_loop.run(self._data_fetcher)
[rank17]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank17]:     self.advance(data_fetcher)
[rank17]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank17]:     super().advance(data_fetcher)
[rank17]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank17]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank17]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank17]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 183, in run
[rank17]:     closure()
[rank17]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank17]:     self._result = self.closure(*args, **kwargs)
[rank17]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank17]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank17]:     return func(*args, **kwargs)
[rank17]:            ^^^^^^^^^^^^^^^^^^^^^
[rank17]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank17]:     step_output = self._step_fn()
[rank17]:                   ^^^^^^^^^^^^^^^
[rank17]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank17]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank17]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank17]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank17]:     output = fn(*args, **kwargs)
[rank17]:              ^^^^^^^^^^^^^^^^^^^
[rank17]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank17]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank17]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank17]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank17]:     outputs = self.forward(batch)
[rank17]:               ^^^^^^^^^^^^^^^^^^^
[rank17]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank17]:     return self.model(**batch)
[rank17]:            ^^^^^^^^^^^^^^^^^^^
[rank17]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank17]:     return self._call_impl(*args, **kwargs)
[rank17]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank17]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank17]:     return inner()
[rank17]:            ^^^^^^^
[rank17]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank17]:     result = forward_call(*args, **kwargs)
[rank17]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank17]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank17]:     output = func(self, *args, **kwargs)
[rank17]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank17]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank17]:     return func(*args, **kwargs)
[rank17]:            ^^^^^^^^^^^^^^^^^^^^^
[rank17]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank17]:     outputs: BaseModelOutputWithPast = self.model(
[rank17]:                                        ^^^^^^^^^^^
[rank17]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank17]:     return self._call_impl(*args, **kwargs)
[rank17]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank17]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank17]:     return forward_call(*args, **kwargs)
[rank17]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank17]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank17]:     output = func(self, *args, **kwargs)
[rank17]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank17]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 519, in forward
[rank17]:     causal_mask = self._update_causal_mask(
[rank17]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank17]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 591, in _update_causal_mask
[rank17]:     raise ValueError(
[rank17]: ValueError: You are attempting to perform batched generation with padding_side='right' this may lead to unexpected behaviour for Flash Attention version of Qwen2. Make sure to  call `tokenizer.padding_side  = 'left'` before tokenizing the input. 
[rank12]: Traceback (most recent call last):
[rank12]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 525, in <module>
[rank12]:     main()
[rank12]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 495, in main
[rank12]:     llm.api.finetune(
[rank12]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank12]:     return train(
[rank12]:            ^^^^^^
[rank12]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank12]:     trainer.fit(model, data)
[rank12]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank12]:     call._call_and_handle_interrupt(
[rank12]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank12]:     return trainer_fn(*args, **kwargs)
[rank12]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank12]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank12]:     self._run(model, ckpt_path=ckpt_path)
[rank12]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank12]:     results = self._run_stage()
[rank12]:               ^^^^^^^^^^^^^^^^^
[rank12]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank12]:     self.fit_loop.run()
[rank12]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank12]:     self.advance()
[rank12]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank12]:     self.epoch_loop.run(self._data_fetcher)
[rank12]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank12]:     self.advance(data_fetcher)
[rank12]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank12]:     super().advance(data_fetcher)
[rank12]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank12]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank12]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank12]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 183, in run
[rank12]:     closure()
[rank12]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank12]:     self._result = self.closure(*args, **kwargs)
[rank12]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank12]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank12]:     return func(*args, **kwargs)
[rank12]:            ^^^^^^^^^^^^^^^^^^^^^
[rank12]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank12]:     step_output = self._step_fn()
[rank12]:                   ^^^^^^^^^^^^^^^
[rank12]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank12]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank12]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank12]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank12]:     output = fn(*args, **kwargs)
[rank12]:              ^^^^^^^^^^^^^^^^^^^
[rank12]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank12]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank12]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank12]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank12]:     outputs = self.forward(batch)
[rank12]:               ^^^^^^^^^^^^^^^^^^^
[rank12]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank12]:     return self.model(**batch)
[rank12]:            ^^^^^^^^^^^^^^^^^^^
[rank12]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank12]:     return self._call_impl(*args, **kwargs)
[rank12]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank12]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank12]:     return inner()
[rank12]:            ^^^^^^^
[rank12]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank12]:     result = forward_call(*args, **kwargs)
[rank12]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank12]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank12]:     output = func(self, *args, **kwargs)
[rank12]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank12]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank12]:     return func(*args, **kwargs)
[rank12]:            ^^^^^^^^^^^^^^^^^^^^^
[rank12]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank12]:     outputs: BaseModelOutputWithPast = self.model(
[rank12]:                                        ^^^^^^^^^^^
[rank12]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank12]:     return self._call_impl(*args, **kwargs)
[rank12]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank12]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank12]:     return forward_call(*args, **kwargs)
[rank12]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank12]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank12]:     output = func(self, *args, **kwargs)
[rank12]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank12]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 519, in forward
[rank12]:     causal_mask = self._update_causal_mask(
[rank12]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank12]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 591, in _update_causal_mask
[rank12]:     raise ValueError(
[rank12]: ValueError: You are attempting to perform batched generation with padding_side='right' this may lead to unexpected behaviour for Flash Attention version of Qwen2. Make sure to  call `tokenizer.padding_side  = 'left'` before tokenizing the input. 
[rank43]: Traceback (most recent call last):
[rank43]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 525, in <module>
[rank43]:     main()
[rank43]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 495, in main
[rank43]:     llm.api.finetune(
[rank43]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank43]:     return train(
[rank43]:            ^^^^^^
[rank43]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank43]:     trainer.fit(model, data)
[rank43]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank43]:     call._call_and_handle_interrupt(
[rank43]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank43]:     return trainer_fn(*args, **kwargs)
[rank43]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank43]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank43]:     self._run(model, ckpt_path=ckpt_path)
[rank43]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank43]:     results = self._run_stage()
[rank43]:               ^^^^^^^^^^^^^^^^^
[rank43]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank43]:     self.fit_loop.run()
[rank43]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank43]:     self.advance()
[rank43]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank43]:     self.epoch_loop.run(self._data_fetcher)
[rank43]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank43]:     self.advance(data_fetcher)
[rank43]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank43]:     super().advance(data_fetcher)
[rank43]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank43]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank43]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank43]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 183, in run
[rank43]:     closure()
[rank43]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank43]:     self._result = self.closure(*args, **kwargs)
[rank43]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank43]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank43]:     return func(*args, **kwargs)
[rank43]:            ^^^^^^^^^^^^^^^^^^^^^
[rank43]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank43]:     step_output = self._step_fn()
[rank43]:                   ^^^^^^^^^^^^^^^
[rank43]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank43]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank43]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank43]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank43]:     output = fn(*args, **kwargs)
[rank43]:              ^^^^^^^^^^^^^^^^^^^
[rank43]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank43]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank43]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank43]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank43]:     outputs = self.forward(batch)
[rank43]:               ^^^^^^^^^^^^^^^^^^^
[rank43]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank43]:     return self.model(**batch)
[rank43]:            ^^^^^^^^^^^^^^^^^^^
[rank43]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank43]:     return self._call_impl(*args, **kwargs)
[rank43]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank43]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank43]:     return inner()
[rank43]:            ^^^^^^^
[rank43]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank43]:     result = forward_call(*args, **kwargs)
[rank43]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank43]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank43]:     output = func(self, *args, **kwargs)
[rank43]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank43]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank43]:     return func(*args, **kwargs)
[rank43]:            ^^^^^^^^^^^^^^^^^^^^^
[rank43]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank43]:     outputs: BaseModelOutputWithPast = self.model(
[rank43]:                                        ^^^^^^^^^^^
[rank43]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank43]:     return self._call_impl(*args, **kwargs)
[rank43]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank43]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank43]:     return forward_call(*args, **kwargs)
[rank43]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank43]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank43]:     output = func(self, *args, **kwargs)
[rank43]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank43]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 519, in forward
[rank43]:     causal_mask = self._update_causal_mask(
[rank43]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank43]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 591, in _update_causal_mask
[rank43]:     raise ValueError(
[rank43]: ValueError: You are attempting to perform batched generation with padding_side='right' this may lead to unexpected behaviour for Flash Attention version of Qwen2. Make sure to  call `tokenizer.padding_side  = 'left'` before tokenizing the input. 
[rank15]: Traceback (most recent call last):
[rank15]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 525, in <module>
[rank15]:     main()
[rank15]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 495, in main
[rank15]:     llm.api.finetune(
[rank15]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank15]:     return train(
[rank15]:            ^^^^^^
[rank15]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank15]:     trainer.fit(model, data)
[rank15]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank15]:     call._call_and_handle_interrupt(
[rank15]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank15]:     return trainer_fn(*args, **kwargs)
[rank15]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank15]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank15]:     self._run(model, ckpt_path=ckpt_path)
[rank15]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank15]:     results = self._run_stage()
[rank15]:               ^^^^^^^^^^^^^^^^^
[rank15]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank15]:     self.fit_loop.run()
[rank15]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank15]:     self.advance()
[rank15]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank15]:     self.epoch_loop.run(self._data_fetcher)
[rank15]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank15]:     self.advance(data_fetcher)
[rank15]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank15]:     super().advance(data_fetcher)
[rank63]: Traceback (most recent call last):
[rank63]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 525, in <module>
[rank63]:     main()
[rank63]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 495, in main
[rank63]:     llm.api.finetune(
[rank63]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank63]:     return train(
[rank63]:            ^^^^^^
[rank63]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank63]:     trainer.fit(model, data)
[rank63]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank63]:     call._call_and_handle_interrupt(
[rank15]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank15]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank15]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank15]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 183, in run
[rank15]:     closure()
[rank15]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank15]:     self._result = self.closure(*args, **kwargs)
[rank15]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank15]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank15]:     return func(*args, **kwargs)
[rank15]:            ^^^^^^^^^^^^^^^^^^^^^
[rank44]: Traceback (most recent call last):
[rank44]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 525, in <module>
[rank44]:     main()
[rank44]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 495, in main
[rank44]:     llm.api.finetune(
[rank44]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank44]:     return train(
[rank44]:            ^^^^^^
[rank44]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank44]:     trainer.fit(model, data)
[rank44]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank44]:     call._call_and_handle_interrupt(
[rank15]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank15]:     step_output = self._step_fn()
[rank15]:                   ^^^^^^^^^^^^^^^
[rank15]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank15]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank15]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank15]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank15]:     output = fn(*args, **kwargs)
[rank15]:              ^^^^^^^^^^^^^^^^^^^
[rank15]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank15]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank15]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank15]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank15]:     outputs = self.forward(batch)
[rank15]:               ^^^^^^^^^^^^^^^^^^^
[rank15]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank15]:     return self.model(**batch)
[rank15]:            ^^^^^^^^^^^^^^^^^^^
[rank15]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank15]:     return self._call_impl(*args, **kwargs)
[rank15]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank15]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank15]:     return inner()
[rank15]:            ^^^^^^^
[rank15]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank15]:     result = forward_call(*args, **kwargs)
[rank15]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank15]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank15]:     output = func(self, *args, **kwargs)
[rank15]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank15]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank15]:     return func(*args, **kwargs)
[rank15]:            ^^^^^^^^^^^^^^^^^^^^^
[rank15]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank15]:     outputs: BaseModelOutputWithPast = self.model(
[rank15]:                                        ^^^^^^^^^^^
[rank15]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank15]:     return self._call_impl(*args, **kwargs)
[rank15]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank63]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank63]:     return trainer_fn(*args, **kwargs)
[rank63]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank63]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank63]:     self._run(model, ckpt_path=ckpt_path)
[rank63]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank63]:     results = self._run_stage()
[rank63]:               ^^^^^^^^^^^^^^^^^
[rank63]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank63]:     self.fit_loop.run()
[rank15]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank15]:     return forward_call(*args, **kwargs)
[rank15]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank63]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank63]:     self.advance()
[rank63]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank63]:     self.epoch_loop.run(self._data_fetcher)
[rank63]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank63]:     self.advance(data_fetcher)
[rank63]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank63]:     super().advance(data_fetcher)
[rank44]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank44]:     return trainer_fn(*args, **kwargs)
[rank44]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank44]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank44]:     self._run(model, ckpt_path=ckpt_path)
[rank44]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank44]:     results = self._run_stage()
[rank44]:               ^^^^^^^^^^^^^^^^^
[rank44]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank44]:     self.fit_loop.run()
[rank15]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank15]:     output = func(self, *args, **kwargs)
[rank15]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank15]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 519, in forward
[rank15]:     causal_mask = self._update_causal_mask(
[rank15]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank15]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 591, in _update_causal_mask
[rank15]:     raise ValueError(
[rank63]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank63]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank63]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank63]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 183, in run
[rank63]:     closure()
[rank63]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank63]:     self._result = self.closure(*args, **kwargs)
[rank63]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank44]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank44]:     self.advance()
[rank44]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank44]:     self.epoch_loop.run(self._data_fetcher)
[rank44]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank44]:     self.advance(data_fetcher)
[rank44]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank44]:     super().advance(data_fetcher)
[rank15]: ValueError: You are attempting to perform batched generation with padding_side='right' this may lead to unexpected behaviour for Flash Attention version of Qwen2. Make sure to  call `tokenizer.padding_side  = 'left'` before tokenizing the input. 
[rank63]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank63]:     return func(*args, **kwargs)
[rank63]:            ^^^^^^^^^^^^^^^^^^^^^
[rank44]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank44]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank44]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank44]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 183, in run
[rank44]:     closure()
[rank44]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank44]:     self._result = self.closure(*args, **kwargs)
[rank44]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank63]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank63]:     step_output = self._step_fn()
[rank63]:                   ^^^^^^^^^^^^^^^
[rank63]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank63]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank63]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank63]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank63]:     output = fn(*args, **kwargs)
[rank63]:              ^^^^^^^^^^^^^^^^^^^
[rank44]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank44]:     return func(*args, **kwargs)
[rank44]:            ^^^^^^^^^^^^^^^^^^^^^
[rank63]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank63]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank63]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank63]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank63]:     outputs = self.forward(batch)
[rank63]:               ^^^^^^^^^^^^^^^^^^^
[rank63]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank63]:     return self.model(**batch)
[rank63]:            ^^^^^^^^^^^^^^^^^^^
[rank44]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank44]:     step_output = self._step_fn()
[rank44]:                   ^^^^^^^^^^^^^^^
[rank44]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank44]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank44]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank44]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank44]:     output = fn(*args, **kwargs)
[rank44]:              ^^^^^^^^^^^^^^^^^^^
[rank63]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank63]:     return self._call_impl(*args, **kwargs)
[rank63]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank63]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank63]:     return inner()
[rank63]:            ^^^^^^^
[rank63]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank63]:     result = forward_call(*args, **kwargs)
[rank63]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank63]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank63]:     output = func(self, *args, **kwargs)
[rank44]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank44]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank44]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank44]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank44]:     outputs = self.forward(batch)
[rank44]:               ^^^^^^^^^^^^^^^^^^^
[rank44]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank44]:     return self.model(**batch)
[rank44]:            ^^^^^^^^^^^^^^^^^^^
[rank63]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank63]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank63]:     return func(*args, **kwargs)
[rank63]:            ^^^^^^^^^^^^^^^^^^^^^
[rank63]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank63]:     outputs: BaseModelOutputWithPast = self.model(
[rank63]:                                        ^^^^^^^^^^^
[rank63]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank63]:     return self._call_impl(*args, **kwargs)
[rank63]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank44]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank44]:     return self._call_impl(*args, **kwargs)
[rank44]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank44]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank44]:     return inner()
[rank44]:            ^^^^^^^
[rank44]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank44]:     result = forward_call(*args, **kwargs)
[rank44]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank44]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank44]:     output = func(self, *args, **kwargs)
[rank63]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank63]:     return forward_call(*args, **kwargs)
[rank63]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank44]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank44]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank44]:     return func(*args, **kwargs)
[rank44]:            ^^^^^^^^^^^^^^^^^^^^^
[rank44]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank44]:     outputs: BaseModelOutputWithPast = self.model(
[rank44]:                                        ^^^^^^^^^^^
[rank44]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank44]:     return self._call_impl(*args, **kwargs)
[rank44]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank63]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank63]:     output = func(self, *args, **kwargs)
[rank63]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank63]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 519, in forward
[rank63]:     causal_mask = self._update_causal_mask(
[rank63]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank63]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 591, in _update_causal_mask
[rank63]:     raise ValueError(
[rank44]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank44]:     return forward_call(*args, **kwargs)
[rank44]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank63]: ValueError: You are attempting to perform batched generation with padding_side='right' this may lead to unexpected behaviour for Flash Attention version of Qwen2. Make sure to  call `tokenizer.padding_side  = 'left'` before tokenizing the input. 
[rank46]: Traceback (most recent call last):
[rank46]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 525, in <module>
[rank46]:     main()
[rank46]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 495, in main
[rank46]:     llm.api.finetune(
[rank46]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank46]:     return train(
[rank46]:            ^^^^^^
[rank46]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank46]:     trainer.fit(model, data)
[rank46]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank46]:     call._call_and_handle_interrupt(
[rank60]: Traceback (most recent call last):
[rank60]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 525, in <module>
[rank60]:     main()
[rank60]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 495, in main
[rank60]:     llm.api.finetune(
[rank60]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank60]:     return train(
[rank60]:            ^^^^^^
[rank60]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank60]:     trainer.fit(model, data)
[rank60]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank60]:     call._call_and_handle_interrupt(
[rank46]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank46]:     return trainer_fn(*args, **kwargs)
[rank46]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank46]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank46]:     self._run(model, ckpt_path=ckpt_path)
[rank46]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank46]:     results = self._run_stage()
[rank46]:               ^^^^^^^^^^^^^^^^^
[rank46]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank46]:     self.fit_loop.run()
[rank60]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank60]:     return trainer_fn(*args, **kwargs)
[rank60]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank60]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank60]:     self._run(model, ckpt_path=ckpt_path)
[rank60]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank60]:     results = self._run_stage()
[rank60]:               ^^^^^^^^^^^^^^^^^
[rank60]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank60]:     self.fit_loop.run()
[rank46]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank46]:     self.advance()
[rank46]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank46]:     self.epoch_loop.run(self._data_fetcher)
[rank46]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank46]:     self.advance(data_fetcher)
[rank46]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank46]:     super().advance(data_fetcher)
[rank60]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank60]:     self.advance()
[rank60]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank60]:     self.epoch_loop.run(self._data_fetcher)
[rank60]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank60]:     self.advance(data_fetcher)
[rank60]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank60]:     super().advance(data_fetcher)
[rank46]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank46]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank46]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank46]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 183, in run
[rank46]:     closure()
[rank46]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank46]:     self._result = self.closure(*args, **kwargs)
[rank46]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank60]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank60]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank60]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank60]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 183, in run
[rank60]:     closure()
[rank60]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank60]:     self._result = self.closure(*args, **kwargs)
[rank60]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank46]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank46]:     return func(*args, **kwargs)
[rank46]:            ^^^^^^^^^^^^^^^^^^^^^
[rank60]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank60]:     return func(*args, **kwargs)
[rank60]:            ^^^^^^^^^^^^^^^^^^^^^
[rank44]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank44]:     output = func(self, *args, **kwargs)
[rank44]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank44]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 519, in forward
[rank44]:     causal_mask = self._update_causal_mask(
[rank44]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank44]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 591, in _update_causal_mask
[rank44]:     raise ValueError(
[rank60]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank60]:     step_output = self._step_fn()
[rank60]:                   ^^^^^^^^^^^^^^^
[rank60]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank60]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank60]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank60]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank60]:     output = fn(*args, **kwargs)
[rank60]:              ^^^^^^^^^^^^^^^^^^^
[rank44]: ValueError: You are attempting to perform batched generation with padding_side='right' this may lead to unexpected behaviour for Flash Attention version of Qwen2. Make sure to  call `tokenizer.padding_side  = 'left'` before tokenizing the input. 
[rank60]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank60]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank60]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank60]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank60]:     outputs = self.forward(batch)
[rank60]:               ^^^^^^^^^^^^^^^^^^^
[rank60]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank60]:     return self.model(**batch)
[rank60]:            ^^^^^^^^^^^^^^^^^^^
[rank46]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank46]:     step_output = self._step_fn()
[rank46]:                   ^^^^^^^^^^^^^^^
[rank46]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank46]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank46]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank46]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank46]:     output = fn(*args, **kwargs)
[rank46]:              ^^^^^^^^^^^^^^^^^^^
[rank60]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank60]:     return self._call_impl(*args, **kwargs)
[rank60]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank60]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank60]:     return inner()
[rank60]:            ^^^^^^^
[rank60]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank60]:     result = forward_call(*args, **kwargs)
[rank60]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank60]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank60]:     output = func(self, *args, **kwargs)
[rank46]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank46]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank46]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank46]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank46]:     outputs = self.forward(batch)
[rank46]:               ^^^^^^^^^^^^^^^^^^^
[rank46]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank46]:     return self.model(**batch)
[rank46]:            ^^^^^^^^^^^^^^^^^^^
[rank60]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank60]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank60]:     return func(*args, **kwargs)
[rank60]:            ^^^^^^^^^^^^^^^^^^^^^
[rank60]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank60]:     outputs: BaseModelOutputWithPast = self.model(
[rank60]:                                        ^^^^^^^^^^^
[rank60]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank60]:     return self._call_impl(*args, **kwargs)
[rank60]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank46]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank46]:     return self._call_impl(*args, **kwargs)
[rank46]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank46]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank46]:     return inner()
[rank46]:            ^^^^^^^
[rank46]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank46]:     result = forward_call(*args, **kwargs)
[rank46]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank46]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank46]:     output = func(self, *args, **kwargs)
[rank60]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank60]:     return forward_call(*args, **kwargs)
[rank60]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank46]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank46]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank46]:     return func(*args, **kwargs)
[rank46]:            ^^^^^^^^^^^^^^^^^^^^^
[rank46]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank46]:     outputs: BaseModelOutputWithPast = self.model(
[rank46]:                                        ^^^^^^^^^^^
[rank46]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank46]:     return self._call_impl(*args, **kwargs)
[rank46]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank60]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank60]:     output = func(self, *args, **kwargs)
[rank60]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank60]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 519, in forward
[rank60]:     causal_mask = self._update_causal_mask(
[rank60]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank60]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 591, in _update_causal_mask
[rank60]:     raise ValueError(
[rank46]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank46]:     return forward_call(*args, **kwargs)
[rank46]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank60]: ValueError: You are attempting to perform batched generation with padding_side='right' this may lead to unexpected behaviour for Flash Attention version of Qwen2. Make sure to  call `tokenizer.padding_side  = 'left'` before tokenizing the input. 
[rank46]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank46]:     output = func(self, *args, **kwargs)
[rank46]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank46]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 519, in forward
[rank46]:     causal_mask = self._update_causal_mask(
[rank46]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank46]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 591, in _update_causal_mask
[rank46]:     raise ValueError(
[rank61]: Traceback (most recent call last):
[rank61]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 525, in <module>
[rank61]:     main()
[rank61]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 495, in main
[rank61]:     llm.api.finetune(
[rank61]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank61]:     return train(
[rank61]:            ^^^^^^
[rank61]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank61]:     trainer.fit(model, data)
[rank61]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank61]:     call._call_and_handle_interrupt(
[rank46]: ValueError: You are attempting to perform batched generation with padding_side='right' this may lead to unexpected behaviour for Flash Attention version of Qwen2. Make sure to  call `tokenizer.padding_side  = 'left'` before tokenizing the input. 
[rank47]: Traceback (most recent call last):
[rank47]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 525, in <module>
[rank47]:     main()
[rank47]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 495, in main
[rank47]:     llm.api.finetune(
[rank47]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank47]:     return train(
[rank47]:            ^^^^^^
[rank47]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank47]:     trainer.fit(model, data)
[rank47]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank47]:     call._call_and_handle_interrupt(
[rank47]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank47]:     return trainer_fn(*args, **kwargs)
[rank47]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank47]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank47]:     self._run(model, ckpt_path=ckpt_path)
[rank47]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank47]:     results = self._run_stage()
[rank47]:               ^^^^^^^^^^^^^^^^^
[rank47]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank47]:     self.fit_loop.run()
[rank47]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank47]:     self.advance()
[rank47]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank47]:     self.epoch_loop.run(self._data_fetcher)
[rank47]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank47]:     self.advance(data_fetcher)
[rank47]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank47]:     super().advance(data_fetcher)
[rank47]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank47]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank47]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank47]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 183, in run
[rank47]:     closure()
[rank47]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank47]:     self._result = self.closure(*args, **kwargs)
[rank47]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank41]: Traceback (most recent call last):
[rank41]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 525, in <module>
[rank41]:     main()
[rank41]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 495, in main
[rank41]:     llm.api.finetune(
[rank41]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank41]:     return train(
[rank41]:            ^^^^^^
[rank41]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank41]:     trainer.fit(model, data)
[rank41]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank41]:     call._call_and_handle_interrupt(
[rank47]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank47]:     return func(*args, **kwargs)
[rank47]:            ^^^^^^^^^^^^^^^^^^^^^
[rank61]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank61]:     return trainer_fn(*args, **kwargs)
[rank61]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank61]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank61]:     self._run(model, ckpt_path=ckpt_path)
[rank61]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank61]:     results = self._run_stage()
[rank61]:               ^^^^^^^^^^^^^^^^^
[rank61]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank61]:     self.fit_loop.run()
[rank41]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank41]:     return trainer_fn(*args, **kwargs)
[rank41]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank41]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank41]:     self._run(model, ckpt_path=ckpt_path)
[rank41]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank41]:     results = self._run_stage()
[rank41]:               ^^^^^^^^^^^^^^^^^
[rank41]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank41]:     self.fit_loop.run()
[rank47]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank47]:     step_output = self._step_fn()
[rank47]:                   ^^^^^^^^^^^^^^^
[rank47]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank47]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank47]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank47]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank47]:     output = fn(*args, **kwargs)
[rank47]:              ^^^^^^^^^^^^^^^^^^^
[rank61]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank61]:     self.advance()
[rank61]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank61]:     self.epoch_loop.run(self._data_fetcher)
[rank61]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank61]:     self.advance(data_fetcher)
[rank61]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank61]:     super().advance(data_fetcher)
[rank41]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank41]:     self.advance()
[rank41]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank41]:     self.epoch_loop.run(self._data_fetcher)
[rank41]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank41]:     self.advance(data_fetcher)
[rank41]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank41]:     super().advance(data_fetcher)
[rank47]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank47]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank47]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank47]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank47]:     outputs = self.forward(batch)
[rank47]:               ^^^^^^^^^^^^^^^^^^^
[rank47]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank47]:     return self.model(**batch)
[rank47]:            ^^^^^^^^^^^^^^^^^^^
[rank61]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank61]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank61]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank61]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 183, in run
[rank61]:     closure()
[rank61]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank61]:     self._result = self.closure(*args, **kwargs)
[rank61]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank41]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank41]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank41]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank41]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 183, in run
[rank41]:     closure()
[rank41]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank41]:     self._result = self.closure(*args, **kwargs)
[rank41]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank47]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank47]:     return self._call_impl(*args, **kwargs)
[rank47]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank47]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank47]:     return inner()
[rank47]:            ^^^^^^^
[rank47]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank47]:     result = forward_call(*args, **kwargs)
[rank47]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank47]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank47]:     output = func(self, *args, **kwargs)
[rank61]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank61]:     return func(*args, **kwargs)
[rank61]:            ^^^^^^^^^^^^^^^^^^^^^
[rank41]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank41]:     return func(*args, **kwargs)
[rank41]:            ^^^^^^^^^^^^^^^^^^^^^
[rank47]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank47]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank47]:     return func(*args, **kwargs)
[rank47]:            ^^^^^^^^^^^^^^^^^^^^^
[rank47]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank47]:     outputs: BaseModelOutputWithPast = self.model(
[rank47]:                                        ^^^^^^^^^^^
[rank47]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank47]:     return self._call_impl(*args, **kwargs)
[rank47]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank61]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank61]:     step_output = self._step_fn()
[rank61]:                   ^^^^^^^^^^^^^^^
[rank61]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank61]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank61]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank61]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank61]:     output = fn(*args, **kwargs)
[rank61]:              ^^^^^^^^^^^^^^^^^^^
[rank41]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank41]:     step_output = self._step_fn()
[rank41]:                   ^^^^^^^^^^^^^^^
[rank41]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank41]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank41]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank41]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank41]:     output = fn(*args, **kwargs)
[rank41]:              ^^^^^^^^^^^^^^^^^^^
[rank47]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank47]:     return forward_call(*args, **kwargs)
[rank47]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank61]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank61]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank61]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank61]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank61]:     outputs = self.forward(batch)
[rank61]:               ^^^^^^^^^^^^^^^^^^^
[rank61]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank61]:     return self.model(**batch)
[rank61]:            ^^^^^^^^^^^^^^^^^^^
[rank41]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank41]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank41]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank41]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank41]:     outputs = self.forward(batch)
[rank41]:               ^^^^^^^^^^^^^^^^^^^
[rank41]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank41]:     return self.model(**batch)
[rank41]:            ^^^^^^^^^^^^^^^^^^^
[rank47]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank47]:     output = func(self, *args, **kwargs)
[rank47]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank47]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 519, in forward
[rank47]:     causal_mask = self._update_causal_mask(
[rank47]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank47]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 591, in _update_causal_mask
[rank47]:     raise ValueError(
[rank61]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank61]:     return self._call_impl(*args, **kwargs)
[rank61]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank61]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank61]:     return inner()
[rank61]:            ^^^^^^^
[rank61]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank61]:     result = forward_call(*args, **kwargs)
[rank61]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank61]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank61]:     output = func(self, *args, **kwargs)
[rank41]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank41]:     return self._call_impl(*args, **kwargs)
[rank41]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank41]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank41]:     return inner()
[rank41]:            ^^^^^^^
[rank41]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank41]:     result = forward_call(*args, **kwargs)
[rank41]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank41]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank41]:     output = func(self, *args, **kwargs)
[rank47]: ValueError: You are attempting to perform batched generation with padding_side='right' this may lead to unexpected behaviour for Flash Attention version of Qwen2. Make sure to  call `tokenizer.padding_side  = 'left'` before tokenizing the input. 
[rank61]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank61]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank61]:     return func(*args, **kwargs)
[rank61]:            ^^^^^^^^^^^^^^^^^^^^^
[rank61]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank61]:     outputs: BaseModelOutputWithPast = self.model(
[rank61]:                                        ^^^^^^^^^^^
[rank61]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank61]:     return self._call_impl(*args, **kwargs)
[rank61]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank41]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank41]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank41]:     return func(*args, **kwargs)
[rank41]:            ^^^^^^^^^^^^^^^^^^^^^
[rank41]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank41]:     outputs: BaseModelOutputWithPast = self.model(
[rank41]:                                        ^^^^^^^^^^^
[rank41]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank41]:     return self._call_impl(*args, **kwargs)
[rank41]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank61]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank61]:     return forward_call(*args, **kwargs)
[rank61]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank41]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank41]:     return forward_call(*args, **kwargs)
[rank41]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank61]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank61]:     output = func(self, *args, **kwargs)
[rank61]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank61]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 519, in forward
[rank61]:     causal_mask = self._update_causal_mask(
[rank61]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank61]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 591, in _update_causal_mask
[rank61]:     raise ValueError(
[rank41]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank41]:     output = func(self, *args, **kwargs)
[rank41]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank41]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 519, in forward
[rank41]:     causal_mask = self._update_causal_mask(
[rank41]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank41]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 591, in _update_causal_mask
[rank41]:     raise ValueError(
[rank61]: ValueError: You are attempting to perform batched generation with padding_side='right' this may lead to unexpected behaviour for Flash Attention version of Qwen2. Make sure to  call `tokenizer.padding_side  = 'left'` before tokenizing the input. 
[rank41]: ValueError: You are attempting to perform batched generation with padding_side='right' this may lead to unexpected behaviour for Flash Attention version of Qwen2. Make sure to  call `tokenizer.padding_side  = 'left'` before tokenizing the input. 
[rank62]: Traceback (most recent call last):
[rank62]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 525, in <module>
[rank62]:     main()
[rank62]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 495, in main
[rank62]:     llm.api.finetune(
[rank62]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank62]:     return train(
[rank62]:            ^^^^^^
[rank62]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank62]:     trainer.fit(model, data)
[rank62]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank62]:     call._call_and_handle_interrupt(
[rank13]: Traceback (most recent call last):
[rank13]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 525, in <module>
[rank13]:     main()
[rank13]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 495, in main
[rank13]:     llm.api.finetune(
[rank13]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank13]:     return train(
[rank13]:            ^^^^^^
[rank13]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank13]:     trainer.fit(model, data)
[rank13]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank13]:     call._call_and_handle_interrupt(
[rank62]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank62]:     return trainer_fn(*args, **kwargs)
[rank62]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank62]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank62]:     self._run(model, ckpt_path=ckpt_path)
[rank62]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank62]:     results = self._run_stage()
[rank62]:               ^^^^^^^^^^^^^^^^^
[rank62]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank62]:     self.fit_loop.run()
[rank13]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank13]:     return trainer_fn(*args, **kwargs)
[rank13]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank13]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank13]:     self._run(model, ckpt_path=ckpt_path)
[rank13]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank13]:     results = self._run_stage()
[rank13]:               ^^^^^^^^^^^^^^^^^
[rank13]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank13]:     self.fit_loop.run()
[rank62]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank62]:     self.advance()
[rank62]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank62]:     self.epoch_loop.run(self._data_fetcher)
[rank62]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank62]:     self.advance(data_fetcher)
[rank62]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank62]:     super().advance(data_fetcher)
[rank13]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank13]:     self.advance()
[rank13]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank13]:     self.epoch_loop.run(self._data_fetcher)
[rank13]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank13]:     self.advance(data_fetcher)
[rank13]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank13]:     super().advance(data_fetcher)
[rank62]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank62]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank62]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank62]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 183, in run
[rank62]:     closure()
[rank62]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank62]:     self._result = self.closure(*args, **kwargs)
[rank62]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank13]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank13]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank13]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank13]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 183, in run
[rank13]:     closure()
[rank13]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank13]:     self._result = self.closure(*args, **kwargs)
[rank13]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank62]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank62]:     return func(*args, **kwargs)
[rank62]:            ^^^^^^^^^^^^^^^^^^^^^
[rank13]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank13]:     return func(*args, **kwargs)
[rank13]:            ^^^^^^^^^^^^^^^^^^^^^
[rank62]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank62]:     step_output = self._step_fn()
[rank62]:                   ^^^^^^^^^^^^^^^
[rank62]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank62]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank62]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank62]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank62]:     output = fn(*args, **kwargs)
[rank62]:              ^^^^^^^^^^^^^^^^^^^
[rank13]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank13]:     step_output = self._step_fn()
[rank13]:                   ^^^^^^^^^^^^^^^
[rank13]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank13]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank13]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank13]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank13]:     output = fn(*args, **kwargs)
[rank13]:              ^^^^^^^^^^^^^^^^^^^
[rank62]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank62]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank62]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank62]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank62]:     outputs = self.forward(batch)
[rank62]:               ^^^^^^^^^^^^^^^^^^^
[rank62]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank62]:     return self.model(**batch)
[rank62]:            ^^^^^^^^^^^^^^^^^^^
[rank13]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank13]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank13]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank13]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank13]:     outputs = self.forward(batch)
[rank13]:               ^^^^^^^^^^^^^^^^^^^
[rank13]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank13]:     return self.model(**batch)
[rank13]:            ^^^^^^^^^^^^^^^^^^^
[rank62]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank62]:     return self._call_impl(*args, **kwargs)
[rank62]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank62]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank62]:     return inner()
[rank62]:            ^^^^^^^
[rank62]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank62]:     result = forward_call(*args, **kwargs)
[rank62]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank62]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank62]:     output = func(self, *args, **kwargs)
[rank13]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank13]:     return self._call_impl(*args, **kwargs)
[rank13]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank13]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank13]:     return inner()
[rank13]:            ^^^^^^^
[rank13]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank13]:     result = forward_call(*args, **kwargs)
[rank13]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank13]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank13]:     output = func(self, *args, **kwargs)
[rank62]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank62]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank62]:     return func(*args, **kwargs)
[rank62]:            ^^^^^^^^^^^^^^^^^^^^^
[rank62]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank62]:     outputs: BaseModelOutputWithPast = self.model(
[rank62]:                                        ^^^^^^^^^^^
[rank62]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank62]:     return self._call_impl(*args, **kwargs)
[rank62]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank13]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank13]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank13]:     return func(*args, **kwargs)
[rank13]:            ^^^^^^^^^^^^^^^^^^^^^
[rank13]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank13]:     outputs: BaseModelOutputWithPast = self.model(
[rank13]:                                        ^^^^^^^^^^^
[rank13]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank13]:     return self._call_impl(*args, **kwargs)
[rank13]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank62]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank62]:     return forward_call(*args, **kwargs)
[rank62]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank13]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank13]:     return forward_call(*args, **kwargs)
[rank13]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank62]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank62]:     output = func(self, *args, **kwargs)
[rank62]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank62]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 519, in forward
[rank62]:     causal_mask = self._update_causal_mask(
[rank62]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank62]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 591, in _update_causal_mask
[rank62]:     raise ValueError(
[rank13]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank13]:     output = func(self, *args, **kwargs)
[rank13]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank13]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 519, in forward
[rank13]:     causal_mask = self._update_causal_mask(
[rank13]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank13]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 591, in _update_causal_mask
[rank13]:     raise ValueError(
[rank62]: ValueError: You are attempting to perform batched generation with padding_side='right' this may lead to unexpected behaviour for Flash Attention version of Qwen2. Make sure to  call `tokenizer.padding_side  = 'left'` before tokenizing the input. 
[rank13]: ValueError: You are attempting to perform batched generation with padding_side='right' this may lead to unexpected behaviour for Flash Attention version of Qwen2. Make sure to  call `tokenizer.padding_side  = 'left'` before tokenizing the input. 
[rank20]: Traceback (most recent call last):
[rank20]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 525, in <module>
[rank20]:     main()
[rank20]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 495, in main
[rank20]:     llm.api.finetune(
[rank20]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank20]:     return train(
[rank20]:            ^^^^^^
[rank20]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank20]:     trainer.fit(model, data)
[rank20]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank20]:     call._call_and_handle_interrupt(
[rank40]: Traceback (most recent call last):
[rank40]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 525, in <module>
[rank40]:     main()
[rank40]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 495, in main
[rank40]:     llm.api.finetune(
[rank40]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank40]:     return train(
[rank40]:            ^^^^^^
[rank40]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank40]:     trainer.fit(model, data)
[rank40]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank40]:     call._call_and_handle_interrupt(
[rank40]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank40]:     return trainer_fn(*args, **kwargs)
[rank40]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank40]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank40]:     self._run(model, ckpt_path=ckpt_path)
[rank40]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank40]:     results = self._run_stage()
[rank40]:               ^^^^^^^^^^^^^^^^^
[rank40]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank40]:     self.fit_loop.run()
[rank40]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank40]:     self.advance()
[rank40]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank40]:     self.epoch_loop.run(self._data_fetcher)
[rank40]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank40]:     self.advance(data_fetcher)
[rank40]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank40]:     super().advance(data_fetcher)
[rank20]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank20]:     return trainer_fn(*args, **kwargs)
[rank20]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank20]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank20]:     self._run(model, ckpt_path=ckpt_path)
[rank20]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank20]:     results = self._run_stage()
[rank20]:               ^^^^^^^^^^^^^^^^^
[rank20]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank20]:     self.fit_loop.run()
[rank40]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank40]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank40]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank40]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 183, in run
[rank40]:     closure()
[rank40]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank40]:     self._result = self.closure(*args, **kwargs)
[rank40]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank20]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank20]:     self.advance()
[rank20]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank20]:     self.epoch_loop.run(self._data_fetcher)
[rank20]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank20]:     self.advance(data_fetcher)
[rank20]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank20]:     super().advance(data_fetcher)
[rank20]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank20]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank20]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank20]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 183, in run
[rank20]:     closure()
[rank20]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank20]:     self._result = self.closure(*args, **kwargs)
[rank20]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank20]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank20]:     return func(*args, **kwargs)
[rank20]:            ^^^^^^^^^^^^^^^^^^^^^
[rank40]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank40]:     return func(*args, **kwargs)
[rank40]:            ^^^^^^^^^^^^^^^^^^^^^
[rank14]: Traceback (most recent call last):
[rank14]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 525, in <module>
[rank14]:     main()
[rank14]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 495, in main
[rank14]:     llm.api.finetune(
[rank14]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank14]:     return train(
[rank14]:            ^^^^^^
[rank14]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank14]:     trainer.fit(model, data)
[rank14]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank14]:     call._call_and_handle_interrupt(
[rank20]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank20]:     step_output = self._step_fn()
[rank20]:                   ^^^^^^^^^^^^^^^
[rank20]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank20]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank20]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank20]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank20]:     output = fn(*args, **kwargs)
[rank20]:              ^^^^^^^^^^^^^^^^^^^
[rank40]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank40]:     step_output = self._step_fn()
[rank40]:                   ^^^^^^^^^^^^^^^
[rank40]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank40]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank40]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank40]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank40]:     output = fn(*args, **kwargs)
[rank40]:              ^^^^^^^^^^^^^^^^^^^
[rank14]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank14]:     return trainer_fn(*args, **kwargs)
[rank14]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank14]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank14]:     self._run(model, ckpt_path=ckpt_path)
[rank14]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank14]:     results = self._run_stage()
[rank14]:               ^^^^^^^^^^^^^^^^^
[rank14]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank14]:     self.fit_loop.run()
[rank20]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank20]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank20]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank20]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank20]:     outputs = self.forward(batch)
[rank20]:               ^^^^^^^^^^^^^^^^^^^
[rank20]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank20]:     return self.model(**batch)
[rank20]:            ^^^^^^^^^^^^^^^^^^^
[rank40]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank40]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank40]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank40]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank40]:     outputs = self.forward(batch)
[rank40]:               ^^^^^^^^^^^^^^^^^^^
[rank40]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank40]:     return self.model(**batch)
[rank40]:            ^^^^^^^^^^^^^^^^^^^
[rank14]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank14]:     self.advance()
[rank14]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank14]:     self.epoch_loop.run(self._data_fetcher)
[rank14]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank14]:     self.advance(data_fetcher)
[rank14]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank14]:     super().advance(data_fetcher)
[rank20]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank20]:     return self._call_impl(*args, **kwargs)
[rank20]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank20]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank20]:     return inner()
[rank20]:            ^^^^^^^
[rank20]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank20]:     result = forward_call(*args, **kwargs)
[rank20]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank20]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank20]:     output = func(self, *args, **kwargs)
[rank40]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank40]:     return self._call_impl(*args, **kwargs)
[rank40]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank40]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank40]:     return inner()
[rank40]:            ^^^^^^^
[rank40]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank40]:     result = forward_call(*args, **kwargs)
[rank40]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank40]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank40]:     output = func(self, *args, **kwargs)
[rank14]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank14]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank14]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank14]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 183, in run
[rank14]:     closure()
[rank14]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank14]:     self._result = self.closure(*args, **kwargs)
[rank14]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank20]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank20]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank20]:     return func(*args, **kwargs)
[rank20]:            ^^^^^^^^^^^^^^^^^^^^^
[rank20]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank20]:     outputs: BaseModelOutputWithPast = self.model(
[rank20]:                                        ^^^^^^^^^^^
[rank20]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank20]:     return self._call_impl(*args, **kwargs)
[rank20]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank40]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank40]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank40]:     return func(*args, **kwargs)
[rank40]:            ^^^^^^^^^^^^^^^^^^^^^
[rank40]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank40]:     outputs: BaseModelOutputWithPast = self.model(
[rank40]:                                        ^^^^^^^^^^^
[rank40]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank40]:     return self._call_impl(*args, **kwargs)
[rank40]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank14]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank14]:     return func(*args, **kwargs)
[rank14]:            ^^^^^^^^^^^^^^^^^^^^^
[rank20]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank20]:     return forward_call(*args, **kwargs)
[rank20]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank40]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank40]:     return forward_call(*args, **kwargs)
[rank40]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank14]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank14]:     step_output = self._step_fn()
[rank14]:                   ^^^^^^^^^^^^^^^
[rank14]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank14]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank14]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank14]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank14]:     output = fn(*args, **kwargs)
[rank14]:              ^^^^^^^^^^^^^^^^^^^
[rank20]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank20]:     output = func(self, *args, **kwargs)
[rank20]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank20]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 519, in forward
[rank20]:     causal_mask = self._update_causal_mask(
[rank20]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank20]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 591, in _update_causal_mask
[rank20]:     raise ValueError(
[rank40]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank40]:     output = func(self, *args, **kwargs)
[rank40]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank40]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 519, in forward
[rank40]:     causal_mask = self._update_causal_mask(
[rank40]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank40]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 591, in _update_causal_mask
[rank40]:     raise ValueError(
[rank14]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank14]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank14]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank14]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank14]:     outputs = self.forward(batch)
[rank14]:               ^^^^^^^^^^^^^^^^^^^
[rank14]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank14]:     return self.model(**batch)
[rank14]:            ^^^^^^^^^^^^^^^^^^^
[rank20]: ValueError: You are attempting to perform batched generation with padding_side='right' this may lead to unexpected behaviour for Flash Attention version of Qwen2. Make sure to  call `tokenizer.padding_side  = 'left'` before tokenizing the input. 
[rank40]: ValueError: You are attempting to perform batched generation with padding_side='right' this may lead to unexpected behaviour for Flash Attention version of Qwen2. Make sure to  call `tokenizer.padding_side  = 'left'` before tokenizing the input. 
[rank14]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank14]:     return self._call_impl(*args, **kwargs)
[rank14]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank14]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank14]:     return inner()
[rank14]:            ^^^^^^^
[rank14]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank14]:     result = forward_call(*args, **kwargs)
[rank14]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank14]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank14]:     output = func(self, *args, **kwargs)
[rank14]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank14]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank14]:     return func(*args, **kwargs)
[rank14]:            ^^^^^^^^^^^^^^^^^^^^^
[rank14]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank14]:     outputs: BaseModelOutputWithPast = self.model(
[rank14]:                                        ^^^^^^^^^^^
[rank14]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank14]:     return self._call_impl(*args, **kwargs)
[rank14]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank14]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank14]:     return forward_call(*args, **kwargs)
[rank14]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank14]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank14]:     output = func(self, *args, **kwargs)
[rank14]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank14]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 519, in forward
[rank14]:     causal_mask = self._update_causal_mask(
[rank14]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank14]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 591, in _update_causal_mask
[rank14]:     raise ValueError(
[rank14]: ValueError: You are attempting to perform batched generation with padding_side='right' this may lead to unexpected behaviour for Flash Attention version of Qwen2. Make sure to  call `tokenizer.padding_side  = 'left'` before tokenizing the input. 
[rank21]: Traceback (most recent call last):
[rank21]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 525, in <module>
[rank21]:     main()
[rank21]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 495, in main
[rank21]:     llm.api.finetune(
[rank21]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank21]:     return train(
[rank21]:            ^^^^^^
[rank21]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank21]:     trainer.fit(model, data)
[rank21]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank21]:     call._call_and_handle_interrupt(
[rank21]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank21]:     return trainer_fn(*args, **kwargs)
[rank21]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank21]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank21]:     self._run(model, ckpt_path=ckpt_path)
[rank21]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank21]:     results = self._run_stage()
[rank21]:               ^^^^^^^^^^^^^^^^^
[rank21]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank21]:     self.fit_loop.run()
[rank21]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank21]:     self.advance()
[rank21]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank21]:     self.epoch_loop.run(self._data_fetcher)
[rank21]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank21]:     self.advance(data_fetcher)
[rank21]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank21]:     super().advance(data_fetcher)
[rank21]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank21]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank21]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank21]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 183, in run
[rank21]:     closure()
[rank21]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank21]:     self._result = self.closure(*args, **kwargs)
[rank21]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank21]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank21]:     return func(*args, **kwargs)
[rank21]:            ^^^^^^^^^^^^^^^^^^^^^
[rank21]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank21]:     step_output = self._step_fn()
[rank21]:                   ^^^^^^^^^^^^^^^
[rank21]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank21]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank21]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank21]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank21]:     output = fn(*args, **kwargs)
[rank21]:              ^^^^^^^^^^^^^^^^^^^
[rank21]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank21]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank21]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank21]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank21]:     outputs = self.forward(batch)
[rank21]:               ^^^^^^^^^^^^^^^^^^^
[rank21]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank21]:     return self.model(**batch)
[rank21]:            ^^^^^^^^^^^^^^^^^^^
[rank21]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank21]:     return self._call_impl(*args, **kwargs)
[rank21]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank21]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank21]:     return inner()
[rank21]:            ^^^^^^^
[rank21]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank21]:     result = forward_call(*args, **kwargs)
[rank21]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank21]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank21]:     output = func(self, *args, **kwargs)
[rank21]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank21]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank21]:     return func(*args, **kwargs)
[rank21]:            ^^^^^^^^^^^^^^^^^^^^^
[rank21]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank21]:     outputs: BaseModelOutputWithPast = self.model(
[rank21]:                                        ^^^^^^^^^^^
[rank21]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank21]:     return self._call_impl(*args, **kwargs)
[rank21]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank21]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank21]:     return forward_call(*args, **kwargs)
[rank21]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank21]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank21]:     output = func(self, *args, **kwargs)
[rank21]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank21]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 519, in forward
[rank21]:     causal_mask = self._update_causal_mask(
[rank21]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank21]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 591, in _update_causal_mask
[rank21]:     raise ValueError(
[rank21]: ValueError: You are attempting to perform batched generation with padding_side='right' this may lead to unexpected behaviour for Flash Attention version of Qwen2. Make sure to  call `tokenizer.padding_side  = 'left'` before tokenizing the input. 
[rank45]: Traceback (most recent call last):
[rank45]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 525, in <module>
[rank45]:     main()
[rank45]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 495, in main
[rank45]:     llm.api.finetune(
[rank45]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank45]:     return train(
[rank45]:            ^^^^^^
[rank45]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank45]:     trainer.fit(model, data)
[rank45]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank45]:     call._call_and_handle_interrupt(
[rank45]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank45]:     return trainer_fn(*args, **kwargs)
[rank45]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank45]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank45]:     self._run(model, ckpt_path=ckpt_path)
[rank45]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank45]:     results = self._run_stage()
[rank45]:               ^^^^^^^^^^^^^^^^^
[rank45]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank45]:     self.fit_loop.run()
[rank45]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank45]:     self.advance()
[rank45]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank45]:     self.epoch_loop.run(self._data_fetcher)
[rank45]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank45]:     self.advance(data_fetcher)
[rank45]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank45]:     super().advance(data_fetcher)
[rank45]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank45]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank45]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank45]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 183, in run
[rank45]:     closure()
[rank45]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank45]:     self._result = self.closure(*args, **kwargs)
[rank45]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank45]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank45]:     return func(*args, **kwargs)
[rank45]:            ^^^^^^^^^^^^^^^^^^^^^
[rank45]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank45]:     step_output = self._step_fn()
[rank45]:                   ^^^^^^^^^^^^^^^
[rank45]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank45]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank45]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank45]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank45]:     output = fn(*args, **kwargs)
[rank45]:              ^^^^^^^^^^^^^^^^^^^
[rank45]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank45]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank45]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank45]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank45]:     outputs = self.forward(batch)
[rank45]:               ^^^^^^^^^^^^^^^^^^^
[rank45]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank45]:     return self.model(**batch)
[rank45]:            ^^^^^^^^^^^^^^^^^^^
[rank45]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank45]:     return self._call_impl(*args, **kwargs)
[rank45]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank45]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank45]:     return inner()
[rank45]:            ^^^^^^^
[rank45]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank45]:     result = forward_call(*args, **kwargs)
[rank45]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank45]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank45]:     output = func(self, *args, **kwargs)
[rank45]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank45]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank45]:     return func(*args, **kwargs)
[rank45]:            ^^^^^^^^^^^^^^^^^^^^^
[rank45]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank45]:     outputs: BaseModelOutputWithPast = self.model(
[rank45]:                                        ^^^^^^^^^^^
[rank45]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank45]:     return self._call_impl(*args, **kwargs)
[rank45]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank45]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank45]:     return forward_call(*args, **kwargs)
[rank45]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank45]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank45]:     output = func(self, *args, **kwargs)
[rank45]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank45]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 519, in forward
[rank45]:     causal_mask = self._update_causal_mask(
[rank45]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank45]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 591, in _update_causal_mask
[rank45]:     raise ValueError(
[rank45]: ValueError: You are attempting to perform batched generation with padding_side='right' this may lead to unexpected behaviour for Flash Attention version of Qwen2. Make sure to  call `tokenizer.padding_side  = 'left'` before tokenizing the input. 
[rank23]: Traceback (most recent call last):
[rank23]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 525, in <module>
[rank23]:     main()
[rank23]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 495, in main
[rank23]:     llm.api.finetune(
[rank23]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank23]:     return train(
[rank23]:            ^^^^^^
[rank23]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank23]:     trainer.fit(model, data)
[rank23]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank23]:     call._call_and_handle_interrupt(
[rank23]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank23]:     return trainer_fn(*args, **kwargs)
[rank23]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank23]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank23]:     self._run(model, ckpt_path=ckpt_path)
[rank23]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank23]:     results = self._run_stage()
[rank23]:               ^^^^^^^^^^^^^^^^^
[rank23]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank23]:     self.fit_loop.run()
[rank23]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank23]:     self.advance()
[rank23]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank23]:     self.epoch_loop.run(self._data_fetcher)
[rank23]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank23]:     self.advance(data_fetcher)
[rank23]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank23]:     super().advance(data_fetcher)
[rank23]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank23]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank23]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank23]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 183, in run
[rank23]:     closure()
[rank23]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank23]:     self._result = self.closure(*args, **kwargs)
[rank23]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank23]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank23]:     return func(*args, **kwargs)
[rank23]:            ^^^^^^^^^^^^^^^^^^^^^
[rank23]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank23]:     step_output = self._step_fn()
[rank23]:                   ^^^^^^^^^^^^^^^
[rank23]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank23]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank23]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank23]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank23]:     output = fn(*args, **kwargs)
[rank23]:              ^^^^^^^^^^^^^^^^^^^
[rank23]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank23]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank23]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank23]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank23]:     outputs = self.forward(batch)
[rank23]:               ^^^^^^^^^^^^^^^^^^^
[rank23]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank23]:     return self.model(**batch)
[rank23]:            ^^^^^^^^^^^^^^^^^^^
[rank23]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank23]:     return self._call_impl(*args, **kwargs)
[rank23]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank23]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank23]:     return inner()
[rank23]:            ^^^^^^^
[rank23]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank23]:     result = forward_call(*args, **kwargs)
[rank23]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank23]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank23]:     output = func(self, *args, **kwargs)
[rank23]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank23]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank23]:     return func(*args, **kwargs)
[rank23]:            ^^^^^^^^^^^^^^^^^^^^^
[rank23]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank23]:     outputs: BaseModelOutputWithPast = self.model(
[rank23]:                                        ^^^^^^^^^^^
[rank23]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank23]:     return self._call_impl(*args, **kwargs)
[rank23]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank23]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank23]:     return forward_call(*args, **kwargs)
[rank23]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank23]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank23]:     output = func(self, *args, **kwargs)
[rank23]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank23]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 519, in forward
[rank23]:     causal_mask = self._update_causal_mask(
[rank23]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank23]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 591, in _update_causal_mask
[rank23]:     raise ValueError(
[rank23]: ValueError: You are attempting to perform batched generation with padding_side='right' this may lead to unexpected behaviour for Flash Attention version of Qwen2. Make sure to  call `tokenizer.padding_side  = 'left'` before tokenizing the input. 
[rank22]: Traceback (most recent call last):
[rank22]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 525, in <module>
[rank22]:     main()
[rank22]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 495, in main
[rank22]:     llm.api.finetune(
[rank22]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank22]:     return train(
[rank22]:            ^^^^^^
[rank22]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank22]:     trainer.fit(model, data)
[rank22]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank22]:     call._call_and_handle_interrupt(
[rank22]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank22]:     return trainer_fn(*args, **kwargs)
[rank22]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank22]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank22]:     self._run(model, ckpt_path=ckpt_path)
[rank22]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank22]:     results = self._run_stage()
[rank22]:               ^^^^^^^^^^^^^^^^^
[rank22]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank22]:     self.fit_loop.run()
[rank22]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank22]:     self.advance()
[rank22]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank22]:     self.epoch_loop.run(self._data_fetcher)
[rank22]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank22]:     self.advance(data_fetcher)
[rank22]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank22]:     super().advance(data_fetcher)
[rank22]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank22]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank22]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank22]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 183, in run
[rank22]:     closure()
[rank22]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank22]:     self._result = self.closure(*args, **kwargs)
[rank22]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank42]: Traceback (most recent call last):
[rank42]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 525, in <module>
[rank42]:     main()
[rank42]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 495, in main
[rank42]:     llm.api.finetune(
[rank42]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank42]:     return train(
[rank42]:            ^^^^^^
[rank42]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank42]:     trainer.fit(model, data)
[rank42]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank42]:     call._call_and_handle_interrupt(
[rank42]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank42]:     return trainer_fn(*args, **kwargs)
[rank42]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank42]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank42]:     self._run(model, ckpt_path=ckpt_path)
[rank42]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank42]:     results = self._run_stage()
[rank42]:               ^^^^^^^^^^^^^^^^^
[rank42]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank42]:     self.fit_loop.run()
[rank22]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank22]:     return func(*args, **kwargs)
[rank22]:            ^^^^^^^^^^^^^^^^^^^^^
[rank42]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank42]:     self.advance()
[rank42]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank42]:     self.epoch_loop.run(self._data_fetcher)
[rank42]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank42]:     self.advance(data_fetcher)
[rank42]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank42]:     super().advance(data_fetcher)
[rank22]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank22]:     step_output = self._step_fn()
[rank22]:                   ^^^^^^^^^^^^^^^
[rank22]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank22]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank22]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank22]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank22]:     output = fn(*args, **kwargs)
[rank22]:              ^^^^^^^^^^^^^^^^^^^
[rank42]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank42]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank42]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank42]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 183, in run
[rank42]:     closure()
[rank42]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank42]:     self._result = self.closure(*args, **kwargs)
[rank42]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank22]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank22]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank22]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank22]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank22]:     outputs = self.forward(batch)
[rank22]:               ^^^^^^^^^^^^^^^^^^^
[rank22]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank22]:     return self.model(**batch)
[rank22]:            ^^^^^^^^^^^^^^^^^^^
[rank22]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank22]:     return self._call_impl(*args, **kwargs)
[rank22]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank22]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank22]:     return inner()
[rank22]:            ^^^^^^^
[rank22]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank22]:     result = forward_call(*args, **kwargs)
[rank22]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank22]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank22]:     output = func(self, *args, **kwargs)
[rank42]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank42]:     return func(*args, **kwargs)
[rank42]:            ^^^^^^^^^^^^^^^^^^^^^
[rank22]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank22]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank22]:     return func(*args, **kwargs)
[rank22]:            ^^^^^^^^^^^^^^^^^^^^^
[rank22]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank22]:     outputs: BaseModelOutputWithPast = self.model(
[rank22]:                                        ^^^^^^^^^^^
[rank22]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank22]:     return self._call_impl(*args, **kwargs)
[rank22]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank42]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank42]:     step_output = self._step_fn()
[rank42]:                   ^^^^^^^^^^^^^^^
[rank42]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank42]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank42]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank42]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank42]:     output = fn(*args, **kwargs)
[rank42]:              ^^^^^^^^^^^^^^^^^^^
[rank22]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank22]:     return forward_call(*args, **kwargs)
[rank22]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank42]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank42]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank42]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank42]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank42]:     outputs = self.forward(batch)
[rank42]:               ^^^^^^^^^^^^^^^^^^^
[rank42]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank42]:     return self.model(**batch)
[rank42]:            ^^^^^^^^^^^^^^^^^^^
[rank22]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank22]:     output = func(self, *args, **kwargs)
[rank22]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank22]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 519, in forward
[rank22]:     causal_mask = self._update_causal_mask(
[rank22]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank22]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 591, in _update_causal_mask
[rank22]:     raise ValueError(
[rank42]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank42]:     return self._call_impl(*args, **kwargs)
[rank42]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank42]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank42]:     return inner()
[rank42]:            ^^^^^^^
[rank42]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank42]:     result = forward_call(*args, **kwargs)
[rank42]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank42]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank42]:     output = func(self, *args, **kwargs)
[rank22]: ValueError: You are attempting to perform batched generation with padding_side='right' this may lead to unexpected behaviour for Flash Attention version of Qwen2. Make sure to  call `tokenizer.padding_side  = 'left'` before tokenizing the input. 
[rank42]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank42]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank42]:     return func(*args, **kwargs)
[rank42]:            ^^^^^^^^^^^^^^^^^^^^^
[rank42]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank42]:     outputs: BaseModelOutputWithPast = self.model(
[rank42]:                                        ^^^^^^^^^^^
[rank42]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank42]:     return self._call_impl(*args, **kwargs)
[rank42]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank42]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank42]:     return forward_call(*args, **kwargs)
[rank42]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank42]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank42]:     output = func(self, *args, **kwargs)
[rank42]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank42]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 519, in forward
[rank42]:     causal_mask = self._update_causal_mask(
[rank42]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank42]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 591, in _update_causal_mask
[rank42]:     raise ValueError(
[rank42]: ValueError: You are attempting to perform batched generation with padding_side='right' this may lead to unexpected behaviour for Flash Attention version of Qwen2. Make sure to  call `tokenizer.padding_side  = 'left'` before tokenizing the input. 
[rank51]: Traceback (most recent call last):
[rank51]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 525, in <module>
[rank51]:     main()
[rank51]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 495, in main
[rank51]:     llm.api.finetune(
[rank51]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank51]:     return train(
[rank51]:            ^^^^^^
[rank51]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank51]:     trainer.fit(model, data)
[rank51]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank51]:     call._call_and_handle_interrupt(
[rank51]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank51]:     return trainer_fn(*args, **kwargs)
[rank51]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank51]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank51]:     self._run(model, ckpt_path=ckpt_path)
[rank51]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank51]:     results = self._run_stage()
[rank51]:               ^^^^^^^^^^^^^^^^^
[rank51]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank51]:     self.fit_loop.run()
[rank51]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank51]:     self.advance()
[rank51]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank51]:     self.epoch_loop.run(self._data_fetcher)
[rank51]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank51]:     self.advance(data_fetcher)
[rank51]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank51]:     super().advance(data_fetcher)
[rank51]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank51]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank51]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank51]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 183, in run
[rank51]:     closure()
[rank51]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank51]:     self._result = self.closure(*args, **kwargs)
[rank51]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank51]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank51]:     return func(*args, **kwargs)
[rank51]:            ^^^^^^^^^^^^^^^^^^^^^
[rank51]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank51]:     step_output = self._step_fn()
[rank51]:                   ^^^^^^^^^^^^^^^
[rank51]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank51]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank51]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank51]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank51]:     output = fn(*args, **kwargs)
[rank51]:              ^^^^^^^^^^^^^^^^^^^
[rank51]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank51]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank51]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank51]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank51]:     outputs = self.forward(batch)
[rank51]:               ^^^^^^^^^^^^^^^^^^^
[rank51]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank51]:     return self.model(**batch)
[rank51]:            ^^^^^^^^^^^^^^^^^^^
[rank51]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank51]:     return self._call_impl(*args, **kwargs)
[rank51]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank51]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank51]:     return inner()
[rank51]:            ^^^^^^^
[rank51]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank51]:     result = forward_call(*args, **kwargs)
[rank51]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank51]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank51]:     output = func(self, *args, **kwargs)
[rank51]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank51]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank51]:     return func(*args, **kwargs)
[rank51]:            ^^^^^^^^^^^^^^^^^^^^^
[rank51]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank51]:     outputs: BaseModelOutputWithPast = self.model(
[rank51]:                                        ^^^^^^^^^^^
[rank51]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank51]:     return self._call_impl(*args, **kwargs)
[rank51]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank51]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank51]:     return forward_call(*args, **kwargs)
[rank51]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank51]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank51]:     output = func(self, *args, **kwargs)
[rank51]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank51]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 519, in forward
[rank51]:     causal_mask = self._update_causal_mask(
[rank51]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank51]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 591, in _update_causal_mask
[rank51]:     raise ValueError(
[rank51]: ValueError: You are attempting to perform batched generation with padding_side='right' this may lead to unexpected behaviour for Flash Attention version of Qwen2. Make sure to  call `tokenizer.padding_side  = 'left'` before tokenizing the input. 
[rank48]: Traceback (most recent call last):
[rank48]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 525, in <module>
[rank48]:     main()
[rank48]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 495, in main
[rank48]:     llm.api.finetune(
[rank48]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank48]:     return train(
[rank48]:            ^^^^^^
[rank48]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank48]:     trainer.fit(model, data)
[rank48]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank48]:     call._call_and_handle_interrupt(
[rank48]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank48]:     return trainer_fn(*args, **kwargs)
[rank48]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank48]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank48]:     self._run(model, ckpt_path=ckpt_path)
[rank48]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank48]:     results = self._run_stage()
[rank48]:               ^^^^^^^^^^^^^^^^^
[rank48]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank48]:     self.fit_loop.run()
[rank48]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank48]:     self.advance()
[rank48]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank48]:     self.epoch_loop.run(self._data_fetcher)
[rank48]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank48]:     self.advance(data_fetcher)
[rank48]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank48]:     super().advance(data_fetcher)
[rank48]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank48]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank48]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank48]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 183, in run
[rank48]:     closure()
[rank48]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank48]:     self._result = self.closure(*args, **kwargs)
[rank48]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank48]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank48]:     return func(*args, **kwargs)
[rank48]:            ^^^^^^^^^^^^^^^^^^^^^
[rank48]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank48]:     step_output = self._step_fn()
[rank48]:                   ^^^^^^^^^^^^^^^
[rank48]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank48]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank48]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank48]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank48]:     output = fn(*args, **kwargs)
[rank48]:              ^^^^^^^^^^^^^^^^^^^
[rank48]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank48]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank48]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank48]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank48]:     outputs = self.forward(batch)
[rank48]:               ^^^^^^^^^^^^^^^^^^^
[rank48]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank48]:     return self.model(**batch)
[rank48]:            ^^^^^^^^^^^^^^^^^^^
[rank48]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank48]:     return self._call_impl(*args, **kwargs)
[rank48]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank48]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank48]:     return inner()
[rank48]:            ^^^^^^^
[rank48]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank48]:     result = forward_call(*args, **kwargs)
[rank48]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank48]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank48]:     output = func(self, *args, **kwargs)
[rank48]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank48]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank48]:     return func(*args, **kwargs)
[rank48]:            ^^^^^^^^^^^^^^^^^^^^^
[rank48]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank48]:     outputs: BaseModelOutputWithPast = self.model(
[rank48]:                                        ^^^^^^^^^^^
[rank48]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank48]:     return self._call_impl(*args, **kwargs)
[rank48]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank48]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank48]:     return forward_call(*args, **kwargs)
[rank48]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank48]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank48]:     output = func(self, *args, **kwargs)
[rank48]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank48]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 519, in forward
[rank48]:     causal_mask = self._update_causal_mask(
[rank48]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank48]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 591, in _update_causal_mask
[rank48]:     raise ValueError(
[rank48]: ValueError: You are attempting to perform batched generation with padding_side='right' this may lead to unexpected behaviour for Flash Attention version of Qwen2. Make sure to  call `tokenizer.padding_side  = 'left'` before tokenizing the input. 
[rank49]: Traceback (most recent call last):
[rank49]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 525, in <module>
[rank49]:     main()
[rank49]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 495, in main
[rank49]:     llm.api.finetune(
[rank49]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank49]:     return train(
[rank49]:            ^^^^^^
[rank49]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank49]:     trainer.fit(model, data)
[rank49]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank49]:     call._call_and_handle_interrupt(
[rank49]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank49]:     return trainer_fn(*args, **kwargs)
[rank49]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank49]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank49]:     self._run(model, ckpt_path=ckpt_path)
[rank49]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank49]:     results = self._run_stage()
[rank49]:               ^^^^^^^^^^^^^^^^^
[rank49]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank49]:     self.fit_loop.run()
[rank49]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank49]:     self.advance()
[rank49]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank49]:     self.epoch_loop.run(self._data_fetcher)
[rank49]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank49]:     self.advance(data_fetcher)
[rank49]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank49]:     super().advance(data_fetcher)
[rank49]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank49]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank49]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank49]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 183, in run
[rank49]:     closure()
[rank49]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank49]:     self._result = self.closure(*args, **kwargs)
[rank49]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank49]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank49]:     return func(*args, **kwargs)
[rank49]:            ^^^^^^^^^^^^^^^^^^^^^
[rank49]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank49]:     step_output = self._step_fn()
[rank49]:                   ^^^^^^^^^^^^^^^
[rank49]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank49]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank49]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank49]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank49]:     output = fn(*args, **kwargs)
[rank49]:              ^^^^^^^^^^^^^^^^^^^
[rank49]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank49]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank49]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank49]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank49]:     outputs = self.forward(batch)
[rank49]:               ^^^^^^^^^^^^^^^^^^^
[rank49]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank49]:     return self.model(**batch)
[rank49]:            ^^^^^^^^^^^^^^^^^^^
[rank49]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank49]:     return self._call_impl(*args, **kwargs)
[rank49]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank49]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank49]:     return inner()
[rank49]:            ^^^^^^^
[rank49]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank49]:     result = forward_call(*args, **kwargs)
[rank49]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank49]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank49]:     output = func(self, *args, **kwargs)
[rank49]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank49]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank49]:     return func(*args, **kwargs)
[rank49]:            ^^^^^^^^^^^^^^^^^^^^^
[rank49]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank49]:     outputs: BaseModelOutputWithPast = self.model(
[rank49]:                                        ^^^^^^^^^^^
[rank49]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank49]:     return self._call_impl(*args, **kwargs)
[rank49]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank49]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank49]:     return forward_call(*args, **kwargs)
[rank49]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank49]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank49]:     output = func(self, *args, **kwargs)
[rank49]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank49]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 519, in forward
[rank49]:     causal_mask = self._update_causal_mask(
[rank49]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank49]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 591, in _update_causal_mask
[rank49]:     raise ValueError(
[rank49]: ValueError: You are attempting to perform batched generation with padding_side='right' this may lead to unexpected behaviour for Flash Attention version of Qwen2. Make sure to  call `tokenizer.padding_side  = 'left'` before tokenizing the input. 
[rank50]: Traceback (most recent call last):
[rank50]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 525, in <module>
[rank50]:     main()
[rank50]:   File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_TPFSDP2.py", line 495, in main
[rank50]:     llm.api.finetune(
[rank50]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 236, in finetune
[rank50]:     return train(
[rank50]:            ^^^^^^
[rank50]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/api.py", line 135, in train
[rank50]:     trainer.fit(model, data)
[rank50]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank50]:     call._call_and_handle_interrupt(
[rank50]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank50]:     return trainer_fn(*args, **kwargs)
[rank50]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank50]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank50]:     self._run(model, ckpt_path=ckpt_path)
[rank50]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank50]:     results = self._run_stage()
[rank50]:               ^^^^^^^^^^^^^^^^^
[rank50]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank50]:     self.fit_loop.run()
[rank50]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank50]:     self.advance()
[rank50]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank50]:     self.epoch_loop.run(self._data_fetcher)
[rank50]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank50]:     self.advance(data_fetcher)
[rank50]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/trainer.py", line 47, in advance
[rank50]:     super().advance(data_fetcher)
[rank50]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank50]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank50]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank50]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 183, in run
[rank50]:     closure()
[rank50]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank50]:     self._result = self.closure(*args, **kwargs)
[rank50]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank50]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank50]:     return func(*args, **kwargs)
[rank50]:            ^^^^^^^^^^^^^^^^^^^^^
[rank50]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank50]:     step_output = self._step_fn()
[rank50]:                   ^^^^^^^^^^^^^^^
[rank50]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank50]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank50]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank50]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank50]:     output = fn(*args, **kwargs)
[rank50]:              ^^^^^^^^^^^^^^^^^^^
[rank50]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/lightning/pytorch/strategies/fsdp2_strategy.py", line 406, in training_step
[rank50]:     loss = self.lightning_module.training_step(batch, batch_idx)
[rank50]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank50]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 386, in training_step
[rank50]:     outputs = self.forward(batch)
[rank50]:               ^^^^^^^^^^^^^^^^^^^
[rank50]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/nemo/collections/llm/gpt/model/hf_auto_model_for_causal_lm.py", line 300, in forward
[rank50]:     return self.model(**batch)
[rank50]:            ^^^^^^^^^^^^^^^^^^^
[rank50]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank50]:     return self._call_impl(*args, **kwargs)
[rank50]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank50]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank50]:     return inner()
[rank50]:            ^^^^^^^
[rank50]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank50]:     result = forward_call(*args, **kwargs)
[rank50]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank50]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank50]:     output = func(self, *args, **kwargs)
[rank50]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank50]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank50]:     return func(*args, **kwargs)
[rank50]:            ^^^^^^^^^^^^^^^^^^^^^
[rank50]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank50]:     outputs: BaseModelOutputWithPast = self.model(
[rank50]:                                        ^^^^^^^^^^^
[rank50]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank50]:     return self._call_impl(*args, **kwargs)
[rank50]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank50]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank50]:     return forward_call(*args, **kwargs)
[rank50]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank50]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank50]:     output = func(self, *args, **kwargs)
[rank50]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank50]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 519, in forward
[rank50]:     causal_mask = self._update_causal_mask(
[rank50]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank50]:   File "/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 591, in _update_causal_mask
[rank50]:     raise ValueError(
[rank50]: ValueError: You are attempting to perform batched generation with padding_side='right' this may lead to unexpected behaviour for Flash Attention version of Qwen2. Make sure to  call `tokenizer.padding_side  = 'left'` before tokenizing the input. 
[W1109 17:38:07.183625535 ProcessGroup.cpp:266] Warning: At the time of process termination, there are still 1 unwaited collective calls. Please review your program to ensure that:
1. c10d_functional.wait_tensor() is invoked on all tensors returned from c10d_functional collective,
2. c10d_functional.wait_tensor() is invoked on all output tensors of async_op=True torch.distributed collective called under `with allow_inflight_collective_as_graph_input_ctx():`,
before the output tensors of the collective are used. (function ~WorkRegistry)
[W1109 17:38:07.183953974 ProcessGroup.cpp:266] Warning: At the time of process termination, there are still 1 unwaited collective calls. Please review your program to ensure that:
1. c10d_functional.wait_tensor() is invoked on all tensors returned from c10d_functional collective,
2. c10d_functional.wait_tensor() is invoked on all output tensors of async_op=True torch.distributed collective called under `with allow_inflight_collective_as_graph_input_ctx():`,
before the output tensors of the collective are used. (function ~WorkRegistry)
[W1109 17:38:07.184338758 ProcessGroup.cpp:266] Warning: At the time of process termination, there are still 1 unwaited collective calls. Please review your program to ensure that:
1. c10d_functional.wait_tensor() is invoked on all tensors returned from c10d_functional collective,
2. c10d_functional.wait_tensor() is invoked on all output tensors of async_op=True torch.distributed collective called under `with allow_inflight_collective_as_graph_input_ctx():`,
before the output tensors of the collective are used. (function ~WorkRegistry)
[W1109 17:38:07.184556711 ProcessGroup.cpp:266] Warning: At the time of process termination, there are still 1 unwaited collective calls. Please review your program to ensure that:
1. c10d_functional.wait_tensor() is invoked on all tensors returned from c10d_functional collective,
2. c10d_functional.wait_tensor() is invoked on all output tensors of async_op=True torch.distributed collective called under `with allow_inflight_collective_as_graph_input_ctx():`,
before the output tensors of the collective are used. (function ~WorkRegistry)
[W1109 17:38:07.463178078 ProcessGroup.cpp:266] Warning: At the time of process termination, there are still 1 unwaited collective calls. Please review your program to ensure that:
1. c10d_functional.wait_tensor() is invoked on all tensors returned from c10d_functional collective,
2. c10d_functional.wait_tensor() is invoked on all output tensors of async_op=True torch.distributed collective called under `with allow_inflight_collective_as_graph_input_ctx():`,
before the output tensors of the collective are used. (function ~WorkRegistry)
[W1109 17:38:07.463241361 ProcessGroup.cpp:266] Warning: At the time of process termination, there are still 1 unwaited collective calls. Please review your program to ensure that:
1. c10d_functional.wait_tensor() is invoked on all tensors returned from c10d_functional collective,
2. c10d_functional.wait_tensor() is invoked on all output tensors of async_op=True torch.distributed collective called under `with allow_inflight_collective_as_graph_input_ctx():`,
before the output tensors of the collective are used. (function ~WorkRegistry)
[W1109 17:38:07.464127002 ProcessGroup.cpp:266] Warning: At the time of process termination, there are still 1 unwaited collective calls. Please review your program to ensure that:
1. c10d_functional.wait_tensor() is invoked on all tensors returned from c10d_functional collective,
2. c10d_functional.wait_tensor() is invoked on all output tensors of async_op=True torch.distributed collective called under `with allow_inflight_collective_as_graph_input_ctx():`,
before the output tensors of the collective are used. (function ~WorkRegistry)
[W1109 17:38:07.464655155 ProcessGroup.cpp:266] Warning: At the time of process termination, there are still 1 unwaited collective calls. Please review your program to ensure that:
1. c10d_functional.wait_tensor() is invoked on all tensors returned from c10d_functional collective,
2. c10d_functional.wait_tensor() is invoked on all output tensors of async_op=True torch.distributed collective called under `with allow_inflight_collective_as_graph_input_ctx():`,
before the output tensors of the collective are used. (function ~WorkRegistry)
[W1109 17:38:07.167910066 ProcessGroup.cpp:266] Warning: At the time of process termination, there are still 1 unwaited collective calls. Please review your program to ensure that:
1. c10d_functional.wait_tensor() is invoked on all tensors returned from c10d_functional collective,
2. c10d_functional.wait_tensor() is invoked on all output tensors of async_op=True torch.distributed collective called under `with allow_inflight_collective_as_graph_input_ctx():`,
before the output tensors of the collective are used. (function ~WorkRegistry)
[W1109 17:38:07.168220984 ProcessGroup.cpp:266] Warning: At the time of process termination, there are still 1 unwaited collective calls. Please review your program to ensure that:
1. c10d_functional.wait_tensor() is invoked on all tensors returned from c10d_functional collective,
2. c10d_functional.wait_tensor() is invoked on all output tensors of async_op=True torch.distributed collective called under `with allow_inflight_collective_as_graph_input_ctx():`,
before the output tensors of the collective are used. (function ~WorkRegistry)
[W1109 17:38:07.168581285 ProcessGroup.cpp:266] Warning: At the time of process termination, there are still 1 unwaited collective calls. Please review your program to ensure that:
1. c10d_functional.wait_tensor() is invoked on all tensors returned from c10d_functional collective,
2. c10d_functional.wait_tensor() is invoked on all output tensors of async_op=True torch.distributed collective called under `with allow_inflight_collective_as_graph_input_ctx():`,
before the output tensors of the collective are used. (function ~WorkRegistry)
[W1109 17:38:07.172700316 ProcessGroup.cpp:266] Warning: At the time of process termination, there are still 1 unwaited collective calls. Please review your program to ensure that:
1. c10d_functional.wait_tensor() is invoked on all tensors returned from c10d_functional collective,
2. c10d_functional.wait_tensor() is invoked on all output tensors of async_op=True torch.distributed collective called under `with allow_inflight_collective_as_graph_input_ctx():`,
before the output tensors of the collective are used. (function ~WorkRegistry)
[W1109 17:38:07.208822602 ProcessGroup.cpp:266] Warning: At the time of process termination, there are still 1 unwaited collective calls. Please review your program to ensure that:
1. c10d_functional.wait_tensor() is invoked on all tensors returned from c10d_functional collective,
2. c10d_functional.wait_tensor() is invoked on all output tensors of async_op=True torch.distributed collective called under `with allow_inflight_collective_as_graph_input_ctx():`,
before the output tensors of the collective are used. (function ~WorkRegistry)
[W1109 17:38:07.209642359 ProcessGroup.cpp:266] Warning: At the time of process termination, there are still 1 unwaited collective calls. Please review your program to ensure that:
1. c10d_functional.wait_tensor() is invoked on all tensors returned from c10d_functional collective,
2. c10d_functional.wait_tensor() is invoked on all output tensors of async_op=True torch.distributed collective called under `with allow_inflight_collective_as_graph_input_ctx():`,
before the output tensors of the collective are used. (function ~WorkRegistry)
[W1109 17:38:07.209826745 ProcessGroup.cpp:266] Warning: At the time of process termination, there are still 1 unwaited collective calls. Please review your program to ensure that:
1. c10d_functional.wait_tensor() is invoked on all tensors returned from c10d_functional collective,
2. c10d_functional.wait_tensor() is invoked on all output tensors of async_op=True torch.distributed collective called under `with allow_inflight_collective_as_graph_input_ctx():`,
before the output tensors of the collective are used. (function ~WorkRegistry)
[W1109 17:38:07.209878107 ProcessGroup.cpp:266] Warning: At the time of process termination, there are still 1 unwaited collective calls. Please review your program to ensure that:
1. c10d_functional.wait_tensor() is invoked on all tensors returned from c10d_functional collective,
2. c10d_functional.wait_tensor() is invoked on all output tensors of async_op=True torch.distributed collective called under `with allow_inflight_collective_as_graph_input_ctx():`,
before the output tensors of the collective are used. (function ~WorkRegistry)
[W1109 17:38:07.222508514 ProcessGroup.cpp:266] Warning: At the time of process termination, there are still 1 unwaited collective calls. Please review your program to ensure that:
1. c10d_functional.wait_tensor() is invoked on all tensors returned from c10d_functional collective,
2. c10d_functional.wait_tensor() is invoked on all output tensors of async_op=True torch.distributed collective called under `with allow_inflight_collective_as_graph_input_ctx():`,
before the output tensors of the collective are used. (function ~WorkRegistry)
[W1109 17:38:07.222807895 ProcessGroup.cpp:266] Warning: At the time of process termination, there are still 1 unwaited collective calls. Please review your program to ensure that:
1. c10d_functional.wait_tensor() is invoked on all tensors returned from c10d_functional collective,
2. c10d_functional.wait_tensor() is invoked on all output tensors of async_op=True torch.distributed collective called under `with allow_inflight_collective_as_graph_input_ctx():`,
before the output tensors of the collective are used. (function ~WorkRegistry)
[W1109 17:38:07.223138355 ProcessGroup.cpp:266] Warning: At the time of process termination, there are still 1 unwaited collective calls. Please review your program to ensure that:
1. c10d_functional.wait_tensor() is invoked on all tensors returned from c10d_functional collective,
2. c10d_functional.wait_tensor() is invoked on all output tensors of async_op=True torch.distributed collective called under `with allow_inflight_collective_as_graph_input_ctx():`,
before the output tensors of the collective are used. (function ~WorkRegistry)
[W1109 17:38:07.223170016 ProcessGroup.cpp:266] Warning: At the time of process termination, there are still 1 unwaited collective calls. Please review your program to ensure that:
1. c10d_functional.wait_tensor() is invoked on all tensors returned from c10d_functional collective,
2. c10d_functional.wait_tensor() is invoked on all output tensors of async_op=True torch.distributed collective called under `with allow_inflight_collective_as_graph_input_ctx():`,
before the output tensors of the collective are used. (function ~WorkRegistry)
[W1109 17:38:07.318615197 ProcessGroup.cpp:266] Warning: At the time of process termination, there are still 1 unwaited collective calls. Please review your program to ensure that:
1. c10d_functional.wait_tensor() is invoked on all tensors returned from c10d_functional collective,
2. c10d_functional.wait_tensor() is invoked on all output tensors of async_op=True torch.distributed collective called under `with allow_inflight_collective_as_graph_input_ctx():`,
before the output tensors of the collective are used. (function ~WorkRegistry)
[W1109 17:38:07.319646954 ProcessGroup.cpp:266] Warning: At the time of process termination, there are still 1 unwaited collective calls. Please review your program to ensure that:
1. c10d_functional.wait_tensor() is invoked on all tensors returned from c10d_functional collective,
2. c10d_functional.wait_tensor() is invoked on all output tensors of async_op=True torch.distributed collective called under `with allow_inflight_collective_as_graph_input_ctx():`,
before the output tensors of the collective are used. (function ~WorkRegistry)
[W1109 17:38:07.319823633 ProcessGroup.cpp:266] Warning: At the time of process termination, there are still 1 unwaited collective calls. Please review your program to ensure that:
1. c10d_functional.wait_tensor() is invoked on all tensors returned from c10d_functional collective,
2. c10d_functional.wait_tensor() is invoked on all output tensors of async_op=True torch.distributed collective called under `with allow_inflight_collective_as_graph_input_ctx():`,
before the output tensors of the collective are used. (function ~WorkRegistry)
[W1109 17:38:07.320169847 ProcessGroup.cpp:266] Warning: At the time of process termination, there are still 1 unwaited collective calls. Please review your program to ensure that:
1. c10d_functional.wait_tensor() is invoked on all tensors returned from c10d_functional collective,
2. c10d_functional.wait_tensor() is invoked on all output tensors of async_op=True torch.distributed collective called under `with allow_inflight_collective_as_graph_input_ctx():`,
before the output tensors of the collective are used. (function ~WorkRegistry)
[W1109 17:38:07.462465903 ProcessGroup.cpp:266] Warning: At the time of process termination, there are still 1 unwaited collective calls. Please review your program to ensure that:
1. c10d_functional.wait_tensor() is invoked on all tensors returned from c10d_functional collective,
2. c10d_functional.wait_tensor() is invoked on all output tensors of async_op=True torch.distributed collective called under `with allow_inflight_collective_as_graph_input_ctx():`,
before the output tensors of the collective are used. (function ~WorkRegistry)
[W1109 17:38:07.462756774 ProcessGroup.cpp:266] Warning: At the time of process termination, there are still 1 unwaited collective calls. Please review your program to ensure that:
1. c10d_functional.wait_tensor() is invoked on all tensors returned from c10d_functional collective,
2. c10d_functional.wait_tensor() is invoked on all output tensors of async_op=True torch.distributed collective called under `with allow_inflight_collective_as_graph_input_ctx():`,
before the output tensors of the collective are used. (function ~WorkRegistry)
[W1109 17:38:07.462985505 ProcessGroup.cpp:266] Warning: At the time of process termination, there are still 1 unwaited collective calls. Please review your program to ensure that:
1. c10d_functional.wait_tensor() is invoked on all tensors returned from c10d_functional collective,
2. c10d_functional.wait_tensor() is invoked on all output tensors of async_op=True torch.distributed collective called under `with allow_inflight_collective_as_graph_input_ctx():`,
before the output tensors of the collective are used. (function ~WorkRegistry)
[W1109 17:38:07.463299322 ProcessGroup.cpp:266] Warning: At the time of process termination, there are still 1 unwaited collective calls. Please review your program to ensure that:
1. c10d_functional.wait_tensor() is invoked on all tensors returned from c10d_functional collective,
2. c10d_functional.wait_tensor() is invoked on all output tensors of async_op=True torch.distributed collective called under `with allow_inflight_collective_as_graph_input_ctx():`,
before the output tensors of the collective are used. (function ~WorkRegistry)
[W1109 17:38:07.118923517 ProcessGroup.cpp:266] Warning: At the time of process termination, there are still 1 unwaited collective calls. Please review your program to ensure that:
1. c10d_functional.wait_tensor() is invoked on all tensors returned from c10d_functional collective,
2. c10d_functional.wait_tensor() is invoked on all output tensors of async_op=True torch.distributed collective called under `with allow_inflight_collective_as_graph_input_ctx():`,
before the output tensors of the collective are used. (function ~WorkRegistry)
[W1109 17:38:07.119094277 ProcessGroup.cpp:266] Warning: At the time of process termination, there are still 1 unwaited collective calls. Please review your program to ensure that:
1. c10d_functional.wait_tensor() is invoked on all tensors returned from c10d_functional collective,
2. c10d_functional.wait_tensor() is invoked on all output tensors of async_op=True torch.distributed collective called under `with allow_inflight_collective_as_graph_input_ctx():`,
before the output tensors of the collective are used. (function ~WorkRegistry)
[W1109 17:38:07.119553913 ProcessGroup.cpp:266] Warning: At the time of process termination, there are still 1 unwaited collective calls. Please review your program to ensure that:
1. c10d_functional.wait_tensor() is invoked on all tensors returned from c10d_functional collective,
2. c10d_functional.wait_tensor() is invoked on all output tensors of async_op=True torch.distributed collective called under `with allow_inflight_collective_as_graph_input_ctx():`,
before the output tensors of the collective are used. (function ~WorkRegistry)
[W1109 17:38:07.119794130 ProcessGroup.cpp:266] Warning: At the time of process termination, there are still 1 unwaited collective calls. Please review your program to ensure that:
1. c10d_functional.wait_tensor() is invoked on all tensors returned from c10d_functional collective,
2. c10d_functional.wait_tensor() is invoked on all output tensors of async_op=True torch.distributed collective called under `with allow_inflight_collective_as_graph_input_ctx():`,
before the output tensors of the collective are used. (function ~WorkRegistry)
[W1109 17:38:08.688926259 ProcessGroup.cpp:266] Warning: At the time of process termination, there are still 1 unwaited collective calls. Please review your program to ensure that:
1. c10d_functional.wait_tensor() is invoked on all tensors returned from c10d_functional collective,
2. c10d_functional.wait_tensor() is invoked on all output tensors of async_op=True torch.distributed collective called under `with allow_inflight_collective_as_graph_input_ctx():`,
before the output tensors of the collective are used. (function ~WorkRegistry)
[W1109 17:38:08.689252960 ProcessGroup.cpp:266] Warning: At the time of process termination, there are still 1 unwaited collective calls. Please review your program to ensure that:
1. c10d_functional.wait_tensor() is invoked on all tensors returned from c10d_functional collective,
2. c10d_functional.wait_tensor() is invoked on all output tensors of async_op=True torch.distributed collective called under `with allow_inflight_collective_as_graph_input_ctx():`,
before the output tensors of the collective are used. (function ~WorkRegistry)
[W1109 17:38:08.689732458 ProcessGroup.cpp:266] Warning: At the time of process termination, there are still 1 unwaited collective calls. Please review your program to ensure that:
1. c10d_functional.wait_tensor() is invoked on all tensors returned from c10d_functional collective,
2. c10d_functional.wait_tensor() is invoked on all output tensors of async_op=True torch.distributed collective called under `with allow_inflight_collective_as_graph_input_ctx():`,
before the output tensors of the collective are used. (function ~WorkRegistry)
[W1109 17:38:08.690403138 ProcessGroup.cpp:266] Warning: At the time of process termination, there are still 1 unwaited collective calls. Please review your program to ensure that:
1. c10d_functional.wait_tensor() is invoked on all tensors returned from c10d_functional collective,
2. c10d_functional.wait_tensor() is invoked on all output tensors of async_op=True torch.distributed collective called under `with allow_inflight_collective_as_graph_input_ctx():`,
before the output tensors of the collective are used. (function ~WorkRegistry)
[W1109 17:38:08.762249912 ProcessGroup.cpp:266] Warning: At the time of process termination, there are still 1 unwaited collective calls. Please review your program to ensure that:
1. c10d_functional.wait_tensor() is invoked on all tensors returned from c10d_functional collective,
2. c10d_functional.wait_tensor() is invoked on all output tensors of async_op=True torch.distributed collective called under `with allow_inflight_collective_as_graph_input_ctx():`,
before the output tensors of the collective are used. (function ~WorkRegistry)
[W1109 17:38:08.762693415 ProcessGroup.cpp:266] Warning: At the time of process termination, there are still 1 unwaited collective calls. Please review your program to ensure that:
1. c10d_functional.wait_tensor() is invoked on all tensors returned from c10d_functional collective,
2. c10d_functional.wait_tensor() is invoked on all output tensors of async_op=True torch.distributed collective called under `with allow_inflight_collective_as_graph_input_ctx():`,
before the output tensors of the collective are used. (function ~WorkRegistry)
[W1109 17:38:08.763173195 ProcessGroup.cpp:266] Warning: At the time of process termination, there are still 1 unwaited collective calls. Please review your program to ensure that:
1. c10d_functional.wait_tensor() is invoked on all tensors returned from c10d_functional collective,
2. c10d_functional.wait_tensor() is invoked on all output tensors of async_op=True torch.distributed collective called under `with allow_inflight_collective_as_graph_input_ctx():`,
before the output tensors of the collective are used. (function ~WorkRegistry)
[W1109 17:38:08.774824033 ProcessGroup.cpp:266] Warning: At the time of process termination, there are still 1 unwaited collective calls. Please review your program to ensure that:
1. c10d_functional.wait_tensor() is invoked on all tensors returned from c10d_functional collective,
2. c10d_functional.wait_tensor() is invoked on all output tensors of async_op=True torch.distributed collective called under `with allow_inflight_collective_as_graph_input_ctx():`,
before the output tensors of the collective are used. (function ~WorkRegistry)
[W1109 17:38:08.718448852 ProcessGroup.cpp:266] Warning: At the time of process termination, there are still 1 unwaited collective calls. Please review your program to ensure that:
1. c10d_functional.wait_tensor() is invoked on all tensors returned from c10d_functional collective,
2. c10d_functional.wait_tensor() is invoked on all output tensors of async_op=True torch.distributed collective called under `with allow_inflight_collective_as_graph_input_ctx():`,
before the output tensors of the collective are used. (function ~WorkRegistry)
[W1109 17:38:08.719292094 ProcessGroup.cpp:266] Warning: At the time of process termination, there are still 1 unwaited collective calls. Please review your program to ensure that:
1. c10d_functional.wait_tensor() is invoked on all tensors returned from c10d_functional collective,
2. c10d_functional.wait_tensor() is invoked on all output tensors of async_op=True torch.distributed collective called under `with allow_inflight_collective_as_graph_input_ctx():`,
before the output tensors of the collective are used. (function ~WorkRegistry)
[W1109 17:38:08.719366864 ProcessGroup.cpp:266] Warning: At the time of process termination, there are still 1 unwaited collective calls. Please review your program to ensure that:
1. c10d_functional.wait_tensor() is invoked on all tensors returned from c10d_functional collective,
2. c10d_functional.wait_tensor() is invoked on all output tensors of async_op=True torch.distributed collective called under `with allow_inflight_collective_as_graph_input_ctx():`,
before the output tensors of the collective are used. (function ~WorkRegistry)
[W1109 17:38:08.719889954 ProcessGroup.cpp:266] Warning: At the time of process termination, there are still 1 unwaited collective calls. Please review your program to ensure that:
1. c10d_functional.wait_tensor() is invoked on all tensors returned from c10d_functional collective,
2. c10d_functional.wait_tensor() is invoked on all output tensors of async_op=True torch.distributed collective called under `with allow_inflight_collective_as_graph_input_ctx():`,
before the output tensors of the collective are used. (function ~WorkRegistry)
srun: error: jzxh159: tasks 36,38-39: Exited with exit code 1
srun: Terminating StepId=1545106.0
[W1109 17:38:08.777287946 ProcessGroup.cpp:266] Warning: At the time of process termination, there are still 1 unwaited collective calls. Please review your program to ensure that:
1. c10d_functional.wait_tensor() is invoked on all tensors returned from c10d_functional collective,
2. c10d_functional.wait_tensor() is invoked on all output tensors of async_op=True torch.distributed collective called under `with allow_inflight_collective_as_graph_input_ctx():`,
before the output tensors of the collective are used. (function ~WorkRegistry)
[W1109 17:38:08.777379278 ProcessGroup.cpp:266] Warning: At the time of process termination, there are still 1 unwaited collective calls. Please review your program to ensure that:
1. c10d_functional.wait_tensor() is invoked on all tensors returned from c10d_functional collective,
2. c10d_functional.wait_tensor() is invoked on all output tensors of async_op=True torch.distributed collective called under `with allow_inflight_collective_as_graph_input_ctx():`,
before the output tensors of the collective are used. (function ~WorkRegistry)
[W1109 17:38:08.777450478 ProcessGroup.cpp:266] Warning: At the time of process termination, there are still 1 unwaited collective calls. Please review your program to ensure that:
1. c10d_functional.wait_tensor() is invoked on all tensors returned from c10d_functional collective,
2. c10d_functional.wait_tensor() is invoked on all output tensors of async_op=True torch.distributed collective called under `with allow_inflight_collective_as_graph_input_ctx():`,
before the output tensors of the collective are used. (function ~WorkRegistry)
[W1109 17:38:08.777712579 ProcessGroup.cpp:266] Warning: At the time of process termination, there are still 1 unwaited collective calls. Please review your program to ensure that:
1. c10d_functional.wait_tensor() is invoked on all tensors returned from c10d_functional collective,
2. c10d_functional.wait_tensor() is invoked on all output tensors of async_op=True torch.distributed collective called under `with allow_inflight_collective_as_graph_input_ctx():`,
before the output tensors of the collective are used. (function ~WorkRegistry)
[W1109 17:38:08.514165138 ProcessGroup.cpp:266] Warning: At the time of process termination, there are still 1 unwaited collective calls. Please review your program to ensure that:
1. c10d_functional.wait_tensor() is invoked on all tensors returned from c10d_functional collective,
2. c10d_functional.wait_tensor() is invoked on all output tensors of async_op=True torch.distributed collective called under `with allow_inflight_collective_as_graph_input_ctx():`,
before the output tensors of the collective are used. (function ~WorkRegistry)
[W1109 17:38:08.515025697 ProcessGroup.cpp:266] Warning: At the time of process termination, there are still 1 unwaited collective calls. Please review your program to ensure that:
1. c10d_functional.wait_tensor() is invoked on all tensors returned from c10d_functional collective,
2. c10d_functional.wait_tensor() is invoked on all output tensors of async_op=True torch.distributed collective called under `with allow_inflight_collective_as_graph_input_ctx():`,
before the output tensors of the collective are used. (function ~WorkRegistry)
[W1109 17:38:08.515566865 ProcessGroup.cpp:266] Warning: At the time of process termination, there are still 1 unwaited collective calls. Please review your program to ensure that:
1. c10d_functional.wait_tensor() is invoked on all tensors returned from c10d_functional collective,
2. c10d_functional.wait_tensor() is invoked on all output tensors of async_op=True torch.distributed collective called under `with allow_inflight_collective_as_graph_input_ctx():`,
before the output tensors of the collective are used. (function ~WorkRegistry)
[W1109 17:38:08.973619700 ProcessGroup.cpp:266] Warning: At the time of process termination, there are still 1 unwaited collective calls. Please review your program to ensure that:
1. c10d_functional.wait_tensor() is invoked on all tensors returned from c10d_functional collective,
2. c10d_functional.wait_tensor() is invoked on all output tensors of async_op=True torch.distributed collective called under `with allow_inflight_collective_as_graph_input_ctx():`,
before the output tensors of the collective are used. (function ~WorkRegistry)
[W1109 17:38:08.973630406 ProcessGroup.cpp:266] Warning: At the time of process termination, there are still 1 unwaited collective calls. Please review your program to ensure that:
1. c10d_functional.wait_tensor() is invoked on all tensors returned from c10d_functional collective,
2. c10d_functional.wait_tensor() is invoked on all output tensors of async_op=True torch.distributed collective called under `with allow_inflight_collective_as_graph_input_ctx():`,
before the output tensors of the collective are used. (function ~WorkRegistry)
[W1109 17:38:08.974397318 ProcessGroup.cpp:266] Warning: At the time of process termination, there are still 1 unwaited collective calls. Please review your program to ensure that:
1. c10d_functional.wait_tensor() is invoked on all tensors returned from c10d_functional collective,
2. c10d_functional.wait_tensor() is invoked on all output tensors of async_op=True torch.distributed collective called under `with allow_inflight_collective_as_graph_input_ctx():`,
before the output tensors of the collective are used. (function ~WorkRegistry)
[W1109 17:38:08.974516155 ProcessGroup.cpp:266] Warning: At the time of process termination, there are still 1 unwaited collective calls. Please review your program to ensure that:
1. c10d_functional.wait_tensor() is invoked on all tensors returned from c10d_functional collective,
2. c10d_functional.wait_tensor() is invoked on all output tensors of async_op=True torch.distributed collective called under `with allow_inflight_collective_as_graph_input_ctx():`,
before the output tensors of the collective are used. (function ~WorkRegistry)
[W1109 17:38:08.906037593 ProcessGroup.cpp:266] Warning: At the time of process termination, there are still 1 unwaited collective calls. Please review your program to ensure that:
1. c10d_functional.wait_tensor() is invoked on all tensors returned from c10d_functional collective,
2. c10d_functional.wait_tensor() is invoked on all output tensors of async_op=True torch.distributed collective called under `with allow_inflight_collective_as_graph_input_ctx():`,
before the output tensors of the collective are used. (function ~WorkRegistry)
[W1109 17:38:08.906719408 ProcessGroup.cpp:266] Warning: At the time of process termination, there are still 1 unwaited collective calls. Please review your program to ensure that:
1. c10d_functional.wait_tensor() is invoked on all tensors returned from c10d_functional collective,
2. c10d_functional.wait_tensor() is invoked on all output tensors of async_op=True torch.distributed collective called under `with allow_inflight_collective_as_graph_input_ctx():`,
before the output tensors of the collective are used. (function ~WorkRegistry)
[W1109 17:38:08.906925297 ProcessGroup.cpp:266] Warning: At the time of process termination, there are still 1 unwaited collective calls. Please review your program to ensure that:
1. c10d_functional.wait_tensor() is invoked on all tensors returned from c10d_functional collective,
2. c10d_functional.wait_tensor() is invoked on all output tensors of async_op=True torch.distributed collective called under `with allow_inflight_collective_as_graph_input_ctx():`,
before the output tensors of the collective are used. (function ~WorkRegistry)
[W1109 17:38:08.577334103 ProcessGroup.cpp:266] Warning: At the time of process termination, there are still 1 unwaited collective calls. Please review your program to ensure that:
1. c10d_functional.wait_tensor() is invoked on all tensors returned from c10d_functional collective,
2. c10d_functional.wait_tensor() is invoked on all output tensors of async_op=True torch.distributed collective called under `with allow_inflight_collective_as_graph_input_ctx():`,
before the output tensors of the collective are used. (function ~WorkRegistry)
[W1109 17:38:08.184562553 ProcessGroup.cpp:266] Warning: At the time of process termination, there are still 1 unwaited collective calls. Please review your program to ensure that:
1. c10d_functional.wait_tensor() is invoked on all tensors returned from c10d_functional collective,
2. c10d_functional.wait_tensor() is invoked on all output tensors of async_op=True torch.distributed collective called under `with allow_inflight_collective_as_graph_input_ctx():`,
before the output tensors of the collective are used. (function ~WorkRegistry)
[W1109 17:38:08.186085402 ProcessGroup.cpp:266] Warning: At the time of process termination, there are still 1 unwaited collective calls. Please review your program to ensure that:
1. c10d_functional.wait_tensor() is invoked on all tensors returned from c10d_functional collective,
2. c10d_functional.wait_tensor() is invoked on all output tensors of async_op=True torch.distributed collective called under `with allow_inflight_collective_as_graph_input_ctx():`,
before the output tensors of the collective are used. (function ~WorkRegistry)
[W1109 17:38:08.186179753 ProcessGroup.cpp:266] Warning: At the time of process termination, there are still 1 unwaited collective calls. Please review your program to ensure that:
1. c10d_functional.wait_tensor() is invoked on all tensors returned from c10d_functional collective,
2. c10d_functional.wait_tensor() is invoked on all output tensors of async_op=True torch.distributed collective called under `with allow_inflight_collective_as_graph_input_ctx():`,
before the output tensors of the collective are used. (function ~WorkRegistry)
[W1109 17:38:08.187119308 ProcessGroup.cpp:266] Warning: At the time of process termination, there are still 1 unwaited collective calls. Please review your program to ensure that:
1. c10d_functional.wait_tensor() is invoked on all tensors returned from c10d_functional collective,
2. c10d_functional.wait_tensor() is invoked on all output tensors of async_op=True torch.distributed collective called under `with allow_inflight_collective_as_graph_input_ctx():`,
before the output tensors of the collective are used. (function ~WorkRegistry)
[W1109 17:38:08.967786099 ProcessGroup.cpp:266] Warning: At the time of process termination, there are still 1 unwaited collective calls. Please review your program to ensure that:
1. c10d_functional.wait_tensor() is invoked on all tensors returned from c10d_functional collective,
2. c10d_functional.wait_tensor() is invoked on all output tensors of async_op=True torch.distributed collective called under `with allow_inflight_collective_as_graph_input_ctx():`,
before the output tensors of the collective are used. (function ~WorkRegistry)
srun: error: jzxh139: tasks 29-31: Exited with exit code 1
srun: error: jzxh092: tasks 9-11: Exited with exit code 1
srun: error: jzxh337: tasks 52,54-55: Exited with exit code 1
srun: error: jzxh356: tasks 56-57,59: Exited with exit code 1
srun: error: jzxh140: tasks 32-33,35: Exited with exit code 1
srun: error: jzxh003: tasks 0-1,3: Exited with exit code 1
srun: error: jzxh091: tasks 4-6: Exited with exit code 1
srun: error: jzxh161: tasks 44,46-47: Exited with exit code 1
srun: error: jzxh125: tasks 21-23: Exited with exit code 1
srun: error: jzxh123: tasks 16,18-19: Exited with exit code 1
srun: error: jzxh357: tasks 60-62: Exited with exit code 1
srun: error: jzxh160: tasks 41-43: Exited with exit code 1
srun: error: jzxh126: tasks 25-27: Exited with exit code 1
srun: error: jzxh336: tasks 48-49,51: Exited with exit code 1
srun: error: jzxh122: tasks 12-13,15: Exited with exit code 1
slurmstepd: error: *** STEP 1545106.0 ON jzxh003 CANCELLED AT 2025-11-09T17:38:09 ***
srun: error: jzxh092: task 8: Exited with exit code 1
srun: error: jzxh140: task 34: Exited with exit code 1
srun: error: jzxh003: task 2: Exited with exit code 1
srun: error: jzxh159: task 37: Exited with exit code 1
srun: error: jzxh139: task 28: Exited with exit code 1
srun: error: jzxh356: task 58: Exited with exit code 1
srun: error: jzxh123: task 17: Exited with exit code 1
srun: error: jzxh161: task 45: Exited with exit code 1
srun: error: jzxh337: task 53: Exited with exit code 1
srun: error: jzxh091: task 7: Exited with exit code 1
srun: error: jzxh125: task 20: Exited with exit code 1
srun: error: jzxh160: task 40: Exited with exit code 1
srun: error: jzxh357: task 63: Exited with exit code 1
srun: error: jzxh336: task 50: Exited with exit code 1
srun: error: jzxh126: task 24: Exited with exit code 1
srun: error: jzxh122: task 14: Exited with exit code 1

real	1m48.731s
user	0m0.019s
sys	0m0.051s
+ date
