Loading nemo/2.4.0
  Loading requirement: gcc/11.4.1 cuda/12.8.0 nccl/2.27.3-1-cuda
    cudnn/9.10.2.21-12-cuda openmpi/4.1.6-cuda intel-oneapi-mkl/2024.1
    magma/2.9.0-cuda sox/14.4.2 ffmpeg/6.1.1-cuda hdf5/1.12.0-mpi-cuda
    libjpeg-turbo/2.1.3
+ srun python -u nemo_megatron.py --model Qwen/Qwen2.5-14B-Instruct --devices 4 --num-nodes 16 --tp-size 4 --pp-size 4 --accumulate-grad-batches 8 --global-batch-size 128
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
[NeMo W 2025-11-10 02:07:43 nemo_logging:405] /lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lhotse/recipes/iwslt22_ta.py:323: SyntaxWarning: invalid escape sequence '\s'
      text = re.sub("\s+", " ", text)
    
[NeMo W 2025-11-10 02:07:43 nemo_logging:405] /lustre/fshomisc/sup/pub/miniforge/24.11.3/envs/nemo-2.4.0+py3.12.10/lib/python3.12/site-packages/lhotse/recipes/iwslt22_ta.py:324: SyntaxWarning: invalid escape sequence '\s'
      text = re.sub("\s+\.\s+", ".", text)
    
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
Supported flash-attn versions are >= 2.1.1, <= 2.8.1. Found flash-attn 2.8.3.
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.8.0)
    Python  3.12.10 (you have 3.12.10)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
Traceback (most recent call last):
  File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_megatron.py", line 188, in <module>
Traceback (most recent call last):
  File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_megatron.py", line 188, in <module>
    main()
  File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_megatron.py", line 167, in main
    pad_seq_len_divisible=16 if args.fp8 else None,
                                ^^^^^^^^
AttributeError: 'Namespace' object has no attribute 'fp8'
    main()
  File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_megatron.py", line 167, in main
    pad_seq_len_divisible=16 if args.fp8 else None,
                                ^^^^^^^^
AttributeError: 'Namespace' object has no attribute 'fp8'
Traceback (most recent call last):
  File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_megatron.py", line 188, in <module>
    main()
  File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_megatron.py", line 167, in main
    pad_seq_len_divisible=16 if args.fp8 else None,
                                ^^^^^^^^
AttributeError: 'Namespace' object has no attribute 'fp8'
Traceback (most recent call last):
  File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_megatron.py", line 188, in <module>
    main()
  File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_megatron.py", line 167, in main
    pad_seq_len_divisible=16 if args.fp8 else None,
                                ^^^^^^^^
AttributeError: 'Namespace' object has no attribute 'fp8'
Traceback (most recent call last):
  File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_megatron.py", line 188, in <module>
Traceback (most recent call last):
  File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_megatron.py", line 188, in <module>
    main()
  File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_megatron.py", line 167, in main
    pad_seq_len_divisible=16 if args.fp8 else None,
                                ^^^^^^^^
AttributeError: 'Namespace' object has no attribute 'fp8'
    main()
  File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_megatron.py", line 167, in main
    pad_seq_len_divisible=16 if args.fp8 else None,
                                ^^^^^^^^
AttributeError: 'Namespace' object has no attribute 'fp8'
Traceback (most recent call last):
  File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_megatron.py", line 188, in <module>
    main()
  File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_megatron.py", line 167, in main
    pad_seq_len_divisible=16 if args.fp8 else None,
                                ^^^^^^^^
AttributeError: 'Namespace' object has no attribute 'fp8'
Traceback (most recent call last):
  File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_megatron.py", line 188, in <module>
    main()
  File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_megatron.py", line 167, in main
    pad_seq_len_divisible=16 if args.fp8 else None,
                                ^^^^^^^^
AttributeError: 'Namespace' object has no attribute 'fp8'
Traceback (most recent call last):
  File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_megatron.py", line 188, in <module>
    main()
  File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_megatron.py", line 167, in main
    pad_seq_len_divisible=16 if args.fp8 else None,
                                ^^^^^^^^
AttributeError: 'Namespace' object has no attribute 'fp8'
Traceback (most recent call last):
  File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_megatron.py", line 188, in <module>
    main()
  File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_megatron.py", line 167, in main
    pad_seq_len_divisible=16 if args.fp8 else None,
                                ^^^^^^^^
AttributeError: 'Namespace' object has no attribute 'fp8'
Traceback (most recent call last):
  File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_megatron.py", line 188, in <module>
    main()
  File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_megatron.py", line 167, in main
    pad_seq_len_divisible=16 if args.fp8 else None,
                                ^^^^^^^^
AttributeError: 'Namespace' object has no attribute 'fp8'
Traceback (most recent call last):
  File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_megatron.py", line 188, in <module>
    main()
  File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_megatron.py", line 167, in main
    pad_seq_len_divisible=16 if args.fp8 else None,
                                ^^^^^^^^
AttributeError: 'Namespace' object has no attribute 'fp8'
Traceback (most recent call last):
  File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_megatron.py", line 188, in <module>
    main()
  File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_megatron.py", line 167, in main
    pad_seq_len_divisible=16 if args.fp8 else None,
                                ^^^^^^^^
AttributeError: 'Namespace' object has no attribute 'fp8'
Traceback (most recent call last):
  File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_megatron.py", line 188, in <module>
Traceback (most recent call last):
  File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_megatron.py", line 188, in <module>
    main()
  File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_megatron.py", line 167, in main
    pad_seq_len_divisible=16 if args.fp8 else None,
                                ^^^^^^^^
AttributeError: 'Namespace' object has no attribute 'fp8'
    main()
  File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_megatron.py", line 167, in main
    pad_seq_len_divisible=16 if args.fp8 else None,
                                ^^^^^^^^
AttributeError: 'Namespace' object has no attribute 'fp8'
Traceback (most recent call last):
  File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_megatron.py", line 188, in <module>
    main()
  File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_megatron.py", line 167, in main
Traceback (most recent call last):
  File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_megatron.py", line 188, in <module>
Traceback (most recent call last):
  File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_megatron.py", line 188, in <module>
    pad_seq_len_divisible=16 if args.fp8 else None,
                                ^^^^^^^^
AttributeError: 'Namespace' object has no attribute 'fp8'
    main()
  File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_megatron.py", line 167, in main
    pad_seq_len_divisible=16 if args.fp8 else None,
                                ^^^^^^^^
AttributeError: 'Namespace' object has no attribute 'fp8'
    main()
  File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_megatron.py", line 167, in main
    pad_seq_len_divisible=16 if args.fp8 else None,
                                ^^^^^^^^
AttributeError: 'Namespace' object has no attribute 'fp8'
Traceback (most recent call last):
  File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_megatron.py", line 188, in <module>
    main()
  File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_megatron.py", line 167, in main
    pad_seq_len_divisible=16 if args.fp8 else None,
                                ^^^^^^^^
AttributeError: 'Namespace' object has no attribute 'fp8'
Traceback (most recent call last):
  File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_megatron.py", line 188, in <module>
    main()
  File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_megatron.py", line 167, in main
    pad_seq_len_divisible=16 if args.fp8 else None,
                                ^^^^^^^^
AttributeError: 'Namespace' object has no attribute 'fp8'
Traceback (most recent call last):
  File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_megatron.py", line 188, in <module>
    main()
  File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_megatron.py", line 167, in main
    pad_seq_len_divisible=16 if args.fp8 else None,
                                ^^^^^^^^
AttributeError: 'Namespace' object has no attribute 'fp8'
Traceback (most recent call last):
  File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_megatron.py", line 188, in <module>
Traceback (most recent call last):
  File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_megatron.py", line 188, in <module>
    main()
  File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_megatron.py", line 167, in main
    pad_seq_len_divisible=16 if args.fp8 else None,
                                ^^^^^^^^
AttributeError: 'Namespace' object has no attribute 'fp8'
    main()
  File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_megatron.py", line 167, in main
    pad_seq_len_divisible=16 if args.fp8 else None,
                                ^^^^^^^^
AttributeError: 'Namespace' object has no attribute 'fp8'
Traceback (most recent call last):
  File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_megatron.py", line 188, in <module>
    main()
  File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_megatron.py", line 167, in main
    pad_seq_len_divisible=16 if args.fp8 else None,
                                ^^^^^^^^
AttributeError: 'Namespace' object has no attribute 'fp8'
Traceback (most recent call last):
  File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_megatron.py", line 188, in <module>
    main()
  File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_megatron.py", line 167, in main
    pad_seq_len_divisible=16 if args.fp8 else None,
                                ^^^^^^^^
AttributeError: 'Namespace' object has no attribute 'fp8'
Traceback (most recent call last):
  File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_megatron.py", line 188, in <module>
    main()
  File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_megatron.py", line 167, in main
    pad_seq_len_divisible=16 if args.fp8 else None,
                                ^^^^^^^^
AttributeError: 'Namespace' object has no attribute 'fp8'
Traceback (most recent call last):
  File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_megatron.py", line 188, in <module>
    main()
  File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_megatron.py", line 167, in main
    pad_seq_len_divisible=16 if args.fp8 else None,
                                ^^^^^^^^
AttributeError: 'Namespace' object has no attribute 'fp8'
Traceback (most recent call last):
  File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_megatron.py", line 188, in <module>
    main()
  File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_megatron.py", line 167, in main
    pad_seq_len_divisible=16 if args.fp8 else None,
                                ^^^^^^^^
AttributeError: 'Namespace' object has no attribute 'fp8'
Traceback (most recent call last):
  File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_megatron.py", line 188, in <module>
    main()
  File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_megatron.py", line 167, in main
Traceback (most recent call last):
  File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_megatron.py", line 188, in <module>
    pad_seq_len_divisible=16 if args.fp8 else None,
                                ^^^^^^^^
AttributeError: 'Namespace' object has no attribute 'fp8'
    main()
  File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_megatron.py", line 167, in main
    pad_seq_len_divisible=16 if args.fp8 else None,
                                ^^^^^^^^
AttributeError: 'Namespace' object has no attribute 'fp8'
Traceback (most recent call last):
  File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_megatron.py", line 188, in <module>
    main()
  File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_megatron.py", line 167, in main
    pad_seq_len_divisible=16 if args.fp8 else None,
                                ^^^^^^^^
AttributeError: 'Namespace' object has no attribute 'fp8'
Traceback (most recent call last):
  File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_megatron.py", line 188, in <module>
    main()
  File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_megatron.py", line 167, in main
    pad_seq_len_divisible=16 if args.fp8 else None,
                                ^^^^^^^^
AttributeError: 'Namespace' object has no attribute 'fp8'
Traceback (most recent call last):
  File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_megatron.py", line 188, in <module>
Traceback (most recent call last):
  File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_megatron.py", line 188, in <module>
    main()
  File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_megatron.py", line 167, in main
    pad_seq_len_divisible=16 if args.fp8 else None,
                                ^^^^^^^^
AttributeError: 'Namespace' object has no attribute 'fp8'
    main()
  File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_megatron.py", line 167, in main
    pad_seq_len_divisible=16 if args.fp8 else None,
                                ^^^^^^^^
AttributeError: 'Namespace' object has no attribute 'fp8'
Traceback (most recent call last):
  File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_megatron.py", line 188, in <module>
    main()
  File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_megatron.py", line 167, in main
    pad_seq_len_divisible=16 if args.fp8 else None,
                                ^^^^^^^^
AttributeError: 'Namespace' object has no attribute 'fp8'
Traceback (most recent call last):
  File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_megatron.py", line 188, in <module>
    main()
  File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_megatron.py", line 167, in main
    pad_seq_len_divisible=16 if args.fp8 else None,
                                ^^^^^^^^
AttributeError: 'Namespace' object has no attribute 'fp8'
Traceback (most recent call last):
  File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_megatron.py", line 188, in <module>
Traceback (most recent call last):
  File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_megatron.py", line 188, in <module>
    main()
  File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_megatron.py", line 167, in main
    pad_seq_len_divisible=16 if args.fp8 else None,
                                ^^^^^^^^
AttributeError: 'Namespace' object has no attribute 'fp8'
    main()
  File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_megatron.py", line 167, in main
    pad_seq_len_divisible=16 if args.fp8 else None,
                                ^^^^^^^^
AttributeError: 'Namespace' object has no attribute 'fp8'
Traceback (most recent call last):
  File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_megatron.py", line 188, in <module>
    main()
  File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_megatron.py", line 167, in main
    pad_seq_len_divisible=16 if args.fp8 else None,
                                ^^^^^^^^
AttributeError: 'Namespace' object has no attribute 'fp8'
Traceback (most recent call last):
  File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_megatron.py", line 188, in <module>
    main()
  File "/lustre/fswork/projects/idris/sos/ssos040/Bench_InstructFT_Tulu3/InstructFT/nemo_megatron.py", line 167, in main
    pad_seq_len_divisible=16 if args.fp8 else None,
                                ^^^^^^^^
AttributeError: 'Namespace' object has no attribute 'fp8'
srun: error: jzxh356: tasks 56-58: Exited with exit code 1
srun: Terminating StepId=1549841.0
slurmstepd: error: *** STEP 1549841.0 ON jzxh003 CANCELLED AT 2025-11-10T02:08:03 ***
srun: error: jzxh356: task 59: Exited with exit code 1
srun: error: jzxh336: tasks 48-49: Terminated
srun: error: jzxh139: tasks 28-29: Terminated
srun: error: jzxh337: tasks 52-54: Terminated
srun: error: jzxh125: tasks 20-21,23: Terminated
srun: error: jzxh092: tasks 8-9,11: Terminated
srun: error: jzxh140: tasks 32-33,35: Terminated
srun: error: jzxh122: tasks 12-14: Terminated
srun: error: jzxh337: task 55: Terminated
srun: error: jzxh092: task 10: Terminated
srun: error: jzxh125: task 22: Terminated
srun: error: jzxh122: task 15: Terminated
srun: error: jzxh140: task 34: Terminated
srun: error: jzxh336: tasks 50-51: Terminated
srun: error: jzxh139: tasks 30-31: Terminated
srun: error: jzxh160: tasks 40-43: Terminated
srun: error: jzxh123: tasks 16-19: Terminated
srun: error: jzxh091: tasks 4-7: Terminated
srun: error: jzxh126: tasks 24-27: Terminated
srun: error: jzxh159: tasks 36-39: Terminated
srun: error: jzxh161: tasks 44-47: Terminated
srun: error: jzxh003: tasks 0-3: Terminated
srun: error: jzxh357: tasks 60-63: Terminated
srun: Force Terminated StepId=1549841.0

real	0m40.629s
user	0m0.018s
sys	0m0.036s
+ date
